<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Linux多进程的一些知识点</title>
      <link href="/linux-multiprocess.html"/>
      <url>/linux-multiprocess.html</url>
      
        <content type="html"><![CDATA[<h1 id="进程间通信方式"><a href="#进程间通信方式" class="headerlink" title="进程间通信方式"></a>进程间通信方式</h1><ol><li>同一主机：<br>$$<br>同一主机进程间通信=\left{<br>\begin{matrix}<br> Unix进程间通信方式 \<br> System V进程间通信方式 \<br> POSIX进程间通信方式<br>\end{matrix}<br>\right.<br>$$<br>$$<br>Unix进程间通信方式=\left{<br>\begin{matrix}<br> 匿名管道 \<br> 有名管道 \<br> 信号<br>\end{matrix}<br>\right.<br>$$<br>$$<br>System V进程间通信 、<br> POSIX进程间通信 =\left{<br>\begin{matrix}<br> 消息队列 \<br> 共享内存 \<br> 信号量<br>\end{matrix}<br>\right.<br>$$</li><li>不同主机（网络）进程间通信：Socket<h1 id="管道"><a href="#管道" class="headerlink" title="管道"></a>管道</h1></li><li>管道是在内核内存中维护的缓冲器，不同操作系统大小不一定相同。</li><li>管道拥有文件的特质：读和写。匿名管道没有文件实体，有名管道有文件实体，但不存储数据。</li><li>一个管道是一个字节流，可以从中读取任意大小的数据块。</li><li>管道传递的数据是顺序的，读出来的顺序和写入时一致。</li><li>管道的数据传递是单向的，一端写入，一端用于读取，属于半双工。</li><li>管道内数据是一次性操作，一旦被读走，就会被删掉来释放空间。</li><li>匿名管道只能在具有公共祖先的进程中使用。（因为拥有相同的文件描述符，指向的管道一致）。</li><li>管道的数据结构是环形的。</li></ol><p>（堵塞）管道<strong>读写</strong>特点：</p><ol><li>如果管道写端的文件描述符都关闭了，且管道内无数据后，再次read将会<strong>返回0</strong>，而不是堵塞。</li><li>如果管道读端的文件描述符都关闭了，这时候向管道写数据，该进程会收到一个信号SIGPIPE，通常会导致进程异常终止。</li><li>如果管道读端的文件描述符没有关闭，且没有从管道读数据，那么在管道写满后再次write会<strong>堵塞</strong>，直到有空位置才能再次写入数据并返回。</li><li>进程启动，若只先开启读端，将会堵塞，直到读端开启。同理，若只开启写段，也会堵塞到读端开启。</li></ol><p><strong>匿名管道（pipe）</strong>：通过一个没有实体的管道，实现具有亲缘关系的进程间通信。</p><p><strong>有名管道（FIFO）</strong>：克服了匿名管道只能用于亲缘关系的进程通信。<br>有名管道提供了一个路径名与之关联，以FIFO文件形式存在于文件系统中，进程间可以访问该路径而彼此通信。</p><p>匿名有名的不同点：</p><ol><li>FIFO在文件系统中作为一个特殊文件存在，但其内容存放于内存中。</li><li>FIFO文件在进程退出后继续保存在文件系统中。</li><li>FIFO有名字，因而不相关的进程可以访问该文件进行通信。</li></ol><h1 id="Linux信号"><a href="#Linux信号" class="headerlink" title="Linux信号"></a>Linux信号</h1><p>kill -l: 查看系统定义的信号列表<br>信号编号-信号名-默认动作-对应事件<br>2:SIGINT：终止进程。&lt;Ctrl+C&gt;，用户终端向正在运行中的由该终端启动的程序发出此信号。<br>3.SIGQUIT：终止进程。&lt;Ctrl+\&gt;,同信号2。<br>9.SIGKILL：终止进程（可以杀死任何进程）。无条件终止进程，该信号不能被忽略，处理和阻塞。<br>11.SIGSEGV：终止进程并产生core文件。指示进程进行了无效内存访问。<br>13.SIGPIPE：终止进程。pipe向一个没有读端的管道写数据。<br>17.SIGCHIL：忽略这个信号。子进程结束时，父进程收到该信号。<br>18.SIGCONT：继续/忽略。如果进程已停止，则使其继续运行。<br>19.SIGSTOP：终止进程。停止进程的执行。该信号不能被忽略，处理和阻塞。<br>SIGKILL和SIGSTOP只能执行默认动作。</p><p>查看信号详细信息：man 7 signal<br>信号的五种默认处理动作：</p><ol><li>Term：终止进程</li><li>Ign：当前进程忽略掉这个信号</li><li>Core：终止进程并生成core文件</li><li>Stop：暂停当前进程</li><li>Cont：继续执行当前被暂停的进程<br>信号的状态：产生、未决（没有被处理的状态）、递达（信号被处理了）</li></ol><p>SIGCHLD信号产生条件：<br>    * 子进程终止时<br>    * 子进程接收到SIGSTOP信号停止时<br>    * 子进程处在停止态，接收到SIGCONT唤醒时<br>产生的SIGCHLD信号会发送给父进程，父进程默认忽略该信号。</p><h1 id="信号集"><a href="#信号集" class="headerlink" title="信号集"></a>信号集</h1><p>两个主要信号集：<br>阻塞信号集：阻止信号响应，并不阻止产生。<br>未决信号集：还未产生响应的信号。</p><ol><li>在内核中，所有没被处理的信号存储在一个集合中，信号状态存储在第二个标志位上。标志位为0，信号不是处于未决状态；标志位为1，信号处于未决状态。</li><li>处理未决信号前，需要和阻塞信号机比较。阻塞信号集默认不阻塞任何信号，如果要阻塞，需要调用系统API。</li><li>在处理未决信号前对阻塞信号集的标志位进行查询。若没有设置阻塞，则正常处理信号；若阻塞了，信号就继续处于未决状态，直至阻塞解除。</li></ol><h1 id="共享内存"><a href="#共享内存" class="headerlink" title="共享内存"></a>共享内存</h1><p>共享内存允许两个或者多个进程共享物理内存的同一块区域(通常被称为段)。由于一个共享内存段会称为一个进程用户空间的一部分，因此这种IPC机制无需内核介入。所有需要做的就是让一个进程将数据复制进共享内存中，并且这部分数据会对<strong>其他所有</strong>共享同一个段的进程可用。<br>与管道等要求发送进程将数据从用户空间的缓冲区复制进内核内存和接收进程将数据从内核内存复制进用户空间的缓冲区的做法相比，这种IPC技术的速度更快。<br>共享内存和内存映射的区别：</p><ol><li><p>共享内存可以直接创建，内存映射需要磁盘文件(匿名映射除外)</p></li><li><p>共享内存效果更高</p></li><li><p>内存</p><p> 所有的进程操作的是同一块共享内存。<br> 内存映射，每个进程在自己的虚拟地址空间中有一个独立的内存。</p></li><li><p>数据安全</p><ul><li>进程突然退出<br>  共享内存还存在内存映射区消失</li><li>运行进程的电脑死机，宕机了<br>  数据存在在共享内存中，没有了<br>  内存映射区的数据 ，由于磁盘文件中的数据还在，所以内存映射区的数据还存在</li></ul></li><li><p>生命周期</p><ul><li>内存映射区: 进程退出，内存映射区销毁</li><li>共享内存: 进程退出，共享内存还在，标记删除，或者关机</li></ul></li></ol><h1 id="进程组与会话"><a href="#进程组与会话" class="headerlink" title="进程组与会话"></a>进程组与会话</h1><h2 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h2><ul><li>进程组是一组相关进程的集合。</li><li>进程组由一个或多个共享同一进程组标识符(PGID)的进程组成。</li><li>一个进程组拥有一个进程组首进程，该进程是创建该组的进程，其进程ID为该进程组的ID，新进程</li><li>会继承其父进程所属的进程组ID。</li><li>进程组拥有一个生命周期，其开始时间为首进程创建组的时刻，结束时间为最后一个成员进程退出组的时刻。</li><li>进程组首进程无需是最后一个离开进程组的成员。<h2 id="会话"><a href="#会话" class="headerlink" title="会话"></a>会话</h2></li><li>会话是一组进程组的集合。</li><li>会话首进程是创建该新会话的进程，其进程ID 会成为会话 ID。新进程会继承其父进程的会话ID。</li><li>一个会话中的所有进程共享<strong>单个</strong>控制终端。控制终端会在会话首进程首次打开一个终端设备时被建立。一个终端最多可能会成为一个会话的控制终端。</li><li>在任一时刻，会话中的其中一个进程组会成为终端的前台进程组，其他进程组会成为后台进程组。只有前台进程组中的进程才能从控制终端中读取输入。当用户在控制终端中输入终端字符生成信号后，该信号会被发送到前台进程组中的所有成员。</li><li>当控制终端的连接建立起来之后，会话首进程会成为该终端的控制进程。</li></ul><p>#守护进程（Daemon 进程）<br>也称精灵进程，是Linux中的后台服务进程。它是一个生存期较长的进程，通常独立于控制终端且周期性执行某种任务或等待处理某些事件，名字一般以d结尾，如Internet服务器inetd,Web服务器httpd。</p><ul><li>生命周期长，在系统启动的时候就被创建并一直运行至系统关闭。</li><li>后台运行且没有控制终端，确保内核永远不会为守护进程自动生成任何控制信号以及终端相关的信号。<h2 id="守护进程创建步骤"><a href="#守护进程创建步骤" class="headerlink" title="守护进程创建步骤"></a>守护进程创建步骤</h2></li></ul><ul><li>执行一个 fork()，之 后父进程退出，子进程继续执行。（*必要）<br>（父进程退出能够不让终端在父进程结束后显示shell提示符；使用fork确保创建的子进程不会成为进程组的首进程） </li><li>子进程调用setsid()开启一个新会话。（*必要）<br>（首先，进程创建新的会话时，会该进程会成为新会话新进程组的首进程，如果用父进程创建，回合原来的进程组会话冲突，因此要用子进程创建。其次，创建新的会话，如果不建立连接的话，会话是没有控制终端的，也就符合的守护进程的要求。）</li><li>清除进程的umask以确保当守护进程创建文件和目录时拥有所需的权限。(函数umask(xxx);)</li><li>修改进程的当前工作目录，通常会改为根目录(/)。<br>（主要因为守护进程是要存活到系统结束，如果在其他目录，该目录就无法卸载，如u盘目录。函数chdir();）</li><li>关闭守护进程从其父进程继承而来的所有打开着的文件描述符。<br>（原因同上，防止无法卸载某些关联磁盘）</li><li>在关闭了文件描述符0、1、2之后，守护进程通常会打开/dev/null并使用dup2()使所有这些描述符指向这个设备。<br>（防止系统调用这些关闭了的文件描述符后出错，重定向到null目录，null目录内的内容会自动被丢弃）</li><li>核心业务逻辑（*必要）</li></ul>]]></content>
      
      
      <categories>
          
          <category> 后台开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 多进程 </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文复现：基于相关性分析的工业时序数据异常检测</title>
      <link href="/correlation-analysis.html"/>
      <url>/correlation-analysis.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> 异常检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 异常处理 </tag>
            
            <tag> 论文复现 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>时间序列集体异常检测与DBSCAN实战</title>
      <link href="/collective-anomaly-and-dbscan.html"/>
      <url>/collective-anomaly-and-dbscan.html</url>
      
        <content type="html"><![CDATA[<h1 id="1-异常类型"><a href="#1-异常类型" class="headerlink" title="1.异常类型"></a>1.异常类型</h1><ul><li><p><strong>point outliers（点异常）</strong>：这种异常样本往往以单个点的形式存在，其数值相较于整体样本而言是明显异常的（例如异常大或异常小的全局异常）。</p></li><li><p><strong>contextual outliers（上下文异常）</strong>：contextual outlier的异常体现在某一段时间区间。例如下图的第二幅子图，该异常点相对于整体样本而言并无异常，但如果考虑其相邻时间内的样本，其有明显的异常特性。</p><span id="more"></span>  </li><li><p><strong>collective outliers（集体异常）</strong>：指一段时间序列数据为异常。且该段数据中单独看每个样本点都不是异常的，样本的异常性体现在该段数据整体而言是异常的。<br><img lazyload="" src="/images/loading.svg" data-src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202205/Collective-anomaly-And-DBSCAN/1.1p11ki2gci80.jpg" alt="1"></p></li></ul><h1 id="2-集体异常检测"><a href="#2-集体异常检测" class="headerlink" title="2.集体异常检测"></a>2.集体异常检测</h1><p>检测集体（模式）异常的常见做法：</p><ul><li><strong>不和谐分析</strong>：利用滑动窗口将时间序列分割成多个子序列，并计算子序列之间的距离（例如，欧几里德距离）以找到时间序列数据中的不和谐，如矩阵配置文件、HotSAX。 </li><li><strong>子序列聚类</strong>：也将子序列分割应用于时间序列数据，并采用子序列作为每个时间点的特征，其中滑动窗口的大小是特征的数量。然后，采用无监督机器学习方法，例如聚类（例如，Kmeans，PCA）或逐点异常值检测算法来检测模式异常值。<br>其中，基于子序列的方法有三种不同的检测策略：<br>基于模型的方法：每个时间序列被转换为模型参数，然后选择合适的模型距离和聚类算法(通常是传统的聚类算法)，并将其应用于提取的模型参数。<br>基于特征的方法：通常在这种方法中，先从每个时间序列中计算等长特征向量，然后进行欧氏距离测量。<br>基于形状的方法：通常直接处理原始时间序列数据。依据序列间的距离/相似度度量进行聚类<h1 id="3-集体异常检测实战"><a href="#3-集体异常检测实战" class="headerlink" title="3.集体异常检测实战"></a>3.集体异常检测实战</h1>检测策略：基于特征的子序列聚类，PCA提取重要特征，DBSCAN算法实现聚类。<br>检测流程：</li></ul><ol><li>加载原始数据</li><li>为了提高检测效果，对数据进行滤波平滑处理。</li><li>去除数据趋势影响。</li><li>按照实际数据模式，划分子序列，并提取特征。</li><li>特征过滤，PCA降维。</li><li>DBSCAN聚类，检测异常序列。<br>首先加载必要的工具并加载数据。</li></ol><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np <span class="token keyword">import</span> os<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd <span class="token keyword">from</span> scipy <span class="token keyword">import</span> signal<span class="token keyword">import</span> random <span class="token keyword">as</span> rd <span class="token keyword">import</span> datetime <span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt <span class="token keyword">import</span> seaborn <span class="token keyword">as</span> sns<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>dates <span class="token keyword">as</span> mdate<span class="token keyword">import</span> warningswarnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">"ignore"</span><span class="token punctuation">)</span><span class="token keyword">from</span> tsfresh<span class="token punctuation">.</span>utilities<span class="token punctuation">.</span>dataframe_functions <span class="token keyword">import</span> roll_time_series<span class="token keyword">from</span> statsmodels<span class="token punctuation">.</span>tsa<span class="token punctuation">.</span>seasonal <span class="token keyword">import</span> seasonal_decompose<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_selection <span class="token keyword">import</span> VarianceThreshold   <span class="token keyword">from</span> tsfresh <span class="token keyword">import</span> extract_features<span class="token keyword">from</span> scipy <span class="token keyword">import</span> signal<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> PCA<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>neighbors <span class="token keyword">import</span> NearestNeighbors<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>cluster <span class="token keyword">import</span> DBSCAN<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> metrics<span class="token keyword">import</span> plotly<span class="token punctuation">.</span>graph_objs <span class="token keyword">as</span> go<span class="token comment" spellcheck="true">#加载资源文件数据</span>data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./Data.csv'</span><span class="token punctuation">)</span>data<span class="token punctuation">.</span>index <span class="token operator">=</span> pd<span class="token punctuation">.</span>to_datetime<span class="token punctuation">(</span>data<span class="token punctuation">.</span>Datetime<span class="token punctuation">)</span></code></pre><p>使用低通滤波器滤波。</p><pre class=" language-python"><code class="language-python">b<span class="token punctuation">,</span> a <span class="token operator">=</span> signal<span class="token punctuation">.</span>butter<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">0.026</span> <span class="token punctuation">,</span> <span class="token string">'lowpass'</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#配置滤波器 8 表示滤波器的阶数</span>data<span class="token punctuation">[</span><span class="token string">'Hu1_0'</span><span class="token punctuation">]</span> <span class="token operator">=</span> signal<span class="token punctuation">.</span>filtfilt<span class="token punctuation">(</span>b<span class="token punctuation">,</span> a<span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token string">'Hu_0'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#data为要过滤的信号</span><span class="token comment" spellcheck="true">#可视化</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Hu_0'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">'Hu1_0'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">'Hu_0'</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><p>结果曲线图如下：<br><img lazyload="" src="/images/loading.svg" data-src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202205/Collective-anomaly-And-DBSCAN/2.5ttokbw5tz00.jpg" alt="2">  </p><p>利用时间序列分解，去除曲线趋势。在前期数据分析时找出数据存在两个周期，77min和1day。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 去趋势</span>decompose_result <span class="token operator">=</span> seasonal_decompose<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">'Hu1_0'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"additive"</span><span class="token punctuation">,</span> period<span class="token operator">=</span><span class="token number">77</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 分离77周期</span>data<span class="token punctuation">[</span><span class="token string">"detrend_77"</span><span class="token punctuation">]</span> <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">'Hu1_0'</span><span class="token punctuation">]</span> <span class="token operator">-</span> decompose_result<span class="token punctuation">.</span>seasonal<span class="token comment" spellcheck="true">#分解1440周期</span>decompose_result <span class="token operator">=</span> seasonal_decompose<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">"detrend_77"</span><span class="token punctuation">]</span> <span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"additive"</span><span class="token punctuation">,</span> period<span class="token operator">=</span><span class="token number">1440</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 趋势分量</span>data<span class="token punctuation">[</span><span class="token string">"Hu0_trend"</span><span class="token punctuation">]</span> <span class="token operator">=</span> decompose_result<span class="token punctuation">.</span>trend<span class="token comment" spellcheck="true">#删除含空值的行，前面分解的序列前端末端含有空值。</span>data <span class="token operator">=</span> data<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#去除趋势</span>data<span class="token punctuation">[</span><span class="token string">'detrend_Hu0'</span><span class="token punctuation">]</span> <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">'Hu1_0'</span><span class="token punctuation">]</span> <span class="token operator">-</span> decompose_result<span class="token punctuation">.</span>trend<span class="token comment" spellcheck="true"># 可视化</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Hu_0'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">'detrend_Hu0'</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202205/Collective-anomaly-And-DBSCAN/3.36x9yqdo7280.jpg" width="60%/"></div>  <p>接下来按照77窗口大小划分子序列，无重复窗口，并提取每个子序列的特征。使用tsfresh工具包，按照API要求，在表中添加id列。</p><pre class=" language-python"><code class="language-python">data<span class="token punctuation">[</span><span class="token string">'id'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token comment" spellcheck="true"># 滚动窗口</span><span class="token comment" spellcheck="true">#max_timeshift:最大偏移量，min_timeshift：最小偏移量，rolling_direction：每次移动的大小和方向。column_sort:按什么排序，默认已从小到大排好</span>df_rolled <span class="token operator">=</span> roll_time_series<span class="token punctuation">(</span>data<span class="token punctuation">,</span> column_id<span class="token operator">=</span><span class="token string">"id"</span><span class="token punctuation">,</span> column_sort<span class="token operator">=</span><span class="token string">"time"</span><span class="token punctuation">,</span>max_timeshift <span class="token operator">=</span> <span class="token number">76</span> <span class="token punctuation">,</span>min_timeshift <span class="token operator">=</span> <span class="token number">76</span><span class="token punctuation">,</span>rolling_direction<span class="token operator">=</span><span class="token operator">-</span><span class="token number">77</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 特征提取</span>df_features <span class="token operator">=</span> extract_features<span class="token punctuation">(</span>df_rolled<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token string">"time"</span><span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> column_id<span class="token operator">=</span><span class="token string">"id"</span><span class="token punctuation">)</span></code></pre><p>利用方差和相关系数进行特征过滤。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#删除含空值列</span>df_features_dropna_All <span class="token operator">=</span> df_features<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 标准化</span>scaler1 <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>df_features_Standar <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>scaler1<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>df_features_dropna_All<span class="token punctuation">)</span><span class="token punctuation">,</span>index<span class="token operator">=</span>df_features_dropna_All<span class="token punctuation">.</span>index<span class="token punctuation">,</span> columns<span class="token operator">=</span>df_features_dropna_All<span class="token punctuation">.</span>columns<span class="token punctuation">)</span>df_features_Standar<span class="token comment" spellcheck="true"># 特征过滤 filter方差</span>X_fratures_columns <span class="token operator">=</span> df_features_Standar<span class="token punctuation">.</span>columnsselector <span class="token operator">=</span> VarianceThreshold<span class="token punctuation">(</span><span class="token number">0.9</span><span class="token punctuation">)</span>X_features <span class="token operator">=</span> selector<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>df_features_Standar<span class="token punctuation">)</span>df_features_filter <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>X_features<span class="token punctuation">,</span>index<span class="token operator">=</span>df_features_Standar<span class="token punctuation">.</span>index<span class="token punctuation">,</span> columns<span class="token operator">=</span>X_fratures_columns<span class="token punctuation">[</span>selector<span class="token punctuation">.</span>get_support<span class="token punctuation">(</span>indices<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 特征过滤 相关系数corr</span><span class="token comment" spellcheck="true"># 剔除相关性系数高于threshold的corr_drop</span><span class="token comment" spellcheck="true"># df_filter.corr()</span>corr_features <span class="token operator">=</span> df_features_filter<span class="token punctuation">.</span>corr<span class="token punctuation">(</span><span class="token punctuation">)</span>threshold <span class="token operator">=</span> <span class="token number">0.4</span>upper_features <span class="token operator">=</span> corr_features<span class="token punctuation">.</span>where<span class="token punctuation">(</span>np<span class="token punctuation">.</span>triu<span class="token punctuation">(</span>np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>corr_features<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>bool<span class="token punctuation">)</span><span class="token punctuation">)</span>corr_features_drop <span class="token operator">=</span> <span class="token punctuation">[</span>column <span class="token keyword">for</span> column <span class="token keyword">in</span> upper_features<span class="token punctuation">.</span>columns <span class="token keyword">if</span> any<span class="token punctuation">(</span>upper_features<span class="token punctuation">[</span>column<span class="token punctuation">]</span><span class="token punctuation">.</span>abs<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> threshold<span class="token punctuation">)</span><span class="token punctuation">]</span>df_features_filter <span class="token operator">=</span> df_features_filter<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>corr_features_drop<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>df_features_filter</code></pre><p>过滤后的特征有14个，再使用PCA特征降维。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># PCA降维,目标维数为7。</span>pca <span class="token operator">=</span> PCA<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">)</span>pca<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>df_features_filter<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#获取特征主成分占比</span>variance <span class="token operator">=</span> pca<span class="token punctuation">.</span>explained_variance_ratio_ var<span class="token operator">=</span>np<span class="token punctuation">.</span>cumsum<span class="token punctuation">(</span>np<span class="token punctuation">.</span>round<span class="token punctuation">(</span>variance<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'% Variance Explained'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'# of Features'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'PCA Analysis'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">100.5</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>var<span class="token punctuation">)</span></code></pre><p>画出特征主成分占比曲线图。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202205/Collective-anomaly-And-DBSCAN/4.50ewczun4dc0.jpg" width="60%/"></div>  <p>选择占比最大的三个特征。</p><pre class=" language-python"><code class="language-python">pca <span class="token operator">=</span> PCA<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>pca<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>df_features_filter<span class="token punctuation">)</span>pca_scale <span class="token operator">=</span> pca<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>df_features_filter<span class="token punctuation">)</span>pca_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>pca_scale<span class="token punctuation">,</span> columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'pc1'</span><span class="token punctuation">,</span> <span class="token string">'pc2'</span><span class="token punctuation">,</span> <span class="token string">'pc3'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>pca<span class="token punctuation">.</span>explained_variance_ratio_<span class="token punctuation">)</span>pca_df </code></pre><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202205/Collective-anomaly-And-DBSCAN/4.4a1wi33d3o20.jpg" width="25%/"></div>  <p>查看特征3D图。</p><pre class=" language-python"><code class="language-python">Scene <span class="token operator">=</span> dict<span class="token punctuation">(</span>xaxis <span class="token operator">=</span> dict<span class="token punctuation">(</span>title <span class="token operator">=</span> <span class="token string">'PC1'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>yaxis <span class="token operator">=</span> dict<span class="token punctuation">(</span>title <span class="token operator">=</span> <span class="token string">'PC2'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>zaxis <span class="token operator">=</span> dict<span class="token punctuation">(</span>title <span class="token operator">=</span> <span class="token string">'PC3'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>trace <span class="token operator">=</span> go<span class="token punctuation">.</span>Scatter3d<span class="token punctuation">(</span>x<span class="token operator">=</span>pca_df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token operator">=</span>pca_df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> z<span class="token operator">=</span>pca_df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'markers'</span><span class="token punctuation">,</span>marker<span class="token operator">=</span>dict<span class="token punctuation">(</span>colorscale<span class="token operator">=</span><span class="token string">'Greys'</span><span class="token punctuation">,</span> opacity<span class="token operator">=</span><span class="token number">0.6</span><span class="token punctuation">,</span> size <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>layout <span class="token operator">=</span> go<span class="token punctuation">.</span>Layout<span class="token punctuation">(</span>margin<span class="token operator">=</span>dict<span class="token punctuation">(</span>l<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>r<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>scene <span class="token operator">=</span> Scene<span class="token punctuation">,</span> height <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">,</span>width <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">)</span>data <span class="token operator">=</span> <span class="token punctuation">[</span>trace<span class="token punctuation">]</span>fig <span class="token operator">=</span> go<span class="token punctuation">.</span>Figure<span class="token punctuation">(</span>data <span class="token operator">=</span> data<span class="token punctuation">,</span> layout <span class="token operator">=</span> layout<span class="token punctuation">)</span>fig<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202205/Collective-anomaly-And-DBSCAN/5.3cmrrg0tjgu0.jpg" width="45%/"></div>  <p>DBSCAN需要确定两个参数：epsilon：聚类半径；minPts：聚类点数。其中minPts一般取特征数目的两倍，对应项目中取6。epsilon利用肘形图确定。<br>画出特征的肘形图，即在y轴上，绘制点之间的平均距离，在x轴上绘制数据集中的所有数据点。从图中，取肘部数值约1.4。</p><pre class=" language-python"><code class="language-python">plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>nn <span class="token operator">=</span> NearestNeighbors<span class="token punctuation">(</span>n_neighbors<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>pca_df<span class="token punctuation">)</span>distances<span class="token punctuation">,</span> idx <span class="token operator">=</span> nn<span class="token punctuation">.</span>kneighbors<span class="token punctuation">(</span>pca_df<span class="token punctuation">)</span>distances <span class="token operator">=</span> np<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>distances<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>distances <span class="token operator">=</span> distances<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>distances<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202205/Collective-anomaly-And-DBSCAN/6.3ph5oy7aiym0.jpg" width="60%/"></div>  <p>确定完两个参数后，开始聚类。输出结果为聚类簇数、噪声点数和剪影得分（评价聚类效果，越接近1越好）。</p><pre class=" language-python"><code class="language-python">db <span class="token operator">=</span> DBSCAN<span class="token punctuation">(</span>eps<span class="token operator">=</span><span class="token number">1.4</span><span class="token punctuation">,</span> min_samples<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>pca_df<span class="token punctuation">)</span>labels <span class="token operator">=</span> db<span class="token punctuation">.</span>labels_<span class="token comment" spellcheck="true"># Number of clusters in labels, ignoring noise if present.</span>n_clusters_ <span class="token operator">=</span> len<span class="token punctuation">(</span>set<span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token keyword">if</span> <span class="token operator">-</span><span class="token number">1</span> <span class="token keyword">in</span> labels <span class="token keyword">else</span> <span class="token number">0</span><span class="token punctuation">)</span>n_noise_ <span class="token operator">=</span> list<span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Estimated number of clusters: %d'</span> <span class="token operator">%</span> n_clusters_<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Estimated number of noise points: %d'</span> <span class="token operator">%</span> n_noise_<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Silhouette Coefficient: %0.3f"</span> <span class="token operator">%</span> metrics<span class="token punctuation">.</span>silhouette_score<span class="token punctuation">(</span>pca_df<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>输出结果：<br>Estimated number of clusters: 1<br>Estimated number of noise points: 10<br>Silhouette Coefficient: 0.528<br>将筛选出来的噪声点即异常点反映在3D图上。</p><pre class=" language-python"><code class="language-python">Scene <span class="token operator">=</span> dict<span class="token punctuation">(</span>xaxis <span class="token operator">=</span> dict<span class="token punctuation">(</span>title <span class="token operator">=</span> <span class="token string">'PC1'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>yaxis <span class="token operator">=</span> dict<span class="token punctuation">(</span>title <span class="token operator">=</span> <span class="token string">'PC2'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>zaxis <span class="token operator">=</span> dict<span class="token punctuation">(</span>title <span class="token operator">=</span> <span class="token string">'PC3'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>labels <span class="token operator">=</span> db<span class="token punctuation">.</span>labels_trace <span class="token operator">=</span> go<span class="token punctuation">.</span>Scatter3d<span class="token punctuation">(</span>x<span class="token operator">=</span>pca_df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token operator">=</span>pca_df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> z<span class="token operator">=</span>pca_df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'markers'</span><span class="token punctuation">,</span>marker<span class="token operator">=</span>dict<span class="token punctuation">(</span>color <span class="token operator">=</span> labels<span class="token punctuation">,</span> colorscale<span class="token operator">=</span><span class="token string">'Viridis'</span><span class="token punctuation">,</span> size <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">,</span> line <span class="token operator">=</span> dict<span class="token punctuation">(</span>color <span class="token operator">=</span> <span class="token string">'gray'</span><span class="token punctuation">,</span>width <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>layout <span class="token operator">=</span> go<span class="token punctuation">.</span>Layout<span class="token punctuation">(</span>scene <span class="token operator">=</span> Scene<span class="token punctuation">,</span> height <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">,</span>width <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">)</span>data <span class="token operator">=</span> <span class="token punctuation">[</span>trace<span class="token punctuation">]</span>fig <span class="token operator">=</span> go<span class="token punctuation">.</span>Figure<span class="token punctuation">(</span>data <span class="token operator">=</span> data<span class="token punctuation">,</span> layout <span class="token operator">=</span> layout<span class="token punctuation">)</span>fig<span class="token punctuation">.</span>update_layout<span class="token punctuation">(</span>title<span class="token operator">=</span><span class="token string">'DBSCAN clusters Derived from PCA'</span><span class="token punctuation">,</span> font<span class="token operator">=</span>dict<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>fig<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202205/Collective-anomaly-And-DBSCAN/7.6znotbvxhto0.jpg" width="45%/"></div>   <p>将筛选出的异常序列反映到时间序列中。</p><pre class=" language-python"><code class="language-python">df_rolled<span class="token punctuation">[</span><span class="token string">'id'</span><span class="token punctuation">]</span> <span class="token operator">=</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>len<span class="token punctuation">(</span>df_rolled<span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>df_rolled<span class="token punctuation">.</span>index <span class="token operator">=</span> df_rolled<span class="token punctuation">.</span>idplt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> labels<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">></span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>        data <span class="token operator">=</span> df_rolled<span class="token punctuation">[</span>i<span class="token operator">*</span><span class="token number">77</span><span class="token punctuation">:</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">77</span><span class="token punctuation">]</span>        plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">'time'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>data<span class="token punctuation">[</span><span class="token string">'detrend_Hu0'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>color<span class="token operator">=</span><span class="token string">'blue'</span><span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        data <span class="token operator">=</span> df_rolled<span class="token punctuation">[</span>i<span class="token operator">*</span><span class="token number">77</span><span class="token punctuation">:</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">77</span><span class="token punctuation">]</span>        plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">'time'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>data<span class="token punctuation">[</span><span class="token string">'detrend_Hu0'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>color<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Hu_0'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>df_rolled<span class="token punctuation">[</span><span class="token string">'detrend_Hu0'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202205/Collective-anomaly-And-DBSCAN/8.36lgllzomlk0.jpg" width="60%/"></div>   ]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集体异常 </tag>
            
            <tag> 子序列聚类 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Windows7环境bat安装mariadb</title>
      <link href="/installing-mariadb-with-bat-in-windows-7-environment.html"/>
      <url>/installing-mariadb-with-bat-in-windows-7-environment.html</url>
      
        <content type="html"><![CDATA[<p>功能实现：编写bat批处理命令，在windows环境下，根据下载的安装包一键安装mariadb。</p><span id="more"></span> <ol><li><p>准备<a class="link" href="https://mariadb.org/download/?t=mariadb&amp;o=true&amp;p=mariadb&amp;r=10.5.4&amp;os=windows&amp;cpu=x86&amp;pkg=zip">mariadb安装包<i class="fas fa-external-link-alt"></i></a></p></li><li><p>解压，在解压后的文件中添加data文件夹。(因为最终目标是将所有要安装的东西打个包，实现一键安装，所以一些不需要后续改动的操作就直接手动完成了。当然，也可以使用bat命令解压再添加文件夹，我试过，完全可以的。前置条件是要先安装一个解压软件，windows7没有解压软件，也就是先静默安装360解压，再继续往下走。)</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202204/Characteristic-Engineering-of-Time-Series/1.68rotst9k800.jpg" width="60%/"></div>  </li><li><p>配置环境变量。配置成功后可在环境变量path中查看是否存在。</p><pre><code>:: 此处将cds设置为bat文件所在绝对路径set cds=%~dp0set cdsset mpth=mariadb:: mysql_path为mariadb解压后的路径（此处bat文件和解压文件在同级目录，解压文件名为mariadb）set mysql_path=%cds%%mpth%echo.:: %引用变量echo 安装路径：%mysql_path%echo.pauseecho 配置环境变量echo.::setx设置环境变量  setx "变量名" "变量值"setx PATH "%path%;%mysql_path%\bin"IF ERRORLEVEL 1 (echo.echo 配置环境变量失败，即将退出echo.goto END)set %path%;%mysql_path%\binecho 环境配置成功pause:ENDpause</code></pre></li><li><p>mariadb安装与注册服务。(注意：第二条注册服务命令为<strong>mysqld</strong>别搞错了，血的教训)。注册成功会有success提示。</p><pre><code>mysql_install_db.exepause:: 在前面安装后会在创建的data文件夹中存在my.ini文件，mariadb为创建服务的名称mysqld -install mariadb --default-file=”my.ini文件的路径“pause</code></pre></li><li><p>注册表修改。在注册服务后，查看服务中的可执行文件路径，会发现执行路径是默认的c盘内的Program Files内的mysqld执行程序，如果你就装在相应路径里，可以不用修改。如果不一致，则需要改成对应的执行程序的路径，也就是一开始解压的文件bin目录里的mysqld程序。(注册表的路径都是一样的，不同的是最后的命名为前面创建服务时的命名，要修改的仅有ImagePath的值)<br>```<br>echo 修改注册表</p></li></ol><p>::reg add 注册表路径 /v 值名 /t 要修改的数值类型 /d 想要输入的数据 /f</p><p>reg add “HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\services\mariadb” /v ImagePath /t REG_EXPAND_SZ /d “"C:\XFTP\mariadb\bin\mysqld" –defaults-file=C:\XFTP\mariadb\data mariadb” /f</p><p>echo 修改注册表完成<br>pause</p><pre><code>6. 启动mariadb服务，并登录进入。默认无密码，直接回车就可进入。</code></pre><p>net start mariadb<br>mariadb -uroot -p</p><p>```<br>7. 数据库备份与恢复。（这部分为初始化数据库，先从模板中导出数据，再应用到其他新建的数据库中，还未完成）</p>]]></content>
      
      
      <categories>
          
          <category> 安装与环境配置 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mariadb </tag>
            
            <tag> bat批处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>时间序列特征工程</title>
      <link href="/characteristic-engineering-of-time-series.html"/>
      <url>/characteristic-engineering-of-time-series.html</url>
      
        <content type="html"><![CDATA[<p>完成数据清洗之后，需要提取有意义的样本特征输入模型中训练，目的是为了更高效的利用算法。提取特征的步骤叫特征工程，分为三步：特征提取、特征预处理、特征降维。下面将针对时序序列的特征工程进行讲述。</p><span id="more"></span><h1 id="1-特征提取"><a href="#1-特征提取" class="headerlink" title="1. 特征提取"></a>1. 特征提取</h1><p>提取时间序列的特征可以从三方面着手。</p><h2 id="1-1-从时间中提取特征"><a href="#1-1-从时间中提取特征" class="headerlink" title="1.1 从时间中提取特征"></a>1.1 从时间中提取特征</h2><p>每条样本数据对应的时间数据包含很多信息，可以从中发现时间上的一些规律特征。<br>提取时间特征可以对时间进行拆解，如2022.04.23 15:08:03，可以将其中年月日时分秒分别拆解为一列，或者以某个时间点为起点，计算经过的时间，如一天中的第几分钟，一年中的第几天或第几周等等。对于受季节、节假日影响的数据，也可以判断是否月初、月末、周末、公共假期、营业时间等等。<br><strong>举例程序实现：</strong></p><pre class=" language-python"><code class="language-python">df <span class="token operator">=</span> Month_data_1T<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span>df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">.</span>index<span class="token comment" spellcheck="true"># 年份</span>df<span class="token punctuation">[</span><span class="token string">'年'</span><span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>year<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 月份</span>df<span class="token punctuation">[</span><span class="token string">'月'</span><span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>month<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 日</span>df<span class="token punctuation">[</span><span class="token string">'日'</span><span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>day<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 小时</span>df<span class="token punctuation">[</span><span class="token string">'时'</span><span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>hour<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 分钟</span>df<span class="token punctuation">[</span><span class="token string">'分'</span><span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>minute<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 一天中的第几分钟</span>df<span class="token punctuation">[</span><span class="token string">'一天中的第几分钟'</span><span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>minute <span class="token operator">+</span> x<span class="token punctuation">.</span>hour<span class="token operator">*</span><span class="token number">60</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 星期几；</span>df<span class="token punctuation">[</span><span class="token string">'星期几'</span><span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>dayofweek<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 一年中的第几天</span>df<span class="token punctuation">[</span><span class="token string">'一年中的第几天'</span><span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>dayofyear<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># # 一年中的第几周</span><span class="token comment" spellcheck="true"># df['一年中的第几周']=df['时间'].apply(lambda x: x.week)</span><span class="token comment" spellcheck="true"># 一天中哪个时间段：凌晨、早晨、上午、中午、下午、傍晚、晚上、深夜；</span>period_dict <span class="token operator">=</span><span class="token punctuation">{</span>    <span class="token number">23</span><span class="token punctuation">:</span> <span class="token number">0x00</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span> <span class="token number">0x00</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span> <span class="token number">0x00</span><span class="token punctuation">,</span>    <span class="token number">2</span><span class="token punctuation">:</span> <span class="token number">0x01</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">:</span> <span class="token number">0x01</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">:</span> <span class="token number">0x01</span><span class="token punctuation">,</span>    <span class="token number">5</span><span class="token punctuation">:</span> <span class="token number">0x02</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">:</span> <span class="token number">0x02</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">:</span> <span class="token number">0x02</span><span class="token punctuation">,</span>    <span class="token number">8</span><span class="token punctuation">:</span> <span class="token number">0x03</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">:</span> <span class="token number">0x03</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">:</span> <span class="token number">0x03</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">:</span> <span class="token number">0x03</span><span class="token punctuation">,</span>    <span class="token number">12</span><span class="token punctuation">:</span> <span class="token number">0x04</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">:</span> <span class="token number">0x04</span><span class="token punctuation">,</span><span class="token number">14</span><span class="token punctuation">:</span> <span class="token number">0x04</span><span class="token punctuation">,</span>     <span class="token number">15</span><span class="token punctuation">:</span> <span class="token number">0x05</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">:</span> <span class="token number">0x05</span><span class="token punctuation">,</span> <span class="token number">17</span><span class="token punctuation">:</span> <span class="token number">0x05</span><span class="token punctuation">,</span><span class="token number">18</span><span class="token punctuation">:</span> <span class="token number">0x05</span><span class="token punctuation">,</span>    <span class="token number">19</span><span class="token punctuation">:</span> <span class="token number">0x07</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">:</span> <span class="token number">0x07</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">:</span> <span class="token number">0x07</span><span class="token punctuation">,</span> <span class="token number">22</span><span class="token punctuation">:</span> <span class="token number">0x07</span><span class="token punctuation">,</span><span class="token comment" spellcheck="true">#     23: '深夜', 0: '深夜', 1: '深夜',</span><span class="token comment" spellcheck="true">#     2: '凌晨', 3: '凌晨', 4: '凌晨',</span><span class="token comment" spellcheck="true">#     5: '早晨', 6: '早晨', 7: '早晨',</span><span class="token comment" spellcheck="true">#     8: '上午', 9: '上午', 10: '上午', 11: '上午',</span><span class="token comment" spellcheck="true">#     12: '中午', 13: '中午',14: '中午',</span><span class="token comment" spellcheck="true">#     15: '下午', 16: '下午', 17: '下午',18: '下午',</span><span class="token comment" spellcheck="true">#     19: '晚上', 20: '晚上', 21: '晚上', 22: '晚上',</span><span class="token punctuation">}</span>df<span class="token punctuation">[</span><span class="token string">'时间段'</span><span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">'时'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>period_dict<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># # 一年中的哪个季度</span><span class="token comment" spellcheck="true"># season_dict = {</span><span class="token comment" spellcheck="true">#     1: '春季', 2: '春季', 3: '春季',</span><span class="token comment" spellcheck="true">#     4: '夏季', 5: '夏季', 6: '夏季',</span><span class="token comment" spellcheck="true">#     7: '秋季', 8: '秋季', 9: '秋季',</span><span class="token comment" spellcheck="true">#     10: '冬季', 11: '冬季', 12: '冬季',</span><span class="token comment" spellcheck="true"># }</span><span class="token comment" spellcheck="true"># df['季节']=df['月'].map(season_dict)</span><span class="token comment" spellcheck="true"># # 是否闰年</span><span class="token comment" spellcheck="true"># df['是否闰年'] = df['时间'].apply(lambda x: x.is_leap_year)</span><span class="token comment" spellcheck="true"># 是否月初</span>df<span class="token punctuation">[</span><span class="token string">'是否月初'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>is_month_start<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 是否月末</span>df<span class="token punctuation">[</span><span class="token string">'是否月末'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>is_month_end<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 是否季节初</span><span class="token comment" spellcheck="true"># df['是否季节初'] = df['时间'].apply(lambda x: x.is_quarter_start)</span><span class="token comment" spellcheck="true"># 是否季节末</span><span class="token comment" spellcheck="true"># df['是否季节末'] = df['时间'].apply(lambda x: x.is_quarter_end)</span><span class="token comment" spellcheck="true"># 是否年初</span><span class="token comment" spellcheck="true"># df['是否年初'] = df['时间'].apply(lambda x: x.is_year_start)</span><span class="token comment" spellcheck="true"># 是否年尾</span><span class="token comment" spellcheck="true"># df['是否年尾'] = df['时间'].apply(lambda x: x.is_year_end)</span><span class="token comment" spellcheck="true"># 是否周末</span>df<span class="token punctuation">[</span><span class="token string">'是否周末'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token boolean">True</span> <span class="token keyword">if</span> x<span class="token punctuation">.</span>dayofweek <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span> <span class="token keyword">else</span> <span class="token boolean">False</span><span class="token punctuation">)</span>df</code></pre><p>结果如下图所示：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202204/Characteristic-Engineering-of-Time-Series/时间特征.407xag8uznw0.jpg"></div> <h2 id="1-2-从时序规律中提取特征"><a href="#1-2-从时序规律中提取特征" class="headerlink" title="1.2 从时序规律中提取特征"></a>1.2 从时序规律中提取特征</h2><p>在数据清洗后的数据分析中，通常会分析时间序列的一些特性，如周期性、时间序列分解、历史数据，可以把这些分析出来的数据用作特征。<br>**举例程序实现： **</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> statsmodels<span class="token punctuation">.</span>tsa<span class="token punctuation">.</span>seasonal <span class="token keyword">import</span> seasonal_decompose<span class="token comment" spellcheck="true"># 数据含有两个周期77和1440</span><span class="token comment" spellcheck="true"># 偏移6min差分</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_-5S"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'Hu_0'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shift<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 偏移77min差分，一小周期</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_-1period"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'Hu_0'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shift<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">*</span><span class="token number">77</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 偏移两小周期</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_-2period"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'Hu_0'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shift<span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span><span class="token number">77</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 偏移1天，一大周期</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_-1day"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'Hu_0'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shift<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">*</span><span class="token number">1440</span><span class="token punctuation">)</span>decompose_result <span class="token operator">=</span> seasonal_decompose<span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">'Hu_0'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"additive"</span><span class="token punctuation">,</span> period<span class="token operator">=</span><span class="token number">77</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 分离77周期分离</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_77seasonal"</span><span class="token punctuation">]</span> <span class="token operator">=</span> decompose_result<span class="token punctuation">.</span>seasonaldecompose_result <span class="token operator">=</span> seasonal_decompose<span class="token punctuation">(</span>decompose_result<span class="token punctuation">.</span>seasonal<span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"additive"</span><span class="token punctuation">,</span> period<span class="token operator">=</span><span class="token number">1440</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 分离1440周期分量</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_1440seasonal"</span><span class="token punctuation">]</span> <span class="token operator">=</span> decompose_result<span class="token punctuation">.</span>seasonal<span class="token comment" spellcheck="true"># 趋势分量</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_trend"</span><span class="token punctuation">]</span> <span class="token operator">=</span> decompose_result<span class="token punctuation">.</span>trend<span class="token comment" spellcheck="true"># 残差分量</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_resid"</span><span class="token punctuation">]</span> <span class="token operator">=</span> decompose_result<span class="token punctuation">.</span>residdf</code></pre><p><img lazyload="" src="/images/loading.svg" data-src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202204/Characteristic-Engineering-of-Time-Series/%E6%97%B6%E5%BA%8F%E8%A7%84%E5%BE%8B%E7%89%B9%E5%BE%81.5n1vvk2y3d40.jpg" alt="时序规律特征"></p><h2 id="1-3-从统计窗口提取特征"><a href="#1-3-从统计窗口提取特征" class="headerlink" title="1.3 从统计窗口提取特征"></a>1.3 从统计窗口提取特征</h2><p>要想提取时间序列的统计特征，需要按固定时间长度把一条时间序列划分为n多条子序列，然后对这些子序列分别构造统计特征。<br>**举例程序实现： **</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># sum() 值的总和</span><span class="token comment" spellcheck="true"># mean() 均值</span><span class="token comment" spellcheck="true"># median() 值的算术中值</span><span class="token comment" spellcheck="true"># min() 最小值</span><span class="token comment" spellcheck="true"># max() 最大</span><span class="token comment" spellcheck="true"># std() 贝塞尔修正样本标准差(均方差)</span><span class="token comment" spellcheck="true"># var() 无偏方差</span><span class="token comment" spellcheck="true"># cov() 无偏协方差（二元）</span><span class="token comment" spellcheck="true"># corr() 相关（二进制）</span><span class="token comment" spellcheck="true"># variation_v = std_v/mean_v 离散系数</span><span class="token comment" spellcheck="true"># polyfit 线性拟合，求斜率</span><span class="token comment" spellcheck="true">#使用rolling滚动窗口，窗口大小为7</span>roll_data <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'Hu_0'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>rolling<span class="token punctuation">(</span>window<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">)</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_mean"</span><span class="token punctuation">]</span> <span class="token operator">=</span> roll_data<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_median"</span><span class="token punctuation">]</span> <span class="token operator">=</span> roll_data<span class="token punctuation">.</span>median<span class="token punctuation">(</span><span class="token punctuation">)</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_min"</span><span class="token punctuation">]</span> <span class="token operator">=</span> roll_data<span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token punctuation">)</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_max"</span><span class="token punctuation">]</span> <span class="token operator">=</span> roll_data<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_std"</span><span class="token punctuation">]</span> <span class="token operator">=</span> roll_data<span class="token punctuation">.</span>std<span class="token punctuation">(</span><span class="token punctuation">)</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_var"</span><span class="token punctuation">]</span> <span class="token operator">=</span> roll_data<span class="token punctuation">.</span>var<span class="token punctuation">(</span><span class="token punctuation">)</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_cov"</span><span class="token punctuation">]</span> <span class="token operator">=</span> roll_data<span class="token punctuation">.</span>cov<span class="token punctuation">(</span><span class="token punctuation">)</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_corr"</span><span class="token punctuation">]</span> <span class="token operator">=</span> roll_data<span class="token punctuation">.</span>corr<span class="token punctuation">(</span><span class="token punctuation">)</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_variation"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">"Hu0_std"</span><span class="token punctuation">]</span><span class="token operator">/</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_mean"</span><span class="token punctuation">]</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_sum"</span><span class="token punctuation">]</span> <span class="token operator">=</span> roll_data<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_sum_diff2"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">"Hu0_sum"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shift<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">-</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_sum"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shift<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># df["Hu0_autocorr1"] = df["Hu_0"].autocorr(1)</span><span class="token comment" spellcheck="true"># df["Hu0_autocorr2"] = df["Hu_0"].autocorr(2)</span>x <span class="token operator">=</span> range<span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">)</span>z <span class="token operator">=</span> <span class="token keyword">lambda</span> y <span class="token punctuation">:</span> np<span class="token punctuation">.</span>polyfit<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_polyfit"</span><span class="token punctuation">]</span> <span class="token operator">=</span> roll_data<span class="token punctuation">.</span>apply<span class="token punctuation">(</span>z<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 一阶差分的均方差</span>roll_data_diff <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'Hu_0'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>diff<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>rolling<span class="token punctuation">(</span>window<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">)</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_diff_std"</span><span class="token punctuation">]</span> <span class="token operator">=</span> roll_data_diff<span class="token punctuation">.</span>std<span class="token punctuation">(</span><span class="token punctuation">)</span>df</code></pre><p><img lazyload="" src="/images/loading.svg" data-src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202204/Characteristic-Engineering-of-Time-Series/%E7%BB%9F%E8%AE%A1%E7%89%B9%E5%BE%81.6ahmg2mw8s00.jpg" alt="统计特征"></p><h1 id="2-特征预处理"><a href="#2-特征预处理" class="headerlink" title="2. 特征预处理"></a>2. 特征预处理</h1><p>特征预处理是对提取出来的特征无量纲化，目的是让特征处于同等地位，避免特征之间差异太大而影响模型学习效果。常用的处理手段有两种：归一化和标准化。归一化是将原数据映射到[m,n]（通常为[0,1]）内，但当数据异常点较多时，容易影响归一化结果，适合小样本。标准化是将数据变换为均值为0，标准差为1的范围内。而平均值和标准差受异常值影响较小，能克服归一化的缺点。此处使用标准化进行举例。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScalerscaler <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#因为上式返回结果为series，这里将其转换为表格形式。</span>df_Standar <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>scaler<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">,</span>index<span class="token operator">=</span>df<span class="token punctuation">.</span>index<span class="token punctuation">,</span> columns<span class="token operator">=</span>df<span class="token punctuation">.</span>columns<span class="token punctuation">)</span>df_Standar</code></pre><h1 id="3-特征降维"><a href="#3-特征降维" class="headerlink" title="3. 特征降维"></a>3. 特征降维</h1><p>特征降维指的是对提取出来的特征进行过滤筛选，减少特征维度。目的是为了降低学习任务的难度和减轻维度灾难问题。<br>通常，从两个方面考虑来选择特征：</p><ol><li>特征是否发散<br>如果一个特征不发散，例如方差接近于0，也就是说样本在这个特征上基本上没有差异，这个特征对于样本的区分并没有什么用。</li><li>特征与目标的相关性<br>与目标相关性高的特征，应当优先选择。<br>区别：特征与特征之间相关性高的，应当优先去除掉其中一个特征，因为它们是替代品。<br>特征选择方法有：Filter过滤法、Wrapper包装法和Embedded嵌入法。其中第二三种方法都适合于有监督学习，需要与目标值关联进行特征选择。因为原数据是为异常检测，没有标签，属于无监督学习，这里仅举例过滤法。<br>通过筛选小方差和强相关特征来达到过滤特征的目的。<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 特征过滤 filter</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_selection <span class="token keyword">import</span> VarianceThreshold  X_train_columns <span class="token operator">=</span> df_Standar<span class="token punctuation">.</span>columns<span class="token comment" spellcheck="true">#方差过滤，返回方差大于设定阈值的列</span>selector <span class="token operator">=</span> VarianceThreshold<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span>X <span class="token operator">=</span> selector<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>df_Standar<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#因为上式返回结果为series，这里将其转换为表格形式。</span><span class="token comment" spellcheck="true">#X_train_columns[selector.get_support(indices=True)]结果为筛选后的列名</span>df_filter <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>X<span class="token punctuation">,</span>index<span class="token operator">=</span>df_concat<span class="token punctuation">.</span>index<span class="token punctuation">,</span> columns<span class="token operator">=</span>X_train_columns<span class="token punctuation">[</span>selector<span class="token punctuation">.</span>get_support<span class="token punctuation">(</span>indices<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>df_filter</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 特征过滤 相关系数corr</span><span class="token comment" spellcheck="true"># 剔除相关性系数高于threshold的corr_drop</span>corr_df <span class="token operator">=</span> df_filter<span class="token punctuation">.</span>corr<span class="token punctuation">(</span><span class="token punctuation">)</span>threshold <span class="token operator">=</span> <span class="token number">0.9</span><span class="token comment" spellcheck="true">#k=1,返回上三角矩阵</span>upper <span class="token operator">=</span> corr_df<span class="token punctuation">.</span>where<span class="token punctuation">(</span>np<span class="token punctuation">.</span>triu<span class="token punctuation">(</span>np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>corr_df<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>bool<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#返回相关系数大于阈值的列名</span>corr_drop <span class="token operator">=</span> <span class="token punctuation">[</span>column <span class="token keyword">for</span> column <span class="token keyword">in</span> upper<span class="token punctuation">.</span>columns <span class="token keyword">if</span> any<span class="token punctuation">(</span>upper<span class="token punctuation">[</span>column<span class="token punctuation">]</span><span class="token punctuation">.</span>abs<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> threshold<span class="token punctuation">)</span><span class="token punctuation">]</span>df_filter <span class="token operator">=</span> df_filter<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>corr_drop<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>df_filter</code></pre><h1 id="4-Tsfresh特征提取工具"><a href="#4-Tsfresh特征提取工具" class="headerlink" title="4. Tsfresh特征提取工具"></a>4. Tsfresh特征提取工具</h1>最后讲一个用于时间序列特征提取的工具<a class="link" href="https://tsfresh.readthedocs.io/en/latest/index.html">tsfresh<i class="fas fa-external-link-alt"></i></a><br>工具介绍就不讲了，直接说一下用法。对于一条长时间序列，要想利用tsfresh工具提取特征，还需要先将其化为一个个子窗口序列。该工具包内就包含这个功能。原表结构为：<br><img lazyload="" src="/images/loading.svg" data-src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202204/Characteristic-Engineering-of-Time-Series/%E6%BB%9A%E5%8A%A8%E7%AA%97%E5%8F%A3%E5%8E%9F%E8%A1%A8%E7%BB%93%E6%9E%84.119hmuad0jy8.jpg" alt="滚动窗口原表结构"></li></ol><p>其中id,time列是在原表的基础上后加上的，目的是为了方便使用API接口函数。id代表组别，time代表时间顺序。然后使用API转换为窗口子序列。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> tsfresh<span class="token punctuation">.</span>utilities<span class="token punctuation">.</span>dataframe_functions <span class="token keyword">import</span> roll_time_series<span class="token comment" spellcheck="true"># 滚动窗口</span><span class="token comment" spellcheck="true">#max_timeshift:最大偏移量，min_timeshift：最小偏移量，rolling_direction：每次移动的大小和方向。column_sort按什么排序，默认已从小到大排好</span>df_rolled <span class="token operator">=</span> roll_time_series<span class="token punctuation">(</span>one_data<span class="token punctuation">,</span> column_id<span class="token operator">=</span><span class="token string">"id"</span><span class="token punctuation">,</span> column_sort<span class="token operator">=</span><span class="token string">"time"</span><span class="token punctuation">,</span>max_timeshift <span class="token operator">=</span> <span class="token number">6</span> <span class="token punctuation">,</span>min_timeshift <span class="token operator">=</span> <span class="token number">6</span><span class="token punctuation">,</span>rolling_direction<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>df_rolled</code></pre><p><img lazyload="" src="/images/loading.svg" data-src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202204/Characteristic-Engineering-of-Time-Series/tsfresh%E7%AA%97%E5%8F%A3%E5%BA%8F%E5%88%97.4f2dy005fr40.jpg" alt="tsfresh窗口序列"><br>转化后的id是原id与原时间的组合，也为后面特征提取中的组别。（1，1）代表1号组别的第一个时间点组成的子序列，（1，43316）代表1号组别第43316个点组成的子序列。然后再进行特征提取.</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> tsfresh <span class="token keyword">import</span> extract_features<span class="token comment" spellcheck="true"># 特征提取,使用drop先删去多余的列，column_id为组别</span>df_features <span class="token operator">=</span> extract_features<span class="token punctuation">(</span>df_rolled<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"date"</span><span class="token punctuation">,</span><span class="token string">"time"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> column_id<span class="token operator">=</span><span class="token string">"id"</span><span class="token punctuation">)</span>df_features</code></pre><p>以上即为tsfresh特征提取的步骤，其内置的特征过滤函数因需要目标值而不适用我的数据，所以后续特征降维仍使用上述过滤法进行选择。</p><blockquote><p>参考网站：<br><a class="link" href="https://cloud.tencent.com/developer/article/1536537">特征工程系列：时间特征构造以及时间序列特征构造<i class="fas fa-external-link-alt"></i></a><br><a class="link" href="https://www.heywhale.com/mw/project/5d86eced8499bc002c108cc8">特征工程理论与代码实现特征工程理论与代码实现<i class="fas fa-external-link-alt"></i></a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 时间序列 </tag>
            
            <tag> 特征工程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>centos7安装QT及环境配置</title>
      <link href="/centos7-an-zhuang-qt-ji-huan-jing-pei-zhi.html"/>
      <url>/centos7-an-zhuang-qt-ji-huan-jing-pei-zhi.html</url>
      
        <content type="html"><![CDATA[<ol><li><p>正常下载安装QT</p></li><li><p>打开QT，打开工具-&gt;选项-&gt;Kits，手动添加一个kit(不懂为啥自动检测出来的都不好使，我就全部都手动添加了)，名称和自动的一样就好。</p><span id="more"></span>  <div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/centos7安装QT及环境配置/10.4dpjrrcig4g0.jpg" width="60%/"></div>  </li><li><p>首先设置QT versions,手动添加qmake，路劲就是你安装QT的地方，和自动检测出来的一样，设置完点击Apply。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/centos7安装QT及环境配置/1.5d7pkq3aynw0.jpg" width="60%/"></div> </li><li><p>然后是添加编译器，这个比较麻烦，需要安装gcc，下面具体说一下操作步骤。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/centos7安装QT及环境配置/2.1zgz8yzam9a8.jpg" width="60%/"></div></li></ol><ul><li><p>回到centos界面，打开终端，执行命令 gcc -v，查看是否已经安装gcc,我这里已经安装过了，用的yum自动给我下的，centos7下载的就是这个4.8.5版本的,但这个版本有问题，不支持c++11，所以还需要换更高些的版本。（没下载的话别用yum下，要么自己找高版本下，要么看我后面）</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/centos7安装QT及环境配置/3.uxn6sxffcn4.jpg" width="60%/"></div> </li><li><p>gcc升级这步骤浪费了我很多时间，但搞完回头一看，其实步骤很简单。首先一定要看看有没有网，ping一下看看，虚拟机联网百度一下，这里有个问题是试过百度方法后依然不行，service network start命令无法启动，然后看到了一个大佬的评论，设置一下IP地址就好了，命令是：dhclient ens33，这里的ens33是自己网卡名字，前面设置联网的过程应该有看到过，自己更改就可以了。有网之后分别执行下面三条命令：</p><pre><code>sudo yum install centos-release-sclsudo yum install devtoolset-8-gcc*scl enable devtoolset-8 bash</code></pre><blockquote><p>这里可以自己选择版本，利用centos-release-scl工具，让你不需要重写编译gcc，能同时保留多个版本的gcc，你需要哪个版本enable一下。执行完后再看一下版本是否更新了。用这个工具缺点是重新启动需要再次enable，可以设置开机自启动，我还没设置，因为QT里不需要，设置一下路径就Ok了。开机启动命令是“ echo “source /opt/rh/devtoolset-9/enable” &gt;&gt; /etc/profile ”，我还没试，不懂行不行。</p></blockquote></li><li><p>查看gcc的路径</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/centos7安装QT及环境配置/4.7c8mgb783300.jpg" width="60%/"></div></li></ul><ol start="5"><li>打开QT里的编译器设置，手动添加gcc,路径就是你前面查找的，具体就是下面两张图。设置完后点应用。<div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/centos7安装QT及环境配置/5.4l9lse48f7c0.jpg" width="60%/"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/centos7安装QT及环境配置/6.2p6xnaktsni0.jpg" width="60%/"></div></li><li>回到kit，设置一下compiler和QT version，然后点击Apply。<div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/centos7安装QT及环境配置/7.72ch9al9tvc0.jpg" width="60%/"></div></li><li>这时候可以打开一个例子试试，build一下，发现还是有问题，报错“ cannot find -lGL”；<div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/centos7安装QT及环境配置/8.3wp797r848m0.jpg" width="60%/"></div>原因在于QT寻找的libGL路径和centos自带的libGL路径不一致，且名称有点区别，所以需要加一个软链接。输入命令：locate libGL ，查看系统libGL的路径和名称，这里选第一个libGL.so.1。<div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/centos7安装QT及环境配置/9.7jiqgedk3000.jpg" width="60%/"></div>创建链接：# ln -s /usr/lib64/libGL.so.1 /usr/lib/libGL.so 需要root权限，可使用sudo su命令进入root。创建成功后再次build，发现成功啦。</li></ol><p>这就是centos7安装QT的全过程了。因为第一次用linux系统，安装个QT就浪费我两天，不停试错，心累，于是搞好后赶忙在这记录一下，留待备用。</p><p>备注：这里还有一个问题是：设置好的kit会有警告：the abi of selected debugger does not match the toolchain abi，是关于debugger的，这是因为自带的gdb版本低了，换个高些的版本就ok了。</p>]]></content>
      
      
      <categories>
          
          <category> 安装与环境配置 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> QT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>时序数据异常检测流程与项目实战</title>
      <link href="/anomaly-detection-process.html"/>
      <url>/anomaly-detection-process.html</url>
      
        <content type="html"><![CDATA[<p>本文主要内容为对时序数据异常检测流程进行简单介绍，然后通过项目实战进行详细解释。全文内容根据个人实际经验所得。</p><h1 id="1-总体流程介绍"><a href="#1-总体流程介绍" class="headerlink" title="1.总体流程介绍"></a>1.总体流程介绍</h1><p>针对项目中传感器数据异常检测，经调研后，个人初步总结工程上实现异常检测的流程。流程框图如下图所示：<br> <span id="more"></span>  </p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Anomaly_detection_process.6l6blsl243s0.jpg" width="60%/"></div>  <p>总体步骤有五步：  </p><ol><li>数据清洗：对数据做初步处理，方便后续的数据分析。包括时间戳的转换（因为是时序数据，需要对时间列做专门处理）、数据重采样（修改时间频率）、缺失值处理、异常值处理、数据平滑处理</li><li>探索性数据分析EDA：通过作图、制表、方程拟合、计算特征量等手段探索数据的结构和规律的一种数据分析方法。主要是利用各种方式自由探索数据分布、数据相关性等。分析后决定检测哪种类型的异常。</li><li>特征提取/相关性分析：对于单维序列，因为缺乏可用特征，需要进行特征提取，以便后续训练模型，时序序列中比较重要的特征是周比环比。对于多维序列，需要先进行相关性分析，剔除相关性强的数据。要根据检测的异常类型，实施特征提取方案。</li><li>训练模型：对数据分析后选择合适的算法进行建模，用提取出的特征或若相关数据进行模型训练。</li><li>异常检测：利用训练好的模型检测实际数据。单维常用算法有LSTM + Vae，通过预测的方式检测异常；多维可利用孤立森林、SVM、kmeans等。</li></ol><h1 id="2-项目实战"><a href="#2-项目实战" class="headerlink" title="2.项目实战"></a>2.项目实战</h1><p>利用工具：jupyter notebook; 语言：python</p><h2 id="2-1-数据清洗"><a href="#2-1-数据清洗" class="headerlink" title="2.1 数据清洗"></a>2.1 数据清洗</h2><p>实现目标：提取csv文件数据，处理缺失值、异常值、数据平滑化，完成数据清洗。<br>首先加载必要库:</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np <span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd <span class="token keyword">import</span> random <span class="token keyword">as</span> rd <span class="token keyword">import</span> datetime <span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt <span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>dates <span class="token keyword">as</span> mdate<span class="token keyword">from</span> statsmodels<span class="token punctuation">.</span>tsa<span class="token punctuation">.</span>seasonal <span class="token keyword">import</span> seasonal_decompose<span class="token keyword">from</span> statsmodels<span class="token punctuation">.</span>graphics<span class="token punctuation">.</span>tsaplots <span class="token keyword">import</span> plot_acf<span class="token keyword">from</span> statsmodels<span class="token punctuation">.</span>graphics<span class="token punctuation">.</span>tsaplots <span class="token keyword">import</span> plot_pacf<span class="token keyword">import</span> seaborn <span class="token keyword">as</span> sns<span class="token keyword">from</span> statsmodels<span class="token punctuation">.</span>tsa<span class="token punctuation">.</span>stattools <span class="token keyword">import</span> adfuller<span class="token keyword">from</span> scipy <span class="token keyword">import</span> signal<span class="token keyword">import</span> warningswarnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">"ignore"</span><span class="token punctuation">)</span></code></pre><p>提取csv文件,利用pd.read_csv()函数可完整提取表中全部内容，函数有很多参数可以选择，实现众多功能</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#读取表格数据</span>data1 <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./data/componet.csv'</span><span class="token punctuation">)</span>data2 <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./data/tehu.csv'</span><span class="token punctuation">)</span>data1 <span class="token comment" spellcheck="true">#展示data1中数据</span></code></pre><p>表格数据如图所示：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet.4mjopka34v80.jpg" width="60%/"></div>  <p>查询表中是否有缺失值，使用.isnull()查询，返回含有缺失值的行。我的数据没有缺失值，表为空，就不展示了。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 查看缺失值</span>pivot_data<span class="token punctuation">[</span>pivot_data<span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T<span class="token punctuation">.</span>any<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span></code></pre><p>将data1中时间列数据设置为索引，方便查询，也方便可视化</p><pre class=" language-python"><code class="language-python">data1<span class="token punctuation">.</span>index <span class="token operator">=</span> pd<span class="token punctuation">.</span>to_datetime<span class="token punctuation">(</span>data1<span class="token punctuation">.</span>Datetime<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#设置时间列为索引</span>data1</code></pre><p>设置完后数据：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_index.78rh4tnfar00.jpg" width="60%/"></div>  <p>先对未处理的数据进行可视化，看看数据形态：</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#可视化</span><span class="token keyword">for</span> c_disc <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'Comp0_Te'</span><span class="token punctuation">,</span><span class="token string">'Comp1_Te'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    t_disc <span class="token operator">=</span> tmp_data1<span class="token punctuation">[</span>c_disc<span class="token punctuation">]</span>    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>c_disc<span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span>c_disc<span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>gca<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>xaxis<span class="token punctuation">.</span>set_major_formatter<span class="token punctuation">(</span>mdate<span class="token punctuation">.</span>DateFormatter<span class="token punctuation">(</span><span class="token string">'%Y-%m-%d'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#设置x轴显示格式</span>    <span class="token comment" spellcheck="true">#设置x轴显示范围，freq代表间隔频率，tmp_data1.index[0]代表起始时间,tmp_data1.index[-1]代表结束时间</span>    plt<span class="token punctuation">.</span>xticks<span class="token punctuation">(</span>pd<span class="token punctuation">.</span>date_range<span class="token punctuation">(</span>tmp_data1<span class="token punctuation">.</span>index<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>tmp_data1<span class="token punctuation">.</span>index<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>freq<span class="token operator">=</span><span class="token string">'D'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>rotation<span class="token operator">=</span><span class="token number">45</span><span class="token punctuation">)</span>     plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>t_disc<span class="token punctuation">)</span></code></pre><p>其中一个曲线示意图：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_plot.4833uxky2zg0.jpg" width="100%/"></div> <p>可以看出，数据有明显的异常点，要么很大，要么很小。为了后面的数据分析与模型训练，我们所以需要对这些明显的异常点进行简单处理。处理方式为使用箱型图，筛选出异常点，然后用前值进行替换。 在此之前，我们先对时间索引进行处理。在这里，我的数据采样间隔大致为2s，但并不固定。因此，在尽可能不影响原数据的情况下，将重采样间隔设置为2S，只做规范时间频率使用。使用resample()函数处理。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#重采样 </span>tmp_data1 <span class="token operator">=</span> data1<span class="token punctuation">.</span>resample<span class="token punctuation">(</span><span class="token string">'2S'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#时间间隔取2S，mean()取平均值,用tmp_data1接收转换后的表，不改变原表内容</span>tmp_data1</code></pre><p>重采样后的数据：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_resample.tfaifs2cgrk.jpg" width="100%/"></div>  <p>可以看出，数据时间间隔已变为2S等距，且值也有所变化，因为非等距时间间隔，不可避免地出现了缺失值。因此下一步对缺失值进行<strong>填补</strong>。填补策略为：对短时间缺失数据填补，长时间缺失数据删除。填补使用缺失点前7个历史数据的均值填补，以是否连续缺失十个点判断是否是长时间缺失数据。这里自己写了个填补函数用于实现上面的功能。（对于几百万的数据量，填补时间很长，有一两小时）</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">nmeans_fill_missing</span><span class="token punctuation">(</span>fill_col<span class="token punctuation">,</span> df <span class="token punctuation">,</span> window<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> time_range <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">'''        实现功能： 对表格中的某一列的缺失值进行填补，使用邻近历史数据的均值填补，对于大范围缺失点，不进行填补，可对均值窗口、缺失时间范围进行设置        fill_col: 选择插值的列，可填名字，也可填index        df: DataFrame,输入需要插值的表        window: 插值窗口大小        time_range: 设置判断长时间间隔的点数        '''</span>        <span class="token comment" spellcheck="true"># count记录起始位置，每当遇到长间隔空值点，会将count移动到下一个非空值点</span>        count <span class="token operator">=</span> <span class="token number">0</span>        i<span class="token operator">=</span><span class="token number">0</span>        <span class="token keyword">while</span> i <span class="token operator">&lt;</span> len<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># count += 1</span>            value <span class="token operator">=</span> np<span class="token punctuation">.</span>isnan<span class="token punctuation">(</span>df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">#判断当前值是否为空</span>            <span class="token keyword">if</span> value <span class="token operator">==</span> <span class="token boolean">True</span><span class="token punctuation">:</span>                <span class="token comment" spellcheck="true"># 判断当前空值点是否是长间隔</span>                islonginterval <span class="token operator">=</span> islong_missing<span class="token punctuation">(</span>fill_col<span class="token punctuation">,</span> df <span class="token punctuation">,</span> range_window<span class="token operator">=</span>time_range<span class="token punctuation">,</span> row_index<span class="token operator">=</span>i<span class="token punctuation">)</span>                <span class="token comment" spellcheck="true">#当遇到长间隔空值时，将count一直移动到下一个非空点</span>                <span class="token keyword">if</span> islonginterval<span class="token punctuation">:</span>                    i <span class="token operator">+=</span> time_range                    <span class="token keyword">while</span> value <span class="token operator">==</span><span class="token boolean">True</span> <span class="token operator">and</span> i<span class="token operator">&lt;</span>len<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">:</span>                        value <span class="token operator">=</span> np<span class="token punctuation">.</span>isnan<span class="token punctuation">(</span>df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>                        i <span class="token operator">+=</span><span class="token number">1</span>                    count <span class="token operator">=</span> i                   <span class="token keyword">else</span><span class="token punctuation">:</span>                      <span class="token keyword">if</span> i <span class="token operator">-</span> count <span class="token operator">&lt;=</span> window<span class="token punctuation">:</span>         <span class="token comment" spellcheck="true">#判断当前位置是否有足够历史数据进行插值</span>                        <span class="token keyword">if</span> i<span class="token operator">+</span>window<span class="token operator">>=</span>len<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token comment" spellcheck="true">#如果已经到了表格末尾，后续数据不够进行填补，直接略过剩下的点。该策略仅针对数据量足够大的情况</span>                            <span class="token keyword">break</span>                        train_value_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>   <span class="token comment" spellcheck="true">#用于当历史数据不够的情况存放窗口内的点，如 [1,2,3,current:NAN,5,6,7]  此时历史数据不够，则取从1开始的7个点，掠过略过空值</span>                        <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>window<span class="token punctuation">)</span><span class="token punctuation">:</span>                            train_value <span class="token operator">=</span> np<span class="token punctuation">.</span>isnan<span class="token punctuation">(</span>df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>j<span class="token operator">+</span>count<span class="token punctuation">]</span><span class="token punctuation">)</span>                             <span class="token keyword">if</span> train_value <span class="token operator">==</span> <span class="token boolean">False</span><span class="token punctuation">:</span>                                train_value_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>j<span class="token operator">+</span>count<span class="token punctuation">]</span><span class="token punctuation">)</span>                        df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>train_value_list<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>                    <span class="token keyword">else</span><span class="token punctuation">:</span>                        df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">[</span>i <span class="token operator">-</span> window<span class="token punctuation">:</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#如果窗口大小满足，取前window内的均值填补</span>            i <span class="token operator">+=</span><span class="token number">1</span>        <span class="token keyword">return</span> df<span class="token comment" spellcheck="true"># 判断当前空值点是否是长间隔</span><span class="token keyword">def</span> <span class="token function">islong_missing</span><span class="token punctuation">(</span>fill_col<span class="token punctuation">,</span> df <span class="token punctuation">,</span> range_window<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> row_index<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">'''        判断当前空值点是否是长间隔        df: DataFrame,输入需要插值的表          window:插值窗口大小        range_window: 设置判断长时间间隔的点数        fill_col: 选择插值的列,可填名字.也可填index        row_index: 开始判断的起始索引        '''</span>        islonginterval <span class="token operator">=</span> <span class="token boolean">True</span>    <span class="token comment" spellcheck="true">#判断当前空值是否属于长时间范围内的空值，是的话就跳过，不进行插值填补</span>        count <span class="token operator">=</span> <span class="token number">1</span>        <span class="token comment" spellcheck="true"># 判断逻辑：判断后续十个时间点是否为空，当存在一个非空点，即跳出循环，且islonginterval为false</span>        <span class="token keyword">while</span> row_index<span class="token operator">+</span>count<span class="token operator">&lt;</span>len<span class="token punctuation">(</span>df<span class="token punctuation">)</span> <span class="token operator">and</span> islonginterval<span class="token operator">==</span><span class="token boolean">True</span> <span class="token operator">and</span> count<span class="token operator">&lt;=</span>range_window<span class="token punctuation">:</span>            islonginterval <span class="token operator">=</span> np<span class="token punctuation">.</span>isnan<span class="token punctuation">(</span>df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>row_index<span class="token operator">+</span>count<span class="token punctuation">]</span><span class="token punctuation">)</span>            count <span class="token operator">+=</span><span class="token number">1</span>        <span class="token keyword">return</span> islonginterval<span class="token comment" spellcheck="true">#对两列分别填补</span><span class="token keyword">for</span> c_disc <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'Comp0_Te'</span><span class="token punctuation">,</span><span class="token string">'Comp1_Te'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    tmp_data1 <span class="token operator">=</span> nmeans_fill_missing<span class="token punctuation">(</span>c_disc<span class="token punctuation">,</span> tmp_data1<span class="token punctuation">,</span> window<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">)</span>tmp_data1</code></pre><p>为了检验填补效果，又写了个子函数，用来获取每次检测到的长间隔时间端的开始时间和结束时间对于的行数。根据返回的结果，查询对应的时间信息，判断是否满足填补策略</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">find_long_missing</span><span class="token punctuation">(</span>fill_col<span class="token punctuation">,</span> df <span class="token punctuation">,</span> time_range <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">'''        实现功能： 获取长间隔断点的点信息，返回dot_list数组，每两个为一对时间段        fill_col: 选择插值的列，可填名字，也可填index        df: DataFrame,输入需要插值的表        time_range: 设置判断长时间间隔的点数        '''</span>        <span class="token comment" spellcheck="true"># count记录起始位置，每当遇到长间隔空值点，会将count移动到下一个非空值点</span>        i<span class="token operator">=</span><span class="token number">0</span>        dot_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">while</span> i <span class="token operator">&lt;</span> len<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">:</span>            value <span class="token operator">=</span> np<span class="token punctuation">.</span>isnan<span class="token punctuation">(</span>df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">#判断当前值是否为空</span>            <span class="token keyword">if</span> value <span class="token operator">==</span> <span class="token boolean">True</span><span class="token punctuation">:</span>                <span class="token comment" spellcheck="true"># 判断当前空值点是否是长间隔</span>                islonginterval <span class="token operator">=</span> islong_missing<span class="token punctuation">(</span>fill_col<span class="token punctuation">,</span> df <span class="token punctuation">,</span> range_window<span class="token operator">=</span>time_range<span class="token punctuation">,</span> row_index<span class="token operator">=</span>i<span class="token punctuation">)</span>                <span class="token comment" spellcheck="true">#当遇到长间隔空值时，将count一直移动到下一个非空点</span>                <span class="token keyword">if</span> islonginterval<span class="token punctuation">:</span>                    dot_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>                    i <span class="token operator">+=</span> <span class="token punctuation">(</span>time_range<span class="token number">-1</span><span class="token punctuation">)</span>                    <span class="token keyword">while</span> value <span class="token operator">==</span><span class="token boolean">True</span> <span class="token operator">and</span> i<span class="token operator">&lt;</span>len<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">:</span>                        i <span class="token operator">+=</span><span class="token number">1</span>                        value <span class="token operator">=</span> np<span class="token punctuation">.</span>isnan<span class="token punctuation">(</span>df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>                                            dot_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>               i <span class="token operator">+=</span><span class="token number">1</span>        <span class="token keyword">return</span> dot_list</code></pre><p>然后删除缺失值并导出。使用reset_index()是为了让时间索引一起导出来。这里用的导出方法缺点是索引需要自己手动加上去。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#删除缺失值</span>tmp_data1 <span class="token operator">=</span> tmp_data1<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> how <span class="token operator">=</span> <span class="token string">'all'</span><span class="token punctuation">,</span>inplace <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#避免之后重新填补，导出经插值，删除空值后的表</span>path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>abspath<span class="token punctuation">(</span>r<span class="token string">'./data/l1_tehu'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 文件夹路径</span>new_file_name <span class="token operator">=</span> <span class="token string">'tmp_data1_insert.csv'</span>tmp_data1<span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span>path <span class="token operator">+</span> <span class="token string">'/'</span> <span class="token operator">+</span> new_file_name<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'a'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'gbk'</span><span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></code></pre><p>下面对前面的<strong>异常值</strong>进行处理。这里只选取其中一个片段进行示范。</p><pre class=" language-python"><code class="language-python">twoday_data <span class="token operator">=</span> tmp_data1<span class="token punctuation">[</span><span class="token string">'2021-11-01 18:58:30'</span><span class="token punctuation">:</span> <span class="token string">'2021-11-03 11:35:00'</span><span class="token punctuation">]</span>twoday_data<span class="token punctuation">.</span>describe<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#描述表的一些信息</span></code></pre><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_twoday_describe.3qyix6pukji0.jpg" width="40%/"></div>  <p>画出箱线图，可以看出存在的一些异常点：</p><pre class=" language-python"><code class="language-python">plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>boxplot<span class="token punctuation">(</span>twoday_data<span class="token punctuation">[</span><span class="token string">'Comp0_Te'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>boxplot<span class="token punctuation">(</span>twoday_data<span class="token punctuation">[</span><span class="token string">'Comp1_Te'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_twoday_boxplot.705wl11k1jo0.jpg" width="60%/"></div>  <p>然后利用四分位，删除异常值并用前值进行填补。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 超过了上四分位2倍四分位距或下四分位2倍距离都算异常值，用上一个值填充</span>a <span class="token operator">=</span> twoday_data<span class="token punctuation">[</span><span class="token string">'Comp0_Te'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>quantile<span class="token punctuation">(</span><span class="token number">0.75</span><span class="token punctuation">)</span>b <span class="token operator">=</span> twoday_data<span class="token punctuation">[</span><span class="token string">'Comp0_Te'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>quantile<span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">)</span>c <span class="token operator">=</span> twoday_data<span class="token punctuation">[</span><span class="token string">'Comp0_Te'</span><span class="token punctuation">]</span>c<span class="token punctuation">[</span><span class="token punctuation">(</span>c<span class="token operator">>=</span><span class="token punctuation">(</span>a<span class="token operator">-</span>b<span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">2</span><span class="token operator">+</span>a<span class="token punctuation">)</span><span class="token operator">|</span><span class="token punctuation">(</span>c<span class="token operator">&lt;=</span>b<span class="token operator">-</span><span class="token punctuation">(</span>a<span class="token operator">-</span>b<span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token operator">=</span>np<span class="token punctuation">.</span>nanc<span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>method<span class="token operator">=</span><span class="token string">'pad'</span><span class="token punctuation">,</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>twoday_data<span class="token punctuation">[</span><span class="token string">'Comp0_Te'</span><span class="token punctuation">]</span> <span class="token operator">=</span> c<span class="token keyword">print</span><span class="token punctuation">(</span>twoday_data<span class="token punctuation">[</span><span class="token string">'Comp0_Te'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>describe<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_twoday_boxplot_new.44m969zxzbg0.jpg" width="60%/"></div>  <p>异常值处理完后，还有数据平滑处理。平滑处理在第二张表中演示。下面处理第二张表的数据。同样的操作，先将时间列设为索引，展示data2中数据：</p><pre class=" language-python"><code class="language-python">data2<span class="token punctuation">.</span>index <span class="token operator">=</span> pd<span class="token punctuation">.</span>to_datetime<span class="token punctuation">(</span>data2<span class="token punctuation">.</span>Datetime<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#设置时间列为索引</span>data2</code></pre><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/L1_id_data.6dh59h41kq40.jpg" width="40%/"></div>   <p>表中有个ID列，表示各个传感器的型号，做数据分析时，可以将ID列提取出来，作为列索引，方便观察。因此，先对表格进行<strong>透视</strong>：</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#数据透视</span><span class="token comment" spellcheck="true">#tmp_data2用来拷贝data2数据变为二重索引表，原表数据保留 </span>tmp_data2<span class="token operator">=</span>data2   tmp_data2<span class="token punctuation">[</span><span class="token string">'L1_id'</span><span class="token punctuation">]</span> <span class="token operator">=</span> tmp_data2<span class="token punctuation">[</span><span class="token string">'L1_id'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>str<span class="token punctuation">)</span>tmp_data2<span class="token operator">=</span>data2<span class="token punctuation">.</span>pivot_table<span class="token punctuation">(</span>index<span class="token operator">=</span><span class="token string">'Datetime'</span><span class="token punctuation">,</span>columns<span class="token operator">=</span><span class="token string">'L1_id'</span><span class="token punctuation">)</span>tmp_data2</code></pre><p>透视结果如下所示：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/L1_id_pivot.2ab6wthn3ack.jpg" width="100%/"></div>  <p>表格的列变成了二重索引，为了方便后续引用，将其变为一重索引。需要注意的是，这种变换需要数据类型都为string型，如果不是，需要提前转换。当然，还有一种手动方法，变为二重索引后导出表，将原列索引删除，自己再加上索引就好。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#改为一重列索引表，用one_class_data2表示</span>one_class_data2 <span class="token operator">=</span>tmp_data2<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>deep<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#拷贝表格</span>one_class_data2<span class="token punctuation">.</span>columns <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"_"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> one_class_data2<span class="token punctuation">.</span>columns<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true">#将原来的二重索引的列名进行拼接</span><span class="token comment" spellcheck="true"># one_class_data2.columns = tmp_data2.columns.droplevel(0)  #这个方法是直接将外围第二重索引去掉，只取第一重列索引。</span>one_class_data2</code></pre><p>结果如下：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/L1_id_oneclass.59gip30dtvk0.jpg" width="100%/"></div>  <p>可以看到，列已经变为一重，列名为二重列名拼接而成。后续步骤与第一张表一样，这里不再做解释。最后再对其进行<strong>平滑处理</strong>。平滑方式选用传统的<em>巴特沃斯</em> 低通滤波器。对于参数wn的确定，首先采样频率定为1=采样长度/采样时间（其实采样频率可以自己定，其他的频率以采样频率为基准进行计算即可，结果都一样）。截止频率需要根据实际的来，我的数据中最大的频率差不多以77个点为一个周期，所以稍微扩大下范围后计算截止频率 = 1/60（采样频率为1，那么采样时间即为周期T=1）。根据公式wn = 2*截止频率/采样频率 = 0.033。以两天的数据量为例。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 低通滤波器-巴特沃斯</span><span class="token comment" spellcheck="true"># wn=2*截至频率/采样频率   如果一天采样10个点，采样频率为10，截止频率为想要滤除的频率上限或下限</span><span class="token comment" spellcheck="true"># pivot_data为透视后清理完的表</span>twoday_data <span class="token operator">=</span> pivot_data<span class="token punctuation">[</span><span class="token string">'2022-01-26 00:00:00'</span><span class="token punctuation">:</span><span class="token string">'2022-01-28 00:00:00'</span><span class="token punctuation">]</span>b<span class="token punctuation">,</span> a <span class="token operator">=</span> signal<span class="token punctuation">.</span>butter<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">0.033</span><span class="token punctuation">,</span> <span class="token string">'lowpass'</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#配置滤波器 8 表示滤波器的阶数</span>twoday_data<span class="token punctuation">[</span><span class="token string">'Te_0_filter'</span><span class="token punctuation">]</span> <span class="token operator">=</span> signal<span class="token punctuation">.</span>filtfilt<span class="token punctuation">(</span>b<span class="token punctuation">,</span> a<span class="token punctuation">,</span> twoday_data<span class="token punctuation">[</span><span class="token string">'Te_0'</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><p>滤波结果如下：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/butter.6leaq5g4j7s0.jpg" width="50%/"></div>  <h2 id="2-2-探索性数据分析EDA"><a href="#2-2-探索性数据分析EDA" class="headerlink" title="2.2 探索性数据分析EDA"></a>2.2 探索性数据分析EDA</h2><p>首先进行相关性分析。这里以表data2为例。分析的数据取较完整地一个月的时间片段，重采样为1min适当减小数据量。（记得导入表后先设置时间索引）</p><pre class=" language-python"><code class="language-python">Month_data2 <span class="token operator">=</span> data2<span class="token punctuation">[</span><span class="token string">'2022-01-25 13:12:30'</span><span class="token punctuation">:</span><span class="token string">'2022-02-24 15:13:00'</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true"># 重采样一分钟(一个月数据)</span>Month_data2_1T <span class="token operator">=</span> Month_data2<span class="token punctuation">.</span>resample<span class="token punctuation">(</span><span class="token string">'T'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>Month_data2_1T<span class="token operator">=</span>Month_data2_1T<span class="token punctuation">.</span>round<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#保留两位小数。</span><span class="token comment" spellcheck="true"># 相关系数</span>Month_data2_1T<span class="token punctuation">.</span>corr<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>这里仅展示部分结果图：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data2_1T_corr.5gurkritpvs0.jpg" width="50%/"></div>  <p>可以看到，每个变量间的相关程度都很高，不利用互相作为特征值。<br>对数据的自相关性和偏相关性进行分析。自相关：描述的是一组时间序列和它前面间隔n个时刻的一组时间序列之前的相关性。偏自相关：描述的是一组时间序列和它前面间隔n个时刻的一组时间序列之前的偏相关性。这里的偏相关性可以从本质上理解为去除了样本之间的干涉，也就是更早时刻的相关性影响。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 自相关，偏自相关，列出每一列的相关图</span>col <span class="token operator">=</span> Month_data2_1T<span class="token punctuation">.</span>columns<span class="token keyword">for</span> c <span class="token keyword">in</span> col<span class="token punctuation">:</span>      fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    ax1 <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">121</span><span class="token punctuation">)</span>    ax1<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span>c<span class="token punctuation">)</span>    ax2 <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">122</span><span class="token punctuation">)</span>    ax2<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span>c<span class="token punctuation">)</span>    plot_acf<span class="token punctuation">(</span>Month_data2_1T<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span>lags<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span>ax <span class="token operator">=</span> ax1<span class="token punctuation">)</span>    plot_pacf<span class="token punctuation">(</span>Month_data2_1T<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span>lags<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span>ax <span class="token operator">=</span> ax2<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>同样的，展示部分结果图。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data2_1T_acf.3xqf5jmk4f80.jpg" width="60%/"></div>  <p>研究自相关、偏相关可用于判断是否适合使用时间预测方法,也可用于查看周期（下面会有演示）。该图可应用于LSTM算法，作为参数选择的依据。具体使用方法有待明确。<br>查看温湿度的统计分布。这里仅仅是查看下数据分布，目前没有对于其分析的一些想法。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 管道温湿度统计分布图</span><span class="token keyword">for</span> c <span class="token keyword">in</span> col<span class="token punctuation">:</span>     plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    sns<span class="token punctuation">.</span>distplot<span class="token punctuation">(</span>Month_data2_1T<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span> bins<span class="token operator">=</span>int<span class="token punctuation">(</span>np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>len<span class="token punctuation">(</span>Month_data2_1T<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>展示部分结果图。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data2_1T_distplot.462fv8dw1b00.jpg" width="60%/"></div>  <p>数据平稳性判断，使用单位根检验法。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">check_stationarity</span><span class="token punctuation">(</span>y<span class="token punctuation">,</span> lags_plots<span class="token operator">=</span><span class="token number">48</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">22</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token string">"Use Series as parameter"</span>    <span class="token comment" spellcheck="true"># Creating plots of the DF</span>    y <span class="token operator">=</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span>y<span class="token punctuation">)</span>    fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>    ax1 <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplot2grid<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> colspan<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>    ax2 <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplot2grid<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    ax3 <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplot2grid<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    ax4 <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplot2grid<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> colspan<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>    y<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>ax<span class="token operator">=</span>ax1<span class="token punctuation">,</span> figsize<span class="token operator">=</span>figsize<span class="token punctuation">)</span>    ax1<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'Nums Variation'</span><span class="token punctuation">)</span>    plot_acf<span class="token punctuation">(</span>y<span class="token punctuation">,</span> lags<span class="token operator">=</span>lags_plots<span class="token punctuation">,</span> zero<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> ax<span class="token operator">=</span>ax2<span class="token punctuation">)</span><span class="token punctuation">;</span>    plot_pacf<span class="token punctuation">(</span>y<span class="token punctuation">,</span> lags<span class="token operator">=</span>lags_plots<span class="token punctuation">,</span> zero<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> ax<span class="token operator">=</span>ax3<span class="token punctuation">)</span><span class="token punctuation">;</span>    sns<span class="token punctuation">.</span>distplot<span class="token punctuation">(</span>y<span class="token punctuation">,</span> bins<span class="token operator">=</span>int<span class="token punctuation">(</span>np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>len<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ax<span class="token operator">=</span>ax4<span class="token punctuation">)</span>    ax4<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'Distribution Chart'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># plt.show()</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Results of Dickey-Fuller Test:'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#  regression：{c”，“ct”，“ctt”，“n”}要包含在回归中的常数和趋势顺序。</span>    <span class="token comment" spellcheck="true"># “c”：仅限常量（默认值）。</span>    <span class="token comment" spellcheck="true"># “ct”：恒定和趋势。</span>    <span class="token comment" spellcheck="true"># “ctt”：常数、线性和二次趋势。</span>    <span class="token comment" spellcheck="true"># n：没有常数，没有趋势。</span>    <span class="token comment" spellcheck="true"># ADF的结果主要看以下两个方面：</span>    <span class="token comment" spellcheck="true"># Test Statistic的值如果比Critical Value (5%)小则满足稳定性需求.</span>    <span class="token comment" spellcheck="true"># p-value越低（理论上需要低于0.05）证明序列越稳定。</span>    adfinput <span class="token operator">=</span> adfuller<span class="token punctuation">(</span>y<span class="token punctuation">,</span>regression <span class="token operator">=</span> <span class="token string">'c'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#单位根检验</span>    adftest <span class="token operator">=</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span>adfinput<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Test Statistic'</span><span class="token punctuation">,</span><span class="token string">'p-value'</span><span class="token punctuation">,</span><span class="token string">'Lags Used'</span><span class="token punctuation">,</span><span class="token string">'Number of Observations Used'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    adftest <span class="token operator">=</span> round<span class="token punctuation">(</span>adftest<span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> key<span class="token punctuation">,</span> value <span class="token keyword">in</span> adfinput<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        adftest<span class="token punctuation">[</span><span class="token string">"Critical Value (%s)"</span><span class="token operator">%</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> value<span class="token punctuation">.</span>round<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>adftest<span class="token punctuation">)</span>        <span class="token keyword">if</span> adftest<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>round<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> adftest<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">.</span>round<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\nThe Test Statistics is lower than the Critical Value of 5%.\nThe serie seems to be stationary'</span><span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\nThe Test Statistics is higher than the Critical Value of 5%.\nThe serie isn't stationary"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 检验平稳性</span>check_stationarity<span class="token punctuation">(</span>Month_data2_1T<span class="token punctuation">[</span><span class="token string">'Te_0'</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><blockquote><p>输出结果为：<br>Results of Dickey-Fuller Test:<br>Test Statistic                    -1.4583<br>p-value                            0.5540<br>Lags Used                         55.0000<br>Number of Observations Used    43266.0000<br>Critical Value (1%)               -3.4305<br>Critical Value (5%)               -2.8616<br>Critical Value (10%)              -2.5668<br>dtype: float64<br>The Test Statistics is higher than the Critical Value of 5%.<br>The serie isn’t stationary  </p></blockquote><p>判断平稳性两个标准：Test Statistic小于Critical Value (5%)　或是p-value小于0.05。平稳性是多数统计学模型的必要条件之一。可见原数据并不是平稳序列。<br>对于非平稳序列，可使用一阶差分使其平稳化。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#序列平稳化，一阶差分</span>Month_data2_1T<span class="token punctuation">[</span><span class="token string">'Te_0_diff'</span><span class="token punctuation">]</span> <span class="token operator">=</span> Month_data2_1T<span class="token punctuation">[</span><span class="token string">'Te_0'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>diff<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span></code></pre><p>其稳定性结果为：</p><blockquote><p>Results of Dickey-Fuller Test:<br>Test Statistic                   -51.9122<br>p-value                            0.0000<br>Lags Used                         54.0000<br>Number of Observations Used    43267.0000<br>Critical Value (1%)               -3.4305<br>Critical Value (5%)               -2.8616<br>Critical Value (10%)              -2.5668<br>dtype: float64<br>The Test Statistics is lower than the Critical Value of 5%.<br>The serie seems to be stationary</p></blockquote><p>可见一阶差分可以有效是原序列平稳。后期可利用差分序列进行异常检测训练。<br>时间序列分解：所谓分解就是将时序数据分离成不同的成分，分解为：长期趋势Trend、季节性Seasonality和随机残差Residuals。分解序列后可针对每个子序列分别建模处理，如建模趋势后，在原数据中减去趋势的干扰。又或者当作特征值。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 管道温湿度时序序列分解：趋势+季节性+残差</span>col <span class="token operator">=</span> Month_data2_1T<span class="token punctuation">.</span>columns<span class="token keyword">for</span> c <span class="token keyword">in</span> col<span class="token punctuation">:</span>      <span class="token comment" spellcheck="true">#用加性模型，周期1440为1440min，分解数据时间频率为1min，一天为1440min。这里将一天设为周期，那么分解出的季节性数据以1天为周期</span>    decompose_result <span class="token operator">=</span> seasonal_decompose<span class="token punctuation">(</span>Month_data2_1T<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"additive"</span><span class="token punctuation">,</span> period<span class="token operator">=</span><span class="token number">1440</span><span class="token punctuation">)</span>    fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">18</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    ax1 <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">411</span><span class="token punctuation">)</span>    ax2 <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">412</span><span class="token punctuation">)</span>    ax3 <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">413</span><span class="token punctuation">)</span>    ax4 <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">414</span><span class="token punctuation">)</span>    ax1<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span>c<span class="token punctuation">)</span>    ax1<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'init'</span><span class="token punctuation">)</span>    ax2<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span>c<span class="token punctuation">)</span>    ax2<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'trend'</span><span class="token punctuation">)</span>    ax3<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span>c<span class="token punctuation">)</span>    ax3<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'seasonal'</span><span class="token punctuation">)</span>    ax4<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span>c<span class="token punctuation">)</span>    ax4<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'resid'</span><span class="token punctuation">)</span>    ax1<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>Month_data2_1T<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">)</span>    ax2<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>decompose_result<span class="token punctuation">.</span>trend<span class="token punctuation">)</span>    ax3<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>decompose_result<span class="token punctuation">.</span>seasonal<span class="token punctuation">)</span>    ax4<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>decompose_result<span class="token punctuation">.</span>resid<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>部分结果如下：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data2_1T_decompose.7bi8h01gdf40.jpg" width="80%/"></div><p>接下来进行周期性检验。首先使用FFT查看频谱图：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">define_fft</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> fs <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> show_pic<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token triple-quoted-string string">"""     # Parameters      data: 检测数据，dataframe类型     show_pic: 是否展示图片     fs: 采样频率，采样时长除以采样点数 = 采样频率    """</span>     n <span class="token operator">=</span> data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    x <span class="token operator">=</span> data<span class="token punctuation">.</span>values    yy <span class="token operator">=</span> fft<span class="token punctuation">(</span>x<span class="token punctuation">)</span>    fre <span class="token operator">=</span> fftfreq<span class="token punctuation">(</span>n<span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">/</span>fs<span class="token punctuation">)</span>            <span class="token comment" spellcheck="true">#求频率横坐标</span>    indices <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>fre <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#筛选大于零的频率</span>    w_pos <span class="token operator">=</span> <span class="token number">2</span><span class="token operator">*</span>abs<span class="token punctuation">(</span>yy<span class="token punctuation">[</span>indices<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">/</span>n    <span class="token comment" spellcheck="true">#计算幅度值</span>    F_pos <span class="token operator">=</span> fre<span class="token punctuation">[</span>indices<span class="token punctuation">]</span>                result_fft <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'freq'</span><span class="token punctuation">,</span> <span class="token string">'spec'</span><span class="token punctuation">,</span> <span class="token string">'T'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>     result_fft<span class="token punctuation">[</span><span class="token string">'freq'</span><span class="token punctuation">]</span> <span class="token operator">=</span> F_pos     result_fft<span class="token punctuation">[</span><span class="token string">'spec'</span><span class="token punctuation">]</span> <span class="token operator">=</span> w_pos     result_fft<span class="token punctuation">[</span><span class="token string">'T'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token operator">/</span>F_pos<span class="token operator">/</span><span class="token number">1440</span>    <span class="token comment" spellcheck="true"># 按照频率强弱程度降序排列 </span>    result_fft <span class="token operator">=</span> result_fft<span class="token punctuation">.</span>sort_values<span class="token punctuation">(</span>by<span class="token operator">=</span><span class="token string">'spec'</span><span class="token punctuation">,</span> ascending<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>     <span class="token keyword">print</span><span class="token punctuation">(</span>result_fft<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> show_pic <span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 频率转换为周期 </span>        plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">/</span>F_pos<span class="token operator">/</span><span class="token number">1440</span><span class="token punctuation">,</span> w_pos<span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token number">0</span>define_fft<span class="token punctuation">(</span>Month_data2_1T<span class="token punctuation">[</span><span class="token string">'Te_0'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>fs<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>show_pic<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></code></pre><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data_1T_periodogram.bx0uzqbkjcw.jpg" width="40%/"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data_1T_residperiod.4rqdgw1afwu0.jpg" width="30%/"></div>  <p>查看左侧频谱图，可以发现图是有问题的。在周期最大的三个点，也即频率最小的三个点处出现了很大的峰值，低频成分上翘，这明显不对。考虑原因可能有二。  </p><ol><li>原数据存在直流偏移的影响。<br>  解决办法：减去直流量，试减去平均值  </li><li>原数据中趋势的存在干扰了频谱分析。当信号中有明显的趋势项而未消除时，进行相关性分析和功率谱密度分析时会出现畸变，造成低频成分上翘甚至淹没主频成分。<br>  解决办法：去趋势。</li></ol><p>对原数据减去平均值后进行FFT分析，发现频谱图的形状并没有变化，改试方案2。去趋势的方法在网上有许多，这里使用了两种办法：多项式拟合去趋势和时序序列分解。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 多项式拟合去趋势,使用滤波后的数据</span>n <span class="token operator">=</span> Month_data2_1T<span class="token punctuation">[</span><span class="token string">'Te_0_filter'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>x<span class="token operator">=</span>np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> n<span class="token punctuation">,</span> n<span class="token punctuation">)</span>y <span class="token operator">=</span> Month_data_1T<span class="token punctuation">[</span><span class="token string">'Te_0_filter'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>valuesz1 <span class="token operator">=</span> np<span class="token punctuation">.</span>polyfit<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>              <span class="token comment" spellcheck="true"># 曲线拟合，返回值为多项式的各项系数，10为阶数，具体数据选取看曲线拟合程度，可进行可视化查看</span>p1 <span class="token operator">=</span> np<span class="token punctuation">.</span>poly1d<span class="token punctuation">(</span>z1<span class="token punctuation">)</span>                    <span class="token comment" spellcheck="true"># 返回值为多项式的表达式，也就是函数式子</span><span class="token comment" spellcheck="true"># print(p1)</span>y_pred <span class="token operator">=</span> p1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                        <span class="token comment" spellcheck="true"># 根据函数的多项式表达式，求解 y,即趋势</span>Month_data_1T<span class="token punctuation">[</span><span class="token string">'x'</span><span class="token punctuation">]</span><span class="token operator">=</span>Month_data_1T<span class="token punctuation">[</span><span class="token string">'Te_0_filter'</span><span class="token punctuation">]</span><span class="token operator">-</span>y_preddefine_fft<span class="token punctuation">(</span>Month_data_1T<span class="token punctuation">[</span><span class="token string">'x'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>fs<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>show_pic<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></code></pre><p>下图为原数据曲线图、趋势图、原数据去趋势图和FFT图。可以看出，用拟合法去趋势后，FFT图尾端翘起现象几乎没有了，但仍有小尾巴残留。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/polyfit.1wq4d6hwhjq8.jpg" width="80%/"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/polyfit_detrend.2eofsy7hwrwg.jpg" width="80%/"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/ployfit_FFT.4u82p09d7n60.jpg" width="50%/">    </div>  <p>接下来是由时序序列分解法。该方法上面讲过了，操作步骤一致，只是在分解趋势适合，分解了两次，使用77周期分解以此，发现还有周期现象，又使用1440周期对分解出的趋势分解了一次，对用原数据减去二次趋势，再求FFT，结果如图。第一张为去趋势后的图，第二张为FFT结果图。可以看出，该方法去趋势效果更好。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/twice_detrend.7jhgdh1lahw0.jpg" width="80%/"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/twice_detrend_FFT.ekqba34lveo.jpg" width="40%/">    </div>  <p>根据频谱图结果，列出最大的三个能量谱的点依次为1天，0.5天，77min。可能的周期也是这三个点。再根据这三个点看自相关图，分别列出滞后点为1000和10000的相关图。如图所示。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/acf_1000.hy1dzybmthk.jpg" width="80%/"></div>  对于自相关图，当序列存在周期时，会在周期出出现一个高峰。从图中可以看出，曲线分别以约77和1440为周期处出现高峰。再结合实际，77min大致为系统运行一个周期，1440min为系统运行一天。由此可见，数据约以77min和1440min为周期。<h2 id="2-3-特征工程"><a href="#2-3-特征工程" class="headerlink" title="2.3 特征工程"></a>2.3 特征工程</h2><h3 id="2-3-1-特征提取"><a href="#2-3-1-特征提取" class="headerlink" title="2.3.1 特征提取"></a>2.3.1 特征提取</h3><ol><li><strong>从时间中提取特征</strong><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#仅取第一列Hu_0数据</span>df <span class="token operator">=</span> Month_data_1T<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span>df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">.</span>index<span class="token comment" spellcheck="true"># 年份</span>df<span class="token punctuation">[</span><span class="token string">'年'</span><span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>year<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 月份</span>df<span class="token punctuation">[</span><span class="token string">'月'</span><span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>month<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 日</span>df<span class="token punctuation">[</span><span class="token string">'日'</span><span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>day<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 小时</span>df<span class="token punctuation">[</span><span class="token string">'时'</span><span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>hour<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 分钟</span>df<span class="token punctuation">[</span><span class="token string">'分'</span><span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>minute<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 一天中的第几分钟</span>df<span class="token punctuation">[</span><span class="token string">'一天中的第几分钟'</span><span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>minute <span class="token operator">+</span> x<span class="token punctuation">.</span>hour<span class="token operator">*</span><span class="token number">60</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 星期几；</span>df<span class="token punctuation">[</span><span class="token string">'星期几'</span><span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>dayofweek<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 一年中的第几天</span>df<span class="token punctuation">[</span><span class="token string">'一年中的第几天'</span><span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>dayofyear<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># # 一年中的第几周</span><span class="token comment" spellcheck="true"># df['一年中的第几周']=df['时间'].apply(lambda x: x.week)</span><span class="token comment" spellcheck="true"># 一天中哪个时间段：凌晨、早晨、上午、中午、下午、傍晚、晚上、深夜；</span>period_dict <span class="token operator">=</span><span class="token punctuation">{</span> <span class="token number">23</span><span class="token punctuation">:</span> <span class="token number">0x00</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span> <span class="token number">0x00</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span> <span class="token number">0x00</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span> <span class="token number">0x01</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">:</span> <span class="token number">0x01</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">:</span> <span class="token number">0x01</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">:</span> <span class="token number">0x02</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">:</span> <span class="token number">0x02</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">:</span> <span class="token number">0x02</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">:</span> <span class="token number">0x03</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">:</span> <span class="token number">0x03</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">:</span> <span class="token number">0x03</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">:</span> <span class="token number">0x03</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">:</span> <span class="token number">0x04</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">:</span> <span class="token number">0x04</span><span class="token punctuation">,</span><span class="token number">14</span><span class="token punctuation">:</span> <span class="token number">0x04</span><span class="token punctuation">,</span>  <span class="token number">15</span><span class="token punctuation">:</span> <span class="token number">0x05</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">:</span> <span class="token number">0x05</span><span class="token punctuation">,</span> <span class="token number">17</span><span class="token punctuation">:</span> <span class="token number">0x05</span><span class="token punctuation">,</span><span class="token number">18</span><span class="token punctuation">:</span> <span class="token number">0x05</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">:</span> <span class="token number">0x07</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">:</span> <span class="token number">0x07</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">:</span> <span class="token number">0x07</span><span class="token punctuation">,</span> <span class="token number">22</span><span class="token punctuation">:</span> <span class="token number">0x07</span><span class="token punctuation">,</span><span class="token comment" spellcheck="true">#     23: '深夜', 0: '深夜', 1: '深夜',</span><span class="token comment" spellcheck="true">#     2: '凌晨', 3: '凌晨', 4: '凌晨',</span><span class="token comment" spellcheck="true">#     5: '早晨', 6: '早晨', 7: '早晨',</span><span class="token comment" spellcheck="true">#     8: '上午', 9: '上午', 10: '上午', 11: '上午',</span><span class="token comment" spellcheck="true">#     12: '中午', 13: '中午',14: '中午',</span><span class="token comment" spellcheck="true">#     15: '下午', 16: '下午', 17: '下午',18: '下午',</span><span class="token comment" spellcheck="true">#     19: '晚上', 20: '晚上', 21: '晚上', 22: '晚上',</span><span class="token punctuation">}</span>df<span class="token punctuation">[</span><span class="token string">'时间段'</span><span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">'时'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>period_dict<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># # 一年中的哪个季度</span><span class="token comment" spellcheck="true"># season_dict = {</span><span class="token comment" spellcheck="true">#     1: '春季', 2: '春季', 3: '春季',</span><span class="token comment" spellcheck="true">#     4: '夏季', 5: '夏季', 6: '夏季',</span><span class="token comment" spellcheck="true">#     7: '秋季', 8: '秋季', 9: '秋季',</span><span class="token comment" spellcheck="true">#     10: '冬季', 11: '冬季', 12: '冬季',</span><span class="token comment" spellcheck="true"># }</span><span class="token comment" spellcheck="true"># df['季节']=df['月'].map(season_dict)</span><span class="token comment" spellcheck="true"># # 是否闰年</span><span class="token comment" spellcheck="true"># df['是否闰年'] = df['时间'].apply(lambda x: x.is_leap_year)</span><span class="token comment" spellcheck="true"># 是否月初</span>df<span class="token punctuation">[</span><span class="token string">'是否月初'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>is_month_start<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 是否月末</span>df<span class="token punctuation">[</span><span class="token string">'是否月末'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>is_month_end<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 是否季节初</span><span class="token comment" spellcheck="true"># df['是否季节初'] = df['时间'].apply(lambda x: x.is_quarter_start)</span><span class="token comment" spellcheck="true"># 是否季节末</span><span class="token comment" spellcheck="true"># df['是否季节末'] = df['时间'].apply(lambda x: x.is_quarter_end)</span><span class="token comment" spellcheck="true"># 是否年初</span><span class="token comment" spellcheck="true"># df['是否年初'] = df['时间'].apply(lambda x: x.is_year_start)</span><span class="token comment" spellcheck="true"># 是否年尾</span><span class="token comment" spellcheck="true"># df['是否年尾'] = df['时间'].apply(lambda x: x.is_year_end)</span><span class="token comment" spellcheck="true"># 是否周末</span>df<span class="token punctuation">[</span><span class="token string">'是否周末'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token boolean">True</span> <span class="token keyword">if</span> x<span class="token punctuation">.</span>dayofweek <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span> <span class="token keyword">else</span> <span class="token boolean">False</span><span class="token punctuation">)</span>df</code></pre>结果如下图所示：<div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202204/Characteristic-Engineering-of-Time-Series/时间特征.407xag8uznw0.jpg"></div> </li><li><strong>从时序规律中提取特征</strong><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> statsmodels<span class="token punctuation">.</span>tsa<span class="token punctuation">.</span>seasonal <span class="token keyword">import</span> seasonal_decompose<span class="token comment" spellcheck="true"># 数据含有两个周期77和1440</span><span class="token comment" spellcheck="true"># 偏移6min差分</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_-5S"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'Hu_0'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shift<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 偏移77min差分，一小周期</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_-1period"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'Hu_0'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shift<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">*</span><span class="token number">77</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 偏移两小周期</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_-2period"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'Hu_0'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shift<span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span><span class="token number">77</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 偏移1天，一大周期</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_-1day"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'Hu_0'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shift<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">*</span><span class="token number">1440</span><span class="token punctuation">)</span>decompose_result <span class="token operator">=</span> seasonal_decompose<span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">'Hu_0'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"additive"</span><span class="token punctuation">,</span> period<span class="token operator">=</span><span class="token number">77</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 分离77周期分离</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_77seasonal"</span><span class="token punctuation">]</span> <span class="token operator">=</span> decompose_result<span class="token punctuation">.</span>seasonaldecompose_result <span class="token operator">=</span> seasonal_decompose<span class="token punctuation">(</span>decompose_result<span class="token punctuation">.</span>seasonal<span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"additive"</span><span class="token punctuation">,</span> period<span class="token operator">=</span><span class="token number">1440</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 分离1440周期分量</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_1440seasonal"</span><span class="token punctuation">]</span> <span class="token operator">=</span> decompose_result<span class="token punctuation">.</span>seasonal<span class="token comment" spellcheck="true"># 趋势分量</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_trend"</span><span class="token punctuation">]</span> <span class="token operator">=</span> decompose_result<span class="token punctuation">.</span>trend<span class="token comment" spellcheck="true"># 残差分量</span>df<span class="token punctuation">[</span><span class="token string">"Hu0_resid"</span><span class="token punctuation">]</span> <span class="token operator">=</span> decompose_result<span class="token punctuation">.</span>residdf</code></pre><img lazyload="" src="/images/loading.svg" data-src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202204/Characteristic-Engineering-of-Time-Series/%E6%97%B6%E5%BA%8F%E8%A7%84%E5%BE%8B%E7%89%B9%E5%BE%81.5n1vvk2y3d40.jpg" alt="时序规律特征"></li><li><strong>从统计窗口提取特征</strong><br>```python<h1 id="sum-值的总和"><a href="#sum-值的总和" class="headerlink" title="sum() 值的总和"></a>sum() 值的总和</h1><h1 id="mean-均值"><a href="#mean-均值" class="headerlink" title="mean() 均值"></a>mean() 均值</h1><h1 id="median-值的算术中值"><a href="#median-值的算术中值" class="headerlink" title="median() 值的算术中值"></a>median() 值的算术中值</h1><h1 id="min-最小值"><a href="#min-最小值" class="headerlink" title="min() 最小值"></a>min() 最小值</h1><h1 id="max-最大"><a href="#max-最大" class="headerlink" title="max() 最大"></a>max() 最大</h1><h1 id="std-贝塞尔修正样本标准差-均方差"><a href="#std-贝塞尔修正样本标准差-均方差" class="headerlink" title="std() 贝塞尔修正样本标准差(均方差)"></a>std() 贝塞尔修正样本标准差(均方差)</h1><h1 id="var-无偏方差"><a href="#var-无偏方差" class="headerlink" title="var() 无偏方差"></a>var() 无偏方差</h1><h1 id="cov-无偏协方差（二元）"><a href="#cov-无偏协方差（二元）" class="headerlink" title="cov() 无偏协方差（二元）"></a>cov() 无偏协方差（二元）</h1><h1 id="corr-相关（二进制）"><a href="#corr-相关（二进制）" class="headerlink" title="corr() 相关（二进制）"></a>corr() 相关（二进制）</h1><h1 id="variation-v-x3D-std-v-x2F-mean-v-离散系数"><a href="#variation-v-x3D-std-v-x2F-mean-v-离散系数" class="headerlink" title="variation_v = std_v/mean_v 离散系数"></a>variation_v = std_v/mean_v 离散系数</h1><h1 id="polyfit-线性拟合，求斜率"><a href="#polyfit-线性拟合，求斜率" class="headerlink" title="polyfit 线性拟合，求斜率"></a>polyfit 线性拟合，求斜率</h1></li></ol><p>#使用rolling滚动窗口，窗口大小为7<br>roll_data = df[‘Hu_0’].rolling(window=7)<br>df[“Hu0_mean”] = roll_data.mean()<br>df[“Hu0_median”] = roll_data.median()<br>df[“Hu0_min”] = roll_data.min()<br>df[“Hu0_max”] = roll_data.max()<br>df[“Hu0_std”] = roll_data.std()<br>df[“Hu0_var”] = roll_data.var()<br>df[“Hu0_cov”] = roll_data.cov()<br>df[“Hu0_corr”] = roll_data.corr()<br>df[“Hu0_variation”] = df[“Hu0_std”]/df[“Hu0_mean”]<br>df[“Hu0_sum”] = roll_data.sum()<br>df[“Hu0_sum_diff2”] = df[“Hu0_sum”].shift(1)-df[“Hu0_sum”].shift(2)</p><h1 id="df-“Hu0-autocorr1”-x3D-df-“Hu-0”-autocorr-1"><a href="#df-“Hu0-autocorr1”-x3D-df-“Hu-0”-autocorr-1" class="headerlink" title="df[“Hu0_autocorr1”] = df[“Hu_0”].autocorr(1)"></a>df[“Hu0_autocorr1”] = df[“Hu_0”].autocorr(1)</h1><h1 id="df-“Hu0-autocorr2”-x3D-df-“Hu-0”-autocorr-2"><a href="#df-“Hu0-autocorr2”-x3D-df-“Hu-0”-autocorr-2" class="headerlink" title="df[“Hu0_autocorr2”] = df[“Hu_0”].autocorr(2)"></a>df[“Hu0_autocorr2”] = df[“Hu_0”].autocorr(2)</h1><p>x = range(7)<br>z = lambda y : np.polyfit(x, y, 1)[0]<br>df[“Hu0_polyfit”] = roll_data.apply(z)</p><h1 id="一阶差分的均方差"><a href="#一阶差分的均方差" class="headerlink" title="一阶差分的均方差"></a>一阶差分的均方差</h1><p>roll_data_diff = df[‘Hu_0’].diff(1).rolling(window=7)<br>df[“Hu0_diff_std”] = roll_data_diff.std()<br>df</p><pre><code>![统计特征](https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202204/Characteristic-Engineering-of-Time-Series/统计特征.6ahmg2mw8s00.jpg)4. **利用tsfresh工具提取特征**先将原序列转换为n个窗口子序列。原表one_data结构为：![滚动窗口原表结构](https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202204/Characteristic-Engineering-of-Time-Series/滚动窗口原表结构.119hmuad0jy8.jpg)其中id,time列是在原表的基础上后加上的，目的是为了方便使用API接口函数。id代表组别，time代表时间顺序。然后使用API转换为窗口子序列。```pythonfrom tsfresh.utilities.dataframe_functions import roll_time_series# 滚动窗口#max_timeshift:最大偏移量，min_timeshift：最小偏移量，rolling_direction：每次移动的大小和方向。column_sort按什么排序，默认已从小到大排好df_rolled = roll_time_series(one_data, column_id="id", column_sort="time",max_timeshift = 6 ,min_timeshift = 6,rolling_direction=-1)df_rolled</code></pre><p><img lazyload="" src="/images/loading.svg" data-src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202204/Characteristic-Engineering-of-Time-Series/tsfresh%E7%AA%97%E5%8F%A3%E5%BA%8F%E5%88%97.4f2dy005fr40.jpg" alt="tsfresh窗口序列"><br>转化后的id是原id与原时间的组合，也为后面特征提取中的组别。（1，1）代表1号组别的第一个时间点组成的子序列，（1，43316）代表1号组别第43316个点组成的子序列。然后再进行特征提取.</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> tsfresh <span class="token keyword">import</span> extract_features<span class="token comment" spellcheck="true"># 特征提取,使用drop先删去多余的列，column_id为组别</span>df_features <span class="token operator">=</span> extract_features<span class="token punctuation">(</span>df_rolled<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"date"</span><span class="token punctuation">,</span><span class="token string">"time"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> column_id<span class="token operator">=</span><span class="token string">"id"</span><span class="token punctuation">)</span>df_features</code></pre><h3 id="2-3-2-特征预处理"><a href="#2-3-2-特征预处理" class="headerlink" title="2.3.2 特征预处理"></a>2.3.2 特征预处理</h3><p>首先处理表中的空值，因为前面窗口大小选为7，所以需要把表df（前面没有划分子窗口的表）的前六行删去，与df_features表的大小保持一致。df_features表中存在大量的空值，需要先将含空值的列删去。然后将df_features的索引设为df的索引，之后会利用concat函数将两表合并。又df表中，因为提取时序规律的特征中，头和尾存在许多空值，需要将其删除，然后取删除后的时间区段，选取df_features表的对应时间段。最后使用concat函数合并两表。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#删除前6行</span>df <span class="token operator">=</span> df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true"># 删除有空值的列</span>df_features <span class="token operator">=</span> df_features<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#设置索引</span>df_features<span class="token punctuation">.</span>index <span class="token operator">=</span> df<span class="token punctuation">.</span>index<span class="token comment" spellcheck="true">#删除空值行，此时查看表可以得到时间段</span>df <span class="token operator">=</span> df<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#合并两表</span>df_concat <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>df<span class="token punctuation">,</span>df_features<span class="token punctuation">[</span><span class="token string">'2022-01-26 13:12:00'</span><span class="token punctuation">:</span><span class="token string">'2022-02-24 03:13:00'</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token punctuation">,</span> axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>df_concat</code></pre><p>然后需要对特征无量纲化。使用标准化。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScalerscaler <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#因为上式返回结果为series，这里将其转换为表格形式。</span>df_Standar <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>scaler<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>df_concat<span class="token punctuation">)</span><span class="token punctuation">,</span>index<span class="token operator">=</span>df_concat<span class="token punctuation">.</span>index<span class="token punctuation">,</span> columns<span class="token operator">=</span>df_concat<span class="token punctuation">.</span>columns<span class="token punctuation">)</span>df_Standar</code></pre><h3 id="2-3-3-特征降维"><a href="#2-3-3-特征降维" class="headerlink" title="2.3.3 特征降维"></a>2.3.3 特征降维</h3><p>使用过滤法，利用方差和相关系数过滤特征。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 特征过滤 filter</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_selection <span class="token keyword">import</span> VarianceThreshold  X_train_columns <span class="token operator">=</span> df_Standar<span class="token punctuation">.</span>columns<span class="token comment" spellcheck="true">#方差过滤，返回方差大于设定阈值的列</span>selector <span class="token operator">=</span> VarianceThreshold<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span>X <span class="token operator">=</span> selector<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>df_Standar<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#因为上式返回结果为series，这里将其转换为表格形式。</span><span class="token comment" spellcheck="true">#X_train_columns[selector.get_support(indices=True)]结果为筛选后的列名</span>df_filter <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>X<span class="token punctuation">,</span>index<span class="token operator">=</span>df_concat<span class="token punctuation">.</span>index<span class="token punctuation">,</span> columns<span class="token operator">=</span>X_train_columns<span class="token punctuation">[</span>selector<span class="token punctuation">.</span>get_support<span class="token punctuation">(</span>indices<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>df_filter</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 特征过滤 相关系数corr</span><span class="token comment" spellcheck="true"># 剔除相关性系数高于threshold的corr_drop</span>corr_df <span class="token operator">=</span> df_filter<span class="token punctuation">.</span>corr<span class="token punctuation">(</span><span class="token punctuation">)</span>threshold <span class="token operator">=</span> <span class="token number">0.9</span><span class="token comment" spellcheck="true">#k=1,返回上三角矩阵</span>upper <span class="token operator">=</span> corr_df<span class="token punctuation">.</span>where<span class="token punctuation">(</span>np<span class="token punctuation">.</span>triu<span class="token punctuation">(</span>np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>corr_df<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>bool<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#返回相关系数大于阈值的列名</span>corr_drop <span class="token operator">=</span> <span class="token punctuation">[</span>column <span class="token keyword">for</span> column <span class="token keyword">in</span> upper<span class="token punctuation">.</span>columns <span class="token keyword">if</span> any<span class="token punctuation">(</span>upper<span class="token punctuation">[</span>column<span class="token punctuation">]</span><span class="token punctuation">.</span>abs<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> threshold<span class="token punctuation">)</span><span class="token punctuation">]</span>df_filter <span class="token operator">=</span> df_filter<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>corr_drop<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>df_filter</code></pre>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 时序数据 </tag>
            
            <tag> 异常处理 </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>c/c++编译流程</title>
      <link href="/compilation-process.html"/>
      <url>/compilation-process.html</url>
      
        <content type="html"><![CDATA[<p>c/c++程序从源代码到二进制程序的编译一般依靠编译工具GCC(GNU Compiler Collection)实现，具体流程分为4步：</p><ol><li>预处理(Preprocessing)</li><li>编译(Compilation)</li><li>汇编(Assemble)</li><li>链接(Linking)   <span id="more"></span></li></ol><h1 id="1-预处理"><a href="#1-预处理" class="headerlink" title="1.预处理"></a>1.预处理</h1><p>对.c或.h或.cpp文件进行预处理，使用预处理器将头文件内容复制到源代码中、删除注释、对宏进行替换等。处理后的文件后缀为.i，实际为完整的源代码，此时文件大小会大许多。gcc命令为:<br><code>gcc -E test.c -o test.i</code><br>-o是指定输出文件名。  </p><h1 id="2-编译"><a href="#2-编译" class="headerlink" title="2.编译"></a>2.编译</h1><p>将预处理文件转换为汇编语言的形式即汇编代码，处理后的文件后缀为.s。编译完后文件已经变得很小了。gcc命令为：<br><code>gcc -S test.i -o test.s</code></p><h1 id="3-汇编"><a href="#3-汇编" class="headerlink" title="3.汇编"></a>3.汇编</h1><p>对汇编代码进一步翻译为机器码，形成目标代码，处理后文件后缀为.o。gcc命令为：<br><code>gcc -c test.s -o test.o</code></p><h1 id="4-链接"><a href="#4-链接" class="headerlink" title="4.链接"></a>4.链接</h1><p>使用链接器将目标代码与其他目标代码、库代码、启动代码等链接起来生成可执行程序，处理后文件后缀为.out(windows下为.exe)。gcc命令为：<br><code>gcc test.o -o test</code><br>gcc工作流程示意图： </p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Compilation_process_img/gcc-compilation-process.33xk22nfohu0.webp" width="60%/"></div><p>注：直接编译为可执行程序的命令为：<code> gcc &lt;文件名&gt; -o &lt;生成的文件名&gt;</code><br>　　gcc命令对于c代码，g++命令对应c++代码。  </p><p>存在误区：</p><ul><li>并不是gcc只能编c，g++只能编c++，两者都可以。后缀为.c的gcc会认作c程序，g++会认作c++；而后缀为.cpp的，两者都会认为是c++程序。g++在编译阶段能调用gcc，而gcc不能自动和c++程序使用的库联结，所以需要g++完成链接，为了统一编译/链接都用了g++。  </li><li>gcc和g++都会定义_cplusplus宏，这个宏只标志编译器将代码按c还是c++语法解释。</li><li>编译能使用gcc/g++，因为在编译阶段g++能自动调用gcc，两者等价；但gcc不能进行库连接，所以链接用g++或gcc -lstdc++。</li></ul>]]></content>
      
      
      <categories>
          
          <category> c++ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> c++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习笔记</title>
      <link href="/machine-learning-notes.html"/>
      <url>/machine-learning-notes.html</url>
      
        <content type="html"><![CDATA[<pre><code>机器学习三要素：数据、算法、模型简单来说，机器学习就是利用已有的数据通过选择的算法训练模型，用以预测分析。</code></pre> <span id="more"></span><h1 id="1-机器学习算法分类"><a href="#1-机器学习算法分类" class="headerlink" title="1 机器学习算法分类"></a>1 机器学习算法分类</h1><ul><li><strong>监督学习</strong>：输入的数据有标签。<br>  对于离散数据，标签用于分类，可以归结为分类问题。<br>  对于连续数据标签，归结为回归问题。</li><li><strong>无监督学习</strong>：输入数据无标签。</li></ul><h1 id="2-开发流程"><a href="#2-开发流程" class="headerlink" title="2 开发流程"></a>2 开发流程</h1><ol><li>收集数据。要考虑到后续分析所需要的数据，选取重要特征、足够多的数据等。</li><li>准备数据。实际中，收集到的数据可能存在很多问题，需要进行数据清洗。然后再将其划分为训练集(占比较大)和测试集。</li><li>选择模型。根据实际情况，选择合适的模型。监督学习模型和无监督学习模型。</li><li>训练。使用训练集数据对选择的模型进行训练，需要反复测试。</li><li>评估。对训练出的模型，用测试集进行测试，检验其性能好坏。评估指标主要有：准确率、召回率、F值。</li><li>参数调整。主要是调整参数对模型进行改进。</li><li>预测。将模型应用于实际，对相关问题进行预测。</li></ol><h1 id="3-学习工具"><a href="#3-学习工具" class="headerlink" title="3 学习工具"></a>3 学习工具</h1><ol><li>机器学习库：sklearn。Python的机器学习工具，包含许多机器学习算法的实现。</li><li>数据集：scikit-learn、kaggle、UCI</li><li>开发工具：pycharm、vscode、Jupyter notebook(网页版可视化)</li></ol><h1 id="4-特征工程"><a href="#4-特征工程" class="headerlink" title="4 特征工程"></a>4 特征工程</h1><p>  在使用模型进行训练前，需要对原始数据展开特征工程，目的是为了更高效的利用算法，能影响机器学习的效果。<br>  包含三个步骤：特征提取、特征预处理、特征降维。</p><h2 id="4-1-特征提取"><a href="#4-1-特征提取" class="headerlink" title="4.1 特征提取"></a>4.1 特征提取</h2><pre><code>从原本的数据集中提取出适合机器学习的数据。  主要是为了解决三个问题:  </code></pre><ul><li>原始数据特征中的强相关性造成的冗余信息。  </li><li>原始数据十分稀疏.</li><li>原始数据维度较大。<blockquote><p>API: sklearn.feature_extraction</p></blockquote></li></ul><h2 id="4-2-特征预处理"><a href="#4-2-特征预处理" class="headerlink" title="4.2 特征预处理"></a>4.2 特征预处理</h2><p>  对特征无量纲化，目的是让特征处于同等地位。常见方法有：归一化和标准化。</p><h3 id="4-2-1-归一化"><a href="#4-2-1-归一化" class="headerlink" title="4.2.1 归一化"></a>4.2.1 归一化</h3><p>  将原始数据映射到[0，1]之间。公式为：<br>  $x’=\frac {x-min}{max-min}$　　　$x’’=x’*(mx-mi)+mi$<br>  其中，ｘ’’为最终结果，max为一列中的最大值，min为一列中的最小值。mx,mi为指定映射的区间，通常mx=1,mi=0<br>  缺点：当数据存在较多异常点是，会影响归一化结果。该方法鲁棒性差，只适合精确小数据场景。  </p><blockquote><p>API: sklearn.preprocessing.MinMaxScaler(feature_range=(0,1)…)</p></blockquote><h3 id="4-2-2-标准化"><a href="#4-2-2-标准化" class="headerlink" title="4.2.2 标准化"></a>4.2.2 标准化</h3><p>  将数据变换为均值为0，标准差为1的范围内。公式为:<br>  $x’=\frac{x-\overline x}{\sigma}$<br>  作用于每一列，$\overline x$ 为平均值，$\sigma$ 为标准差<br>  平均值和标准差受异常值影响较小，标准化方法能一定程度上克服异常点带来的干扰。适用于样本数量大的情况。</p><blockquote><p>API: sklearn.preprocessing.StandardScaler()  </p></blockquote><h2 id="4-3-特征降维"><a href="#4-3-特征降维" class="headerlink" title="4.3 特征降维"></a>4.3 特征降维</h2><p>  减少相关性较强的特征，得到一组不相关的主变量。常见方法有：特征选择和主成分分析。  </p><h3 id="4-3-1-特征选择"><a href="#4-3-1-特征选择" class="headerlink" title="4.3.1 特征选择"></a>4.3.1 特征选择</h3><p>  在原有的冗余特征中找出主要特征。</p><ul><li>Filter(过滤式): <ul><li>方差选择法：过滤低方差特征<blockquote><p>API: sklearn.feature_selection.VarianceThreshold(threshold = 0.0)  </p></blockquote></li><li>相关系数： 过滤相关程度高的特征,常用有皮尔逊相关系数。对于相关性程度高的特征：<ol><li>选取其中一个</li><li>加权求和</li><li>主成分分析<blockquote><p>API: scipy.stats.pearsonr</p></blockquote></li></ol></li></ul></li><li>Embedded(嵌入式)：<ul><li>决策树</li><li>正则化 <h3 id="4-3-2-主成分分析-PCA"><a href="#4-3-2-主成分分析-PCA" class="headerlink" title="4.3.2 主成分分析(PCA)"></a>4.3.2 主成分分析(PCA)</h3>将n维特征映射到k维上，实现特征降维，减少复杂度。一般用于回归分析或聚类。<blockquote><p>API: sklearn.decomposition.PCA(n_components=None)  </p></blockquote><h1 id="5-模型选择与调优"><a href="#5-模型选择与调优" class="headerlink" title="5. 模型选择与调优"></a>5. 模型选择与调优</h1><p>一般来说，模型调优有3个方向：选择更好的算法，调优模型参数，改进数据。这里简单说下模型参数调优。<br>模型参数调优有两步：交叉验证(cross validation)和超参数搜索-网格搜索(Grid Search)。</p></li></ul></li><li>交叉验证：对于训练集数据，再次将其划分为训练集和验证集，用以评估模型预测准确性，让模型更加准确可信。限制模型过拟合、欠拟合等问题。</li><li>超参数搜索-网格搜索:对于算法中需要自定义的参数，叫超参数。对模型预设几种超参数组合，同时训练，选出最优参数组合。<blockquote><p>API: sklearn.model_selection.GridSearchCV  (同时进行交叉验证和网格搜索)</p></blockquote></li></ul><h1 id="6-总结"><a href="#6-总结" class="headerlink" title="6.总结"></a>6.总结</h1><p>机器学习实战流程：</p><ol><li>导入数据</li><li>划分数据集</li><li>特征工程</li><li>模型训练与调优</li><li>模型评估</li></ol>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
