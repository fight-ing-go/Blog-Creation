<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="keywords" content="Hexo Theme Keep"><meta name="description" content="fighting"><meta name="author" content="EasyBoy"><title>时序数据异常检测流程与项目实战 | EasyBoy</title><link rel="stylesheet" href="/css/style.css"><link rel="shortcut icon" href="/images/cell-16x16-next.png"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/css/font-awesome.min.css"><script id="hexo-configurations">let KEEP=window.KEEP||{};KEEP.hexo_config={hostname:"easyboy-blog.com",root:"/",language:"zh-CN",path:"search.xml"},KEEP.theme_config={toc:{enable:!0,number:!1,expand_all:!0,init_open:!0},style:{primary_color:"#0066CC",avatar:"/images/avatar.jpeg",favicon:"/images/cell-16x16-next.png",article_img_align:"left",left_side_width:"260px",content_max_width:"920px",hover:{shadow:!1,scale:!1},first_screen:{enable:!0,background_img:"https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/wallpaper_img/wallhaven-k7g117_1920x1080.9rq9no91ra0.jpg",description:"Welcome to Easyboy's Blog"},scroll:{progress_bar:{enable:!1},percent:{enable:!1}}},local_search:{enable:!0,preload:!0},code_copy:{enable:!0,style:"default"},pjax:{enable:!0},lazyload:{enable:!0},version:"3.4.5"},KEEP.language_ago={second:"%s 秒前",minute:"%s 分钟前",hour:"%s 小时前",day:"%s 天前",week:"%s 周前",month:"%s 个月前",year:"%s 年前"}</script><meta name="generator" content="Hexo 6.0.0"><link rel="alternate" href="/atom.xml" title="home-laser" type="application/atom+xml">

<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head><body><div class="progress-bar-container"><span class="pjax-progress-bar"></span> <span class="pjax-progress-icon"><i class="fas fa-circle-notch fa-spin"></i></span></div><main class="page-container"><div class="page-main-content"><div class="page-main-content-top"><header class="header-wrapper"><div class="header-content"><div class="left"><a class="logo-image" href="/"><img src="/images/cell-32x32-next.png"> </a><a class="logo-title" href="/">EasyBoy</a></div><div class="right"><div class="pc"><ul class="menu-list"><li class="menu-item"><a href="/">首页</a></li><li class="menu-item"><a href="/archives">归档</a></li><li class="menu-item"><a href="/categories">分类</a></li><li class="menu-item"><a href="/tags">标签</a></li><li class="menu-item"><a href="/about">关于</a></li><li class="menu-item search search-popup-trigger"><i class="fas fa-search"></i></li></ul></div><div class="mobile"><div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div><div class="icon-item menu-bar"><div class="menu-bar-middle"></div></div></div></div></div><div class="header-drawer"><ul class="drawer-menu-list"><li class="drawer-menu-item flex-center"><a href="/">首页</a></li><li class="drawer-menu-item flex-center"><a href="/archives">归档</a></li><li class="drawer-menu-item flex-center"><a href="/categories">分类</a></li><li class="drawer-menu-item flex-center"><a href="/tags">标签</a></li><li class="drawer-menu-item flex-center"><a href="/about">关于</a></li></ul></div><div class="window-mask"></div></header></div><div class="page-main-content-middle"><div class="main-content"><div class="fade-in-down-animation"><div class="article-content-container"><div class="article-title"><span class="title-hover-animation">时序数据异常检测流程与项目实战</span></div><div class="article-header"><div class="avatar"><img src="/images/avatar.jpeg"></div><div class="info"><div class="author"><span class="name">EasyBoy</span></div><div class="meta-info"><div class="article-meta-info"><span class="article-date article-meta-item"><i class="fas fa-edit"></i>&nbsp; <span class="pc">2022-03-25 20:23:25</span> <span class="mobile">2022-03-25 20:23</span><span class="pc">更新于：2022-04-15</span> </span><span class="article-categories article-meta-item"><i class="fas fa-folder"></i>&nbsp;<ul><li><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>&nbsp;</li></ul></span><span class="article-tags article-meta-item"><i class="fas fa-tags"></i>&nbsp;<ul><li><a href="/tags/%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE/">时序数据</a>&nbsp;</li><li>| <a href="/tags/%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/">异常处理</a>&nbsp;</li><li>| <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>&nbsp;</li></ul></span><span class="article-wordcount article-meta-item"><i class="fas fa-file-word"></i>&nbsp;<span>6.9k 字</span> </span><span class="article-pv article-meta-item"><i class="fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span></span></div></div></div></div><div class="article-content markdown-body"><p>本文主要内容为对时序数据异常检测流程进行简单介绍，然后通过项目实战进行详细解释。全文内容根据个人实际经验所得。</p><h1 id="1-总体流程介绍"><a href="#1-总体流程介绍" class="headerlink" title="1.总体流程介绍"></a>1.总体流程介绍</h1><p>针对项目中传感器数据异常检测，经调研后，个人初步总结工程上实现异常检测的流程。流程框图如下图所示：<br><span id="more"></span></p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Anomaly_detection_process.6l6blsl243s0.jpg" width="60%/"></div><p>总体步骤有五步：</p><ol><li>数据清洗：对数据做初步处理，方便后续的数据分析。包括时间戳的转换（因为是时序数据，需要对时间列做专门处理）、数据重采样（修改时间频率）、缺失值处理、异常值处理、数据平滑处理</li><li>探索性数据分析EDA：通过作图、制表、方程拟合、计算特征量等手段探索数据的结构和规律的一种数据分析方法。主要是利用各种方式自由探索数据分布、数据相关性等。</li><li>特征提取/相关性分析：对于单维序列，因为缺乏可用特征，需要进行特征提取，以便后续训练模型，时序序列中比较重要的特征是周比环比。对于多维序列，需要先进行相关性分析，剔除相关性强的数据。</li><li>训练模型：对数据分析后选择合适的算法进行建模，用提取出的特征或若相关数据进行模型训练。</li><li>异常检测：利用训练好的模型检测实际数据。单维常用算法有LSTM + Vae，通过预测的方式检测异常；多维可利用孤立森林、SVM、kmeans等。</li></ol><h1 id="2-项目实战"><a href="#2-项目实战" class="headerlink" title="2.项目实战"></a>2.项目实战</h1><p>利用工具：jupyter notebook; 语言：python</p><h2 id="2-1-数据清洗"><a href="#2-1-数据清洗" class="headerlink" title="2.1 数据清洗"></a>2.1 数据清洗</h2><p>实现目标：提取csv文件数据，处理缺失值、异常值、数据平滑化，完成数据清洗。<br>首先加载必要库:</p><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np 
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd 
<span class="token keyword">import</span> random <span class="token keyword">as</span> rd 
<span class="token keyword">import</span> datetime 
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt 
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>dates <span class="token keyword">as</span> mdate
<span class="token keyword">from</span> statsmodels<span class="token punctuation">.</span>tsa<span class="token punctuation">.</span>seasonal <span class="token keyword">import</span> seasonal_decompose
<span class="token keyword">from</span> statsmodels<span class="token punctuation">.</span>graphics<span class="token punctuation">.</span>tsaplots <span class="token keyword">import</span> plot_acf
<span class="token keyword">from</span> statsmodels<span class="token punctuation">.</span>graphics<span class="token punctuation">.</span>tsaplots <span class="token keyword">import</span> plot_pacf
<span class="token keyword">import</span> seaborn <span class="token keyword">as</span> sns
<span class="token keyword">from</span> statsmodels<span class="token punctuation">.</span>tsa<span class="token punctuation">.</span>stattools <span class="token keyword">import</span> adfuller
<span class="token keyword">from</span> scipy <span class="token keyword">import</span> signal
<span class="token keyword">import</span> warnings
warnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">"ignore"</span><span class="token punctuation">)</span>
</code></pre><p>提取csv文件,利用pd.read_csv()函数可完整提取表中全部内容，函数有很多参数可以选择，实现众多功能</p><pre class="language-python"><code class="language-python"><span class="token comment" spellcheck="true">#读取表格数据</span>
data1 <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./data/componet.csv'</span><span class="token punctuation">)</span>
data2 <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./data/tehu.csv'</span><span class="token punctuation">)</span>
data1 <span class="token comment" spellcheck="true">#展示data1中数据</span>
</code></pre><p>表格数据如图所示：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet.4mjopka34v80.jpg" width="60%/"></div><p>查询表中是否有缺失值，使用.isnull()查询，返回含有缺失值的行。我的数据没有缺失值，表为空，就不展示了。</p><pre class="language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 查看缺失值</span>
pivot_data<span class="token punctuation">[</span>pivot_data<span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T<span class="token punctuation">.</span>any<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre><p>将data1中时间列数据设置为索引，方便查询，也方便可视化</p><pre class="language-python"><code class="language-python">data1<span class="token punctuation">.</span>index <span class="token operator">=</span> pd<span class="token punctuation">.</span>to_datetime<span class="token punctuation">(</span>data1<span class="token punctuation">.</span>Datetime<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#设置时间列为索引</span>
data1
</code></pre><p>设置完后数据：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_index.78rh4tnfar00.jpg" width="60%/"></div><p>先对未处理的数据进行可视化，看看数据形态：</p><pre class="language-python"><code class="language-python"><span class="token comment" spellcheck="true">#可视化</span>
<span class="token keyword">for</span> c_disc <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'Comp0_Te'</span><span class="token punctuation">,</span><span class="token string">'Comp1_Te'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    t_disc <span class="token operator">=</span> tmp_data1<span class="token punctuation">[</span>c_disc<span class="token punctuation">]</span>
    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>c_disc<span class="token punctuation">)</span>    
    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span>c_disc<span class="token punctuation">)</span>    
    plt<span class="token punctuation">.</span>gca<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>xaxis<span class="token punctuation">.</span>set_major_formatter<span class="token punctuation">(</span>mdate<span class="token punctuation">.</span>DateFormatter<span class="token punctuation">(</span><span class="token string">'%Y-%m-%d'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#设置x轴显示格式</span>
    <span class="token comment" spellcheck="true">#设置x轴显示范围，freq代表间隔频率，tmp_data1.index[0]代表起始时间,tmp_data1.index[-1]代表结束时间</span>
    plt<span class="token punctuation">.</span>xticks<span class="token punctuation">(</span>pd<span class="token punctuation">.</span>date_range<span class="token punctuation">(</span>tmp_data1<span class="token punctuation">.</span>index<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>tmp_data1<span class="token punctuation">.</span>index<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>freq<span class="token operator">=</span><span class="token string">'D'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>rotation<span class="token operator">=</span><span class="token number">45</span><span class="token punctuation">)</span> 
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>t_disc<span class="token punctuation">)</span>
</code></pre><p>其中一个曲线示意图：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_plot.4833uxky2zg0.jpg" width="100%/"></div><p>可以看出，数据有明显的异常点，要么很大，要么很小。为了后面的数据分析与模型训练，我们所以需要对这些明显的异常点进行简单处理。处理方式为使用箱型图，筛选出异常点，然后用前值进行替换。 在此之前，我们先对时间索引进行处理。在这里，我的数据采样间隔大致为2s，但并不固定。因此，在尽可能不影响原数据的情况下，将重采样间隔设置为2S，只做规范时间频率使用。使用resample()函数处理。</p><pre class="language-python"><code class="language-python"><span class="token comment" spellcheck="true">#重采样 </span>
tmp_data1 <span class="token operator">=</span> data1<span class="token punctuation">.</span>resample<span class="token punctuation">(</span><span class="token string">'2S'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#时间间隔取2S，mean()取平均值,用tmp_data1接收转换后的表，不改变原表内容</span>
tmp_data1
</code></pre><p>重采样后的数据：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_resample.tfaifs2cgrk.jpg" width="100%/"></div><p>可以看出，数据时间间隔已变为2S等距，且值也有所变化，因为非等距时间间隔，不可避免地出现了缺失值。因此下一步对缺失值进行<strong>填补</strong>。填补策略为：对短时间缺失数据填补，长时间缺失数据删除。填补使用缺失点前7个历史数据的均值填补，以是否连续缺失十个点判断是否是长时间缺失数据。这里自己写了个填补函数用于实现上面的功能。（对于几百万的数据量，填补时间很长，有一两小时）</p><pre class="language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">nmeans_fill_missing</span><span class="token punctuation">(</span>fill_col<span class="token punctuation">,</span> df <span class="token punctuation">,</span> window<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> time_range <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">'''
        实现功能： 对表格中的某一列的缺失值进行填补，使用邻近历史数据的均值填补，对于大范围缺失点，不进行填补，可对均值窗口、缺失时间范围进行设置
        fill_col: 选择插值的列，可填名字，也可填index
        df: DataFrame,输入需要插值的表
        window: 插值窗口大小
        time_range: 设置判断长时间间隔的点数
        '''</span>
        <span class="token comment" spellcheck="true"># count记录起始位置，每当遇到长间隔空值点，会将count移动到下一个非空值点</span>
        count <span class="token operator">=</span> <span class="token number">0</span>
        i<span class="token operator">=</span><span class="token number">0</span>
        <span class="token keyword">while</span> i <span class="token operator">&lt;</span> len<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># count += 1</span>
            value <span class="token operator">=</span> np<span class="token punctuation">.</span>isnan<span class="token punctuation">(</span>df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">#判断当前值是否为空</span>
            <span class="token keyword">if</span> value <span class="token operator">==</span> <span class="token boolean">True</span><span class="token punctuation">:</span>
                <span class="token comment" spellcheck="true"># 判断当前空值点是否是长间隔</span>
                islonginterval <span class="token operator">=</span> islong_missing<span class="token punctuation">(</span>fill_col<span class="token punctuation">,</span> df <span class="token punctuation">,</span> range_window<span class="token operator">=</span>time_range<span class="token punctuation">,</span> row_index<span class="token operator">=</span>i<span class="token punctuation">)</span>
                <span class="token comment" spellcheck="true">#当遇到长间隔空值时，将count一直移动到下一个非空点</span>
                <span class="token keyword">if</span> islonginterval<span class="token punctuation">:</span>
                    i <span class="token operator">+=</span> time_range
                    <span class="token keyword">while</span> value <span class="token operator">==</span><span class="token boolean">True</span> <span class="token operator">and</span> i<span class="token operator">&lt;</span>len<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">:</span>
                        value <span class="token operator">=</span> np<span class="token punctuation">.</span>isnan<span class="token punctuation">(</span>df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
                        i <span class="token operator">+=</span><span class="token number">1</span>
                    count <span class="token operator">=</span> i   
                <span class="token keyword">else</span><span class="token punctuation">:</span>  
                    <span class="token keyword">if</span> i <span class="token operator">-</span> count <span class="token operator">&lt;=</span> window<span class="token punctuation">:</span>         <span class="token comment" spellcheck="true">#判断当前位置是否有足够历史数据进行插值</span>
                        <span class="token keyword">if</span> i<span class="token operator">+</span>window<span class="token operator">>=</span>len<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token comment" spellcheck="true">#如果已经到了表格末尾，后续数据不够进行填补，直接略过剩下的点。该策略仅针对数据量足够大的情况</span>
                            <span class="token keyword">break</span>
                        train_value_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>   <span class="token comment" spellcheck="true">#用于当历史数据不够的情况存放窗口内的点，如 [1,2,3,current:NAN,5,6,7]  此时历史数据不够，则取从1开始的7个点，掠过略过空值</span>
                        <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>window<span class="token punctuation">)</span><span class="token punctuation">:</span>
                            train_value <span class="token operator">=</span> np<span class="token punctuation">.</span>isnan<span class="token punctuation">(</span>df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>j<span class="token operator">+</span>count<span class="token punctuation">]</span><span class="token punctuation">)</span> 
                            <span class="token keyword">if</span> train_value <span class="token operator">==</span> <span class="token boolean">False</span><span class="token punctuation">:</span>
                                train_value_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>j<span class="token operator">+</span>count<span class="token punctuation">]</span><span class="token punctuation">)</span>
                        df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>train_value_list<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
                    <span class="token keyword">else</span><span class="token punctuation">:</span>
                        df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">[</span>i <span class="token operator">-</span> window<span class="token punctuation">:</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#如果窗口大小满足，取前window内的均值填补</span>
            i <span class="token operator">+=</span><span class="token number">1</span>

        <span class="token keyword">return</span> df

<span class="token comment" spellcheck="true"># 判断当前空值点是否是长间隔</span>
<span class="token keyword">def</span> <span class="token function">islong_missing</span><span class="token punctuation">(</span>fill_col<span class="token punctuation">,</span> df <span class="token punctuation">,</span> range_window<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> row_index<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">'''
        判断当前空值点是否是长间隔
        df: DataFrame,输入需要插值的表  
        window:插值窗口大小
        range_window: 设置判断长时间间隔的点数
        fill_col: 选择插值的列,可填名字.也可填index
        row_index: 开始判断的起始索引
        '''</span>

        islonginterval <span class="token operator">=</span> <span class="token boolean">True</span>    <span class="token comment" spellcheck="true">#判断当前空值是否属于长时间范围内的空值，是的话就跳过，不进行插值填补</span>
        count <span class="token operator">=</span> <span class="token number">1</span>
        <span class="token comment" spellcheck="true"># 判断逻辑：判断后续十个时间点是否为空，当存在一个非空点，即跳出循环，且islonginterval为false</span>
        <span class="token keyword">while</span> row_index<span class="token operator">+</span>count<span class="token operator">&lt;</span>len<span class="token punctuation">(</span>df<span class="token punctuation">)</span> <span class="token operator">and</span> islonginterval<span class="token operator">==</span><span class="token boolean">True</span> <span class="token operator">and</span> count<span class="token operator">&lt;=</span>range_window<span class="token punctuation">:</span>
            islonginterval <span class="token operator">=</span> np<span class="token punctuation">.</span>isnan<span class="token punctuation">(</span>df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>row_index<span class="token operator">+</span>count<span class="token punctuation">]</span><span class="token punctuation">)</span>
            count <span class="token operator">+=</span><span class="token number">1</span>

        <span class="token keyword">return</span> islonginterval

<span class="token comment" spellcheck="true">#对两列分别填补</span>
<span class="token keyword">for</span> c_disc <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'Comp0_Te'</span><span class="token punctuation">,</span><span class="token string">'Comp1_Te'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    tmp_data1 <span class="token operator">=</span> nmeans_fill_missing<span class="token punctuation">(</span>c_disc<span class="token punctuation">,</span> tmp_data1<span class="token punctuation">,</span> window<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">)</span>
tmp_data1
</code></pre><p>为了检验填补效果，又写了个子函数，用来获取每次检测到的长间隔时间端的开始时间和结束时间对于的行数。根据返回的结果，查询对应的时间信息，判断是否满足填补策略</p><pre class="language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">find_long_missing</span><span class="token punctuation">(</span>fill_col<span class="token punctuation">,</span> df <span class="token punctuation">,</span> time_range <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">'''
        实现功能： 获取长间隔断点的点信息，返回dot_list数组，每两个为一对时间段
        fill_col: 选择插值的列，可填名字，也可填index
        df: DataFrame,输入需要插值的表
        time_range: 设置判断长时间间隔的点数
        '''</span>
        <span class="token comment" spellcheck="true"># count记录起始位置，每当遇到长间隔空值点，会将count移动到下一个非空值点</span>
        i<span class="token operator">=</span><span class="token number">0</span>
        dot_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">while</span> i <span class="token operator">&lt;</span> len<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">:</span>
            value <span class="token operator">=</span> np<span class="token punctuation">.</span>isnan<span class="token punctuation">(</span>df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">#判断当前值是否为空</span>
            <span class="token keyword">if</span> value <span class="token operator">==</span> <span class="token boolean">True</span><span class="token punctuation">:</span>
                <span class="token comment" spellcheck="true"># 判断当前空值点是否是长间隔</span>
                islonginterval <span class="token operator">=</span> islong_missing<span class="token punctuation">(</span>fill_col<span class="token punctuation">,</span> df <span class="token punctuation">,</span> range_window<span class="token operator">=</span>time_range<span class="token punctuation">,</span> row_index<span class="token operator">=</span>i<span class="token punctuation">)</span>
                <span class="token comment" spellcheck="true">#当遇到长间隔空值时，将count一直移动到下一个非空点</span>
                <span class="token keyword">if</span> islonginterval<span class="token punctuation">:</span>
                    dot_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>
                    i <span class="token operator">+=</span> <span class="token punctuation">(</span>time_range<span class="token number">-1</span><span class="token punctuation">)</span>
                    <span class="token keyword">while</span> value <span class="token operator">==</span><span class="token boolean">True</span> <span class="token operator">and</span> i<span class="token operator">&lt;</span>len<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">:</span>
                        i <span class="token operator">+=</span><span class="token number">1</span>
                        value <span class="token operator">=</span> np<span class="token punctuation">.</span>isnan<span class="token punctuation">(</span>df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
                        
                    dot_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>   
            i <span class="token operator">+=</span><span class="token number">1</span>
        <span class="token keyword">return</span> dot_list
</code></pre><p>然后删除缺失值并导出。使用reset_index()是为了让时间索引一起导出来。这里用的导出方法缺点是索引需要自己手动加上去。</p><pre class="language-python"><code class="language-python"><span class="token comment" spellcheck="true">#删除缺失值</span>
tmp_data1 <span class="token operator">=</span> tmp_data1<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> how <span class="token operator">=</span> <span class="token string">'all'</span><span class="token punctuation">,</span>inplace <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#避免之后重新填补，导出经插值，删除空值后的表</span>
path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>abspath<span class="token punctuation">(</span>r<span class="token string">'./data/l1_tehu'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 文件夹路径</span>
new_file_name <span class="token operator">=</span> <span class="token string">'tmp_data1_insert.csv'</span>
tmp_data1<span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span>path <span class="token operator">+</span> <span class="token string">'/'</span> <span class="token operator">+</span> new_file_name<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'a'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'gbk'</span><span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
</code></pre><p>下面对前面的<strong>异常值</strong>进行处理。这里只选取其中一个片段进行示范。</p><pre class="language-python"><code class="language-python">twoday_data <span class="token operator">=</span> tmp_data1<span class="token punctuation">[</span><span class="token string">'2021-11-01 18:58:30'</span><span class="token punctuation">:</span> <span class="token string">'2021-11-03 11:35:00'</span><span class="token punctuation">]</span>
twoday_data<span class="token punctuation">.</span>describe<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#描述表的一些信息</span>
</code></pre><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_twoday_describe.3qyix6pukji0.jpg" width="40%/"></div><p>画出箱线图，可以看出存在的一些异常点：</p><pre class="language-python"><code class="language-python">plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>boxplot<span class="token punctuation">(</span>twoday_data<span class="token punctuation">[</span><span class="token string">'Comp0_Te'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>boxplot<span class="token punctuation">(</span>twoday_data<span class="token punctuation">[</span><span class="token string">'Comp1_Te'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_twoday_boxplot.705wl11k1jo0.jpg" width="60%/"></div><p>然后利用四分位，删除异常值并用前值进行填补。</p><pre class="language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 超过了上四分位2倍四分位距或下四分位2倍距离都算异常值，用上一个值填充</span>
a <span class="token operator">=</span> twoday_data<span class="token punctuation">[</span><span class="token string">'Comp0_Te'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>quantile<span class="token punctuation">(</span><span class="token number">0.75</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> twoday_data<span class="token punctuation">[</span><span class="token string">'Comp0_Te'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>quantile<span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">)</span>
c <span class="token operator">=</span> twoday_data<span class="token punctuation">[</span><span class="token string">'Comp0_Te'</span><span class="token punctuation">]</span>
c<span class="token punctuation">[</span><span class="token punctuation">(</span>c<span class="token operator">>=</span><span class="token punctuation">(</span>a<span class="token operator">-</span>b<span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">2</span><span class="token operator">+</span>a<span class="token punctuation">)</span><span class="token operator">|</span><span class="token punctuation">(</span>c<span class="token operator">&lt;=</span>b<span class="token operator">-</span><span class="token punctuation">(</span>a<span class="token operator">-</span>b<span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token operator">=</span>np<span class="token punctuation">.</span>nan
c<span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>method<span class="token operator">=</span><span class="token string">'pad'</span><span class="token punctuation">,</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
twoday_data<span class="token punctuation">[</span><span class="token string">'Comp0_Te'</span><span class="token punctuation">]</span> <span class="token operator">=</span> c
<span class="token keyword">print</span><span class="token punctuation">(</span>twoday_data<span class="token punctuation">[</span><span class="token string">'Comp0_Te'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>describe<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_twoday_boxplot_new.44m969zxzbg0.jpg" width="60%/"></div><p>异常值处理完后，还有数据平滑处理。平滑处理在第二张表中演示。下面处理第二张表的数据。同样的操作，先将时间列设为索引，展示data2中数据：</p><pre class="language-python"><code class="language-python">data2<span class="token punctuation">.</span>index <span class="token operator">=</span> pd<span class="token punctuation">.</span>to_datetime<span class="token punctuation">(</span>data2<span class="token punctuation">.</span>Datetime<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#设置时间列为索引</span>
data2
</code></pre><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/L1_id_data.6dh59h41kq40.jpg" width="40%/"></div><p>表中有个ID列，表示各个传感器的型号，做数据分析时，可以将ID列提取出来，作为列索引，方便观察。因此，先对表格进行<strong>透视</strong>：</p><pre class="language-python"><code class="language-python"><span class="token comment" spellcheck="true">#数据透视</span>
<span class="token comment" spellcheck="true">#tmp_data2用来拷贝data2数据变为二重索引表，原表数据保留 </span>
tmp_data2<span class="token operator">=</span>data2   
tmp_data2<span class="token punctuation">[</span><span class="token string">'L1_id'</span><span class="token punctuation">]</span> <span class="token operator">=</span> tmp_data2<span class="token punctuation">[</span><span class="token string">'L1_id'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>str<span class="token punctuation">)</span>
tmp_data2<span class="token operator">=</span>data2<span class="token punctuation">.</span>pivot_table<span class="token punctuation">(</span>index<span class="token operator">=</span><span class="token string">'Datetime'</span><span class="token punctuation">,</span>columns<span class="token operator">=</span><span class="token string">'L1_id'</span><span class="token punctuation">)</span>
tmp_data2
</code></pre><p>透视结果如下所示：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/L1_id_pivot.2ab6wthn3ack.jpg" width="100%/"></div><p>表格的列变成了二重索引，为了方便后续引用，将其变为一重索引。需要注意的是，这种变换需要数据类型都为string型，如果不是，需要提前转换。当然，还有一种手动方法，变为二重索引后导出表，将原列索引删除，自己再加上索引就好。</p><pre class="language-python"><code class="language-python"><span class="token comment" spellcheck="true">#改为一重列索引表，用one_class_data2表示</span>
one_class_data2 <span class="token operator">=</span>tmp_data2<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>deep<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#拷贝表格</span>
one_class_data2<span class="token punctuation">.</span>columns <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"_"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> one_class_data2<span class="token punctuation">.</span>columns<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true">#将原来的二重索引的列名进行拼接</span>
<span class="token comment" spellcheck="true"># one_class_data2.columns = tmp_data2.columns.droplevel(0)  #这个方法是直接将外围第二重索引去掉，只取第一重列索引。</span>
one_class_data2
</code></pre><p>结果如下：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/L1_id_oneclass.59gip30dtvk0.jpg" width="100%/"></div><p>可以看到，列已经变为一重，列名为二重列名拼接而成。后续步骤与第一张表一样，这里不再做解释。最后再对其进行<strong>平滑处理</strong>。平滑方式选用传统的<em>巴特沃斯</em> 低通滤波器。对于参数wn的确定，首先采样频率定为1=采样长度/采样时间（其实采样频率可以自己定，其他的频率以采样频率为基准进行计算即可，结果都一样）。截止频率需要根据实际的来，我的数据中最大的频率差不多以77个点为一个周期，所以稍微扩大下范围后计算截止频率 = 1/60（采样频率为1，那么采样时间即为周期T=1）。根据公式wn = 2*截止频率/采样频率 = 0.033。以两天的数据量为例。</p><pre class="language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 低通滤波器-巴特沃斯</span>
<span class="token comment" spellcheck="true"># wn=2*截至频率/采样频率   如果一天采样10个点，采样频率为10，截止频率为想要滤除的频率上限或下限</span>
<span class="token comment" spellcheck="true"># pivot_data为透视后清理完的表</span>
twoday_data <span class="token operator">=</span> pivot_data<span class="token punctuation">[</span><span class="token string">'2022-01-26 00:00:00'</span><span class="token punctuation">:</span><span class="token string">'2022-01-28 00:00:00'</span><span class="token punctuation">]</span>
b<span class="token punctuation">,</span> a <span class="token operator">=</span> signal<span class="token punctuation">.</span>butter<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">0.033</span><span class="token punctuation">,</span> <span class="token string">'lowpass'</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#配置滤波器 8 表示滤波器的阶数</span>
twoday_data<span class="token punctuation">[</span><span class="token string">'Te_0_filter'</span><span class="token punctuation">]</span> <span class="token operator">=</span> signal<span class="token punctuation">.</span>filtfilt<span class="token punctuation">(</span>b<span class="token punctuation">,</span> a<span class="token punctuation">,</span> twoday_data<span class="token punctuation">[</span><span class="token string">'Te_0'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre><p>滤波结果如下：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/butter.6leaq5g4j7s0.jpg" width="50%/"></div><h2 id="2-2-探索性数据分析EDA"><a href="#2-2-探索性数据分析EDA" class="headerlink" title="2.2 探索性数据分析EDA"></a>2.2 探索性数据分析EDA</h2><p>首先进行相关性分析。这里以表data2为例。分析的数据取较完整地一个月的时间片段，重采样为1min适当减小数据量。（记得导入表后先设置时间索引）</p><pre class="language-python"><code class="language-python">Month_data2 <span class="token operator">=</span> data2<span class="token punctuation">[</span><span class="token string">'2022-01-25 13:12:30'</span><span class="token punctuation">:</span><span class="token string">'2022-02-24 15:13:00'</span><span class="token punctuation">]</span>
<span class="token comment" spellcheck="true"># 重采样一分钟(一个月数据)</span>
Month_data2_1T <span class="token operator">=</span> Month_data2<span class="token punctuation">.</span>resample<span class="token punctuation">(</span><span class="token string">'T'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
Month_data2_1T<span class="token operator">=</span>Month_data2_1T<span class="token punctuation">.</span>round<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#保留两位小数。</span>
<span class="token comment" spellcheck="true"># 相关系数</span>
Month_data2_1T<span class="token punctuation">.</span>corr<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><p>这里仅展示部分结果图：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data2_1T_corr.5gurkritpvs0.jpg" width="50%/"></div><p>可以看到，每个变量间的相关程度都很高，不利用互相作为特征值。<br>对数据的自相关性和偏相关性进行分析。自相关：描述的是一组时间序列和它前面间隔n个时刻的一组时间序列之前的相关性。偏自相关：描述的是一组时间序列和它前面间隔n个时刻的一组时间序列之前的偏相关性。这里的偏相关性可以从本质上理解为去除了样本之间的干涉，也就是更早时刻的相关性影响。</p><pre class="language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 自相关，偏自相关，列出每一列的相关图</span>
col <span class="token operator">=</span> Month_data2_1T<span class="token punctuation">.</span>columns
<span class="token keyword">for</span> c <span class="token keyword">in</span> col<span class="token punctuation">:</span>  
    fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    ax1 <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">121</span><span class="token punctuation">)</span>
    ax1<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span>c<span class="token punctuation">)</span>
    ax2 <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">122</span><span class="token punctuation">)</span>
    ax2<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span>c<span class="token punctuation">)</span>
    plot_acf<span class="token punctuation">(</span>Month_data2_1T<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span>lags<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span>ax <span class="token operator">=</span> ax1<span class="token punctuation">)</span>
    plot_pacf<span class="token punctuation">(</span>Month_data2_1T<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span>lags<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span>ax <span class="token operator">=</span> ax2<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><p>同样的，展示部分结果图。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data2_1T_acf.3xqf5jmk4f80.jpg" width="60%/"></div><p>研究自相关、偏相关可用于判断是否适合使用时间预测方法,也可用于查看周期（下面会有演示）。该图可应用于LSTM算法，作为参数选择的依据。具体使用方法有待明确。<br>查看温湿度的统计分布。这里仅仅是查看下数据分布，目前没有对于其分析的一些想法。</p><pre class="language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 管道温湿度统计分布图</span>
<span class="token keyword">for</span> c <span class="token keyword">in</span> col<span class="token punctuation">:</span> 
    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    sns<span class="token punctuation">.</span>distplot<span class="token punctuation">(</span>Month_data2_1T<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span> bins<span class="token operator">=</span>int<span class="token punctuation">(</span>np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>len<span class="token punctuation">(</span>Month_data2_1T<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><p>展示部分结果图。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data2_1T_distplot.462fv8dw1b00.jpg" width="60%/"></div><p>数据平稳性判断，使用单位根检验法。</p><pre class="language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">check_stationarity</span><span class="token punctuation">(</span>y<span class="token punctuation">,</span> lags_plots<span class="token operator">=</span><span class="token number">48</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">22</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token string">"Use Series as parameter"</span>
    <span class="token comment" spellcheck="true"># Creating plots of the DF</span>
    y <span class="token operator">=</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
    fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>

    ax1 <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplot2grid<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> colspan<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
    ax2 <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplot2grid<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    ax3 <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplot2grid<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    ax4 <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplot2grid<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> colspan<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

    y<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>ax<span class="token operator">=</span>ax1<span class="token punctuation">,</span> figsize<span class="token operator">=</span>figsize<span class="token punctuation">)</span>
    ax1<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'Nums Variation'</span><span class="token punctuation">)</span>
    plot_acf<span class="token punctuation">(</span>y<span class="token punctuation">,</span> lags<span class="token operator">=</span>lags_plots<span class="token punctuation">,</span> zero<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> ax<span class="token operator">=</span>ax2<span class="token punctuation">)</span><span class="token punctuation">;</span>
    plot_pacf<span class="token punctuation">(</span>y<span class="token punctuation">,</span> lags<span class="token operator">=</span>lags_plots<span class="token punctuation">,</span> zero<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> ax<span class="token operator">=</span>ax3<span class="token punctuation">)</span><span class="token punctuation">;</span>
    sns<span class="token punctuation">.</span>distplot<span class="token punctuation">(</span>y<span class="token punctuation">,</span> bins<span class="token operator">=</span>int<span class="token punctuation">(</span>np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>len<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ax<span class="token operator">=</span>ax4<span class="token punctuation">)</span>
    ax4<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'Distribution Chart'</span><span class="token punctuation">)</span>

    plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># plt.show()</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Results of Dickey-Fuller Test:'</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">#  regression：{c”，“ct”，“ctt”，“n”}要包含在回归中的常数和趋势顺序。</span>
    <span class="token comment" spellcheck="true"># “c”：仅限常量（默认值）。</span>
    <span class="token comment" spellcheck="true"># “ct”：恒定和趋势。</span>
    <span class="token comment" spellcheck="true"># “ctt”：常数、线性和二次趋势。</span>
    <span class="token comment" spellcheck="true"># n：没有常数，没有趋势。</span>

    <span class="token comment" spellcheck="true"># ADF的结果主要看以下两个方面：</span>
    <span class="token comment" spellcheck="true"># Test Statistic的值如果比Critical Value (5%)小则满足稳定性需求.</span>
    <span class="token comment" spellcheck="true"># p-value越低（理论上需要低于0.05）证明序列越稳定。</span>
    adfinput <span class="token operator">=</span> adfuller<span class="token punctuation">(</span>y<span class="token punctuation">,</span>regression <span class="token operator">=</span> <span class="token string">'c'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#单位根检验</span>
    adftest <span class="token operator">=</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span>adfinput<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Test Statistic'</span><span class="token punctuation">,</span><span class="token string">'p-value'</span><span class="token punctuation">,</span><span class="token string">'Lags Used'</span><span class="token punctuation">,</span><span class="token string">'Number of Observations Used'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    adftest <span class="token operator">=</span> round<span class="token punctuation">(</span>adftest<span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> key<span class="token punctuation">,</span> value <span class="token keyword">in</span> adfinput<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        adftest<span class="token punctuation">[</span><span class="token string">"Critical Value (%s)"</span><span class="token operator">%</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> value<span class="token punctuation">.</span>round<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>
        
    <span class="token keyword">print</span><span class="token punctuation">(</span>adftest<span class="token punctuation">)</span>
    
    <span class="token keyword">if</span> adftest<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>round<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> adftest<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">.</span>round<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\nThe Test Statistics is lower than the Critical Value of 5%.\nThe serie seems to be stationary'</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\nThe Test Statistics is higher than the Critical Value of 5%.\nThe serie isn't stationary"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 检验平稳性</span>
check_stationarity<span class="token punctuation">(</span>Month_data2_1T<span class="token punctuation">[</span><span class="token string">'Te_0'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre><blockquote><p>输出结果为：<br>Results of Dickey-Fuller Test:<br>Test Statistic -1.4583<br>p-value 0.5540<br>Lags Used 55.0000<br>Number of Observations Used 43266.0000<br>Critical Value (1%) -3.4305<br>Critical Value (5%) -2.8616<br>Critical Value (10%) -2.5668<br>dtype: float64<br>The Test Statistics is higher than the Critical Value of 5%.<br>The serie isn’t stationary</p></blockquote><p>判断平稳性两个标准：Test Statistic小于Critical Value (5%)　或是p-value小于0.05。平稳性是多数统计学模型的必要条件之一。可见原数据并不是平稳序列。<br>对于非平稳序列，可使用一阶差分使其平稳化。</p><pre class="language-python"><code class="language-python"><span class="token comment" spellcheck="true">#序列平稳化，一阶差分</span>
Month_data2_1T<span class="token punctuation">[</span><span class="token string">'Te_0_diff'</span><span class="token punctuation">]</span> <span class="token operator">=</span> Month_data2_1T<span class="token punctuation">[</span><span class="token string">'Te_0'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>diff<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
</code></pre><p>其稳定性结果为：</p><blockquote><p>Results of Dickey-Fuller Test:<br>Test Statistic -51.9122<br>p-value 0.0000<br>Lags Used 54.0000<br>Number of Observations Used 43267.0000<br>Critical Value (1%) -3.4305<br>Critical Value (5%) -2.8616<br>Critical Value (10%) -2.5668<br>dtype: float64<br>The Test Statistics is lower than the Critical Value of 5%.<br>The serie seems to be stationary</p></blockquote><p>可见一阶差分可以有效是原序列平稳。后期可利用差分序列进行异常检测训练。<br>时间序列分解：所谓分解就是将时序数据分离成不同的成分，分解为：长期趋势Trend、季节性Seasonality和随机残差Residuals。分解序列后可针对每个子序列分别建模处理，如建模趋势后，在原数据中减去趋势的干扰。又或者当作特征值。</p><pre class="language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 管道温湿度时序序列分解：趋势+季节性+残差</span>
col <span class="token operator">=</span> Month_data2_1T<span class="token punctuation">.</span>columns
<span class="token keyword">for</span> c <span class="token keyword">in</span> col<span class="token punctuation">:</span>  
    <span class="token comment" spellcheck="true">#用加性模型，周期1440为1440min，分解数据时间频率为1min，一天为1440min。这里将一天设为周期，那么分解出的季节性数据以1天为周期</span>
    decompose_result <span class="token operator">=</span> seasonal_decompose<span class="token punctuation">(</span>Month_data2_1T<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"additive"</span><span class="token punctuation">,</span> period<span class="token operator">=</span><span class="token number">1440</span><span class="token punctuation">)</span>
    fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">18</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    ax1 <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">411</span><span class="token punctuation">)</span>
    ax2 <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">412</span><span class="token punctuation">)</span>
    ax3 <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">413</span><span class="token punctuation">)</span>
    ax4 <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">414</span><span class="token punctuation">)</span>
    ax1<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span>c<span class="token punctuation">)</span>
    ax1<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'init'</span><span class="token punctuation">)</span>
    ax2<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span>c<span class="token punctuation">)</span>
    ax2<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'trend'</span><span class="token punctuation">)</span>
    ax3<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span>c<span class="token punctuation">)</span>
    ax3<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'seasonal'</span><span class="token punctuation">)</span>
    ax4<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span>c<span class="token punctuation">)</span>
    ax4<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'resid'</span><span class="token punctuation">)</span>
    ax1<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>Month_data2_1T<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">)</span>
    ax2<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>decompose_result<span class="token punctuation">.</span>trend<span class="token punctuation">)</span>
    ax3<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>decompose_result<span class="token punctuation">.</span>seasonal<span class="token punctuation">)</span>
    ax4<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>decompose_result<span class="token punctuation">.</span>resid<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><p>部分结果如下：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data2_1T_decompose.7bi8h01gdf40.jpg" width="80%/"></div><p>接下来进行周期性检验。首先使用FFT查看频谱图：</p><pre class="language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">define_fft</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> fs <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> show_pic<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span> 
    <span class="token triple-quoted-string string">""" 
    # Parameters  

    data: 检测数据，dataframe类型 
    show_pic: 是否展示图片 
    fs: 采样频率，采样时长除以采样点数 = 采样频率
    """</span> 
    n <span class="token operator">=</span> data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    x <span class="token operator">=</span> data<span class="token punctuation">.</span>values
    yy <span class="token operator">=</span> fft<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    fre <span class="token operator">=</span> fftfreq<span class="token punctuation">(</span>n<span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">/</span>fs<span class="token punctuation">)</span>            <span class="token comment" spellcheck="true">#求频率横坐标</span>
    indices <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>fre <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#筛选大于零的频率</span>
    w_pos <span class="token operator">=</span> <span class="token number">2</span><span class="token operator">*</span>abs<span class="token punctuation">(</span>yy<span class="token punctuation">[</span>indices<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">/</span>n    <span class="token comment" spellcheck="true">#计算幅度值</span>
    F_pos <span class="token operator">=</span> fre<span class="token punctuation">[</span>indices<span class="token punctuation">]</span>            

    result_fft <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'freq'</span><span class="token punctuation">,</span> <span class="token string">'spec'</span><span class="token punctuation">,</span> <span class="token string">'T'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> 
    result_fft<span class="token punctuation">[</span><span class="token string">'freq'</span><span class="token punctuation">]</span> <span class="token operator">=</span> F_pos 
    result_fft<span class="token punctuation">[</span><span class="token string">'spec'</span><span class="token punctuation">]</span> <span class="token operator">=</span> w_pos 
    result_fft<span class="token punctuation">[</span><span class="token string">'T'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token operator">/</span>F_pos<span class="token operator">/</span><span class="token number">1440</span>
    <span class="token comment" spellcheck="true"># 按照频率强弱程度降序排列 </span>
    result_fft <span class="token operator">=</span> result_fft<span class="token punctuation">.</span>sort_values<span class="token punctuation">(</span>by<span class="token operator">=</span><span class="token string">'spec'</span><span class="token punctuation">,</span> ascending<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span> 
    <span class="token keyword">print</span><span class="token punctuation">(</span>result_fft<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> show_pic <span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 频率转换为周期 </span>
        plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">/</span>F_pos<span class="token operator">/</span><span class="token number">1440</span><span class="token punctuation">,</span> w_pos<span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token number">0</span>

define_fft<span class="token punctuation">(</span>Month_data2_1T<span class="token punctuation">[</span><span class="token string">'Te_0'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>fs<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>show_pic<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data_1T_periodogram.bx0uzqbkjcw.jpg" width="40%/"> <img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data_1T_residperiod.4rqdgw1afwu0.jpg" width="30%/"></div><p>查看左侧频谱图，可以发现图是有问题的。在周期最大的三个点，也即频率最小的三个点处出现了很大的峰值，低频成分上翘，这明显不对。考虑原因可能有二。</p><ol><li>原数据存在直流偏移的影响。<br>解决办法：减去直流量，试减去平均值</li><li>原数据中趋势的存在干扰了频谱分析。当信号中有明显的趋势项而未消除时，进行相关性分析和功率谱密度分析时会出现畸变，造成低频成分上翘甚至淹没主频成分。<br>解决办法：去趋势。</li></ol><p>对原数据减去平均值后进行FFT分析，发现频谱图的形状并没有变化，改试方案2。去趋势的方法在网上有许多，这里使用了两种办法：多项式拟合去趋势和时序序列分解。</p><pre class="language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 多项式拟合去趋势,使用滤波后的数据</span>
n <span class="token operator">=</span> Month_data2_1T<span class="token punctuation">[</span><span class="token string">'Te_0_filter'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
x<span class="token operator">=</span>np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> n<span class="token punctuation">,</span> n<span class="token punctuation">)</span>
y <span class="token operator">=</span> Month_data_1T<span class="token punctuation">[</span><span class="token string">'Te_0_filter'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values
z1 <span class="token operator">=</span> np<span class="token punctuation">.</span>polyfit<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>              <span class="token comment" spellcheck="true"># 曲线拟合，返回值为多项式的各项系数，10为阶数，具体数据选取看曲线拟合程度，可进行可视化查看</span>
p1 <span class="token operator">=</span> np<span class="token punctuation">.</span>poly1d<span class="token punctuation">(</span>z1<span class="token punctuation">)</span>                    <span class="token comment" spellcheck="true"># 返回值为多项式的表达式，也就是函数式子</span>
<span class="token comment" spellcheck="true"># print(p1)</span>
y_pred <span class="token operator">=</span> p1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                        <span class="token comment" spellcheck="true"># 根据函数的多项式表达式，求解 y,即趋势</span>
Month_data_1T<span class="token punctuation">[</span><span class="token string">'x'</span><span class="token punctuation">]</span><span class="token operator">=</span>Month_data_1T<span class="token punctuation">[</span><span class="token string">'Te_0_filter'</span><span class="token punctuation">]</span><span class="token operator">-</span>y_pred
define_fft<span class="token punctuation">(</span>Month_data_1T<span class="token punctuation">[</span><span class="token string">'x'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>fs<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>show_pic<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre><p>下图为原数据曲线图、趋势图、原数据去趋势图和FFT图。可以看出，用拟合法去趋势后，FFT图尾端翘起现象几乎没有了，但仍有小尾巴残留。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/polyfit.1wq4d6hwhjq8.jpg" width="80%/"> <img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/polyfit_detrend.2eofsy7hwrwg.jpg" width="80%/"> <img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/ployfit_FFT.4u82p09d7n60.jpg" width="50%/"></div><p>接下来是由时序序列分解法。该方法上面讲过了，操作步骤一致，只是在分解趋势适合，分解了两次，使用77周期分解以此，发现还有周期现象，又使用1440周期对分解出的趋势分解了一次，对用原数据减去二次趋势，再求FFT，结果如图。第一张为去趋势后的图，第二张为FFT结果图。可以看出，该方法去趋势效果更好。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/twice_detrend.7jhgdh1lahw0.jpg" width="80%/"> <img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/twice_detrend_FFT.ekqba34lveo.jpg" width="40%/"></div><p>根据频谱图结果，列出最大的三个能量谱的点依次为1天，0.5天，77min。可能的周期也是这三个点。再根据这三个点看自相关图，分别列出滞后点为1000和10000的相关图。如图所示。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/acf_1000.hy1dzybmthk.jpg" width="80%/"></div>对于自相关图，当序列存在周期时，会在周期出出现一个高峰。从图中可以看出，曲线分别以约77和1440为周期处出现高峰。再结合实际，77min大致为系统运行一个周期，1440min为系统运行一天。由此可见，数据约以77min和1440min为周期。<h2 id="2-3-特征工程"><a href="#2-3-特征工程" class="headerlink" title="2.3 特征工程"></a>2.3 特征工程</h2><h3 id="2-3-1-特征提取"><a href="#2-3-1-特征提取" class="headerlink" title="2.3.1 特征提取"></a>2.3.1 特征提取</h3><ol><li><strong>从时间中提取特征</strong><pre class="language-python"><code class="language-python"><span class="token comment" spellcheck="true">#仅取第一列Hu_0数据</span>
df <span class="token operator">=</span> Month_data_1T<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span>
df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">.</span>index
<span class="token comment" spellcheck="true"># 年份</span>
df<span class="token punctuation">[</span><span class="token string">'年'</span><span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>year<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 月份</span>
df<span class="token punctuation">[</span><span class="token string">'月'</span><span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>month<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 日</span>
df<span class="token punctuation">[</span><span class="token string">'日'</span><span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>day<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 小时</span>
df<span class="token punctuation">[</span><span class="token string">'时'</span><span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>hour<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 分钟</span>
df<span class="token punctuation">[</span><span class="token string">'分'</span><span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>minute<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 一天中的第几分钟</span>
df<span class="token punctuation">[</span><span class="token string">'一天中的第几分钟'</span><span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>minute <span class="token operator">+</span> x<span class="token punctuation">.</span>hour<span class="token operator">*</span><span class="token number">60</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 星期几；</span>
df<span class="token punctuation">[</span><span class="token string">'星期几'</span><span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>dayofweek<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 一年中的第几天</span>
df<span class="token punctuation">[</span><span class="token string">'一年中的第几天'</span><span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>dayofyear<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># # 一年中的第几周</span>
<span class="token comment" spellcheck="true"># df['一年中的第几周']=df['时间'].apply(lambda x: x.week)</span>
<span class="token comment" spellcheck="true"># 一天中哪个时间段：凌晨、早晨、上午、中午、下午、傍晚、晚上、深夜；</span>
period_dict <span class="token operator">=</span><span class="token punctuation">{</span>
 <span class="token number">23</span><span class="token punctuation">:</span> <span class="token number">0x00</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span> <span class="token number">0x00</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span> <span class="token number">0x00</span><span class="token punctuation">,</span>
 <span class="token number">2</span><span class="token punctuation">:</span> <span class="token number">0x01</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">:</span> <span class="token number">0x01</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">:</span> <span class="token number">0x01</span><span class="token punctuation">,</span>
 <span class="token number">5</span><span class="token punctuation">:</span> <span class="token number">0x02</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">:</span> <span class="token number">0x02</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">:</span> <span class="token number">0x02</span><span class="token punctuation">,</span>
 <span class="token number">8</span><span class="token punctuation">:</span> <span class="token number">0x03</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">:</span> <span class="token number">0x03</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">:</span> <span class="token number">0x03</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">:</span> <span class="token number">0x03</span><span class="token punctuation">,</span>
 <span class="token number">12</span><span class="token punctuation">:</span> <span class="token number">0x04</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">:</span> <span class="token number">0x04</span><span class="token punctuation">,</span><span class="token number">14</span><span class="token punctuation">:</span> <span class="token number">0x04</span><span class="token punctuation">,</span> 
 <span class="token number">15</span><span class="token punctuation">:</span> <span class="token number">0x05</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">:</span> <span class="token number">0x05</span><span class="token punctuation">,</span> <span class="token number">17</span><span class="token punctuation">:</span> <span class="token number">0x05</span><span class="token punctuation">,</span><span class="token number">18</span><span class="token punctuation">:</span> <span class="token number">0x05</span><span class="token punctuation">,</span>
 <span class="token number">19</span><span class="token punctuation">:</span> <span class="token number">0x07</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">:</span> <span class="token number">0x07</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">:</span> <span class="token number">0x07</span><span class="token punctuation">,</span> <span class="token number">22</span><span class="token punctuation">:</span> <span class="token number">0x07</span><span class="token punctuation">,</span>
<span class="token comment" spellcheck="true">#     23: '深夜', 0: '深夜', 1: '深夜',</span>
<span class="token comment" spellcheck="true">#     2: '凌晨', 3: '凌晨', 4: '凌晨',</span>
<span class="token comment" spellcheck="true">#     5: '早晨', 6: '早晨', 7: '早晨',</span>
<span class="token comment" spellcheck="true">#     8: '上午', 9: '上午', 10: '上午', 11: '上午',</span>
<span class="token comment" spellcheck="true">#     12: '中午', 13: '中午',14: '中午',</span>
<span class="token comment" spellcheck="true">#     15: '下午', 16: '下午', 17: '下午',18: '下午',</span>
<span class="token comment" spellcheck="true">#     19: '晚上', 20: '晚上', 21: '晚上', 22: '晚上',</span>
<span class="token punctuation">}</span>
df<span class="token punctuation">[</span><span class="token string">'时间段'</span><span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">'时'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>period_dict<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># # 一年中的哪个季度</span>
<span class="token comment" spellcheck="true"># season_dict = {</span>
<span class="token comment" spellcheck="true">#     1: '春季', 2: '春季', 3: '春季',</span>
<span class="token comment" spellcheck="true">#     4: '夏季', 5: '夏季', 6: '夏季',</span>
<span class="token comment" spellcheck="true">#     7: '秋季', 8: '秋季', 9: '秋季',</span>
<span class="token comment" spellcheck="true">#     10: '冬季', 11: '冬季', 12: '冬季',</span>
<span class="token comment" spellcheck="true"># }</span>
<span class="token comment" spellcheck="true"># df['季节']=df['月'].map(season_dict)</span>
<span class="token comment" spellcheck="true"># # 是否闰年</span>
<span class="token comment" spellcheck="true"># df['是否闰年'] = df['时间'].apply(lambda x: x.is_leap_year)</span>
<span class="token comment" spellcheck="true"># 是否月初</span>
df<span class="token punctuation">[</span><span class="token string">'是否月初'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>is_month_start<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 是否月末</span>
df<span class="token punctuation">[</span><span class="token string">'是否月末'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>is_month_end<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 是否季节初</span>
<span class="token comment" spellcheck="true"># df['是否季节初'] = df['时间'].apply(lambda x: x.is_quarter_start)</span>
<span class="token comment" spellcheck="true"># 是否季节末</span>
<span class="token comment" spellcheck="true"># df['是否季节末'] = df['时间'].apply(lambda x: x.is_quarter_end)</span>
<span class="token comment" spellcheck="true"># 是否年初</span>
<span class="token comment" spellcheck="true"># df['是否年初'] = df['时间'].apply(lambda x: x.is_year_start)</span>
<span class="token comment" spellcheck="true"># 是否年尾</span>
<span class="token comment" spellcheck="true"># df['是否年尾'] = df['时间'].apply(lambda x: x.is_year_end)</span>
<span class="token comment" spellcheck="true"># 是否周末</span>
df<span class="token punctuation">[</span><span class="token string">'是否周末'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'时间'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token boolean">True</span> <span class="token keyword">if</span> x<span class="token punctuation">.</span>dayofweek <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span> <span class="token keyword">else</span> <span class="token boolean">False</span><span class="token punctuation">)</span>
df
</code></pre>结果如下图所示：<div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202204/Characteristic-Engineering-of-Time-Series/时间特征.407xag8uznw0.jpg"></div></li><li><strong>从时序规律中提取特征</strong><pre class="language-python"><code class="language-python"><span class="token keyword">from</span> statsmodels<span class="token punctuation">.</span>tsa<span class="token punctuation">.</span>seasonal <span class="token keyword">import</span> seasonal_decompose
<span class="token comment" spellcheck="true"># 数据含有两个周期77和1440</span>
<span class="token comment" spellcheck="true"># 偏移6min差分</span>
df<span class="token punctuation">[</span><span class="token string">"Hu0_-5S"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'Hu_0'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shift<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 偏移77min差分，一小周期</span>
df<span class="token punctuation">[</span><span class="token string">"Hu0_-1period"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'Hu_0'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shift<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">*</span><span class="token number">77</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 偏移两小周期</span>
df<span class="token punctuation">[</span><span class="token string">"Hu0_-2period"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'Hu_0'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shift<span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span><span class="token number">77</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 偏移1天，一大周期</span>
df<span class="token punctuation">[</span><span class="token string">"Hu0_-1day"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'Hu_0'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shift<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">*</span><span class="token number">1440</span><span class="token punctuation">)</span>
decompose_result <span class="token operator">=</span> seasonal_decompose<span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">'Hu_0'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"additive"</span><span class="token punctuation">,</span> period<span class="token operator">=</span><span class="token number">77</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 分离77周期分离</span>
df<span class="token punctuation">[</span><span class="token string">"Hu0_77seasonal"</span><span class="token punctuation">]</span> <span class="token operator">=</span> decompose_result<span class="token punctuation">.</span>seasonal
decompose_result <span class="token operator">=</span> seasonal_decompose<span class="token punctuation">(</span>decompose_result<span class="token punctuation">.</span>seasonal<span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"additive"</span><span class="token punctuation">,</span> period<span class="token operator">=</span><span class="token number">1440</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 分离1440周期分量</span>
df<span class="token punctuation">[</span><span class="token string">"Hu0_1440seasonal"</span><span class="token punctuation">]</span> <span class="token operator">=</span> decompose_result<span class="token punctuation">.</span>seasonal
<span class="token comment" spellcheck="true"># 趋势分量</span>
df<span class="token punctuation">[</span><span class="token string">"Hu0_trend"</span><span class="token punctuation">]</span> <span class="token operator">=</span> decompose_result<span class="token punctuation">.</span>trend
<span class="token comment" spellcheck="true"># 残差分量</span>
df<span class="token punctuation">[</span><span class="token string">"Hu0_resid"</span><span class="token punctuation">]</span> <span class="token operator">=</span> decompose_result<span class="token punctuation">.</span>resid
df
</code></pre><img lazyload="" src="/images/loading.svg" data-src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202204/Characteristic-Engineering-of-Time-Series/%E6%97%B6%E5%BA%8F%E8%A7%84%E5%BE%8B%E7%89%B9%E5%BE%81.5n1vvk2y3d40.jpg" alt="时序规律特征"></li><li><strong>从统计窗口提取特征</strong><br>```python<h1 id="sum-值的总和"><a href="#sum-值的总和" class="headerlink" title="sum() 值的总和"></a>sum() 值的总和</h1><h1 id="mean-均值"><a href="#mean-均值" class="headerlink" title="mean() 均值"></a>mean() 均值</h1><h1 id="median-值的算术中值"><a href="#median-值的算术中值" class="headerlink" title="median() 值的算术中值"></a>median() 值的算术中值</h1><h1 id="min-最小值"><a href="#min-最小值" class="headerlink" title="min() 最小值"></a>min() 最小值</h1><h1 id="max-最大"><a href="#max-最大" class="headerlink" title="max() 最大"></a>max() 最大</h1><h1 id="std-贝塞尔修正样本标准差-均方差"><a href="#std-贝塞尔修正样本标准差-均方差" class="headerlink" title="std() 贝塞尔修正样本标准差(均方差)"></a>std() 贝塞尔修正样本标准差(均方差)</h1><h1 id="var-无偏方差"><a href="#var-无偏方差" class="headerlink" title="var() 无偏方差"></a>var() 无偏方差</h1><h1 id="cov-无偏协方差（二元）"><a href="#cov-无偏协方差（二元）" class="headerlink" title="cov() 无偏协方差（二元）"></a>cov() 无偏协方差（二元）</h1><h1 id="corr-相关（二进制）"><a href="#corr-相关（二进制）" class="headerlink" title="corr() 相关（二进制）"></a>corr() 相关（二进制）</h1><h1 id="variation-v-x3D-std-v-x2F-mean-v-离散系数"><a href="#variation-v-x3D-std-v-x2F-mean-v-离散系数" class="headerlink" title="variation_v = std_v/mean_v 离散系数"></a>variation_v = std_v/mean_v 离散系数</h1><h1 id="polyfit-线性拟合，求斜率"><a href="#polyfit-线性拟合，求斜率" class="headerlink" title="polyfit 线性拟合，求斜率"></a>polyfit 线性拟合，求斜率</h1></li></ol><p>#使用rolling滚动窗口，窗口大小为7<br>roll_data = df[‘Hu_0’].rolling(window=7)<br>df[“Hu0_mean”] = roll_data.mean()<br>df[“Hu0_median”] = roll_data.median()<br>df[“Hu0_min”] = roll_data.min()<br>df[“Hu0_max”] = roll_data.max()<br>df[“Hu0_std”] = roll_data.std()<br>df[“Hu0_var”] = roll_data.var()<br>df[“Hu0_cov”] = roll_data.cov()<br>df[“Hu0_corr”] = roll_data.corr()<br>df[“Hu0_variation”] = df[“Hu0_std”]/df[“Hu0_mean”]<br>df[“Hu0_sum”] = roll_data.sum()<br>df[“Hu0_sum_diff2”] = df[“Hu0_sum”].shift(1)-df[“Hu0_sum”].shift(2)</p><h1 id="df-“Hu0-autocorr1”-x3D-df-“Hu-0”-autocorr-1"><a href="#df-“Hu0-autocorr1”-x3D-df-“Hu-0”-autocorr-1" class="headerlink" title="df[“Hu0_autocorr1”] = df[“Hu_0”].autocorr(1)"></a>df[“Hu0_autocorr1”] = df[“Hu_0”].autocorr(1)</h1><h1 id="df-“Hu0-autocorr2”-x3D-df-“Hu-0”-autocorr-2"><a href="#df-“Hu0-autocorr2”-x3D-df-“Hu-0”-autocorr-2" class="headerlink" title="df[“Hu0_autocorr2”] = df[“Hu_0”].autocorr(2)"></a>df[“Hu0_autocorr2”] = df[“Hu_0”].autocorr(2)</h1><p>x = range(7)<br>z = lambda y : np.polyfit(x, y, 1)[0]<br>df[“Hu0_polyfit”] = roll_data.apply(z)</p><h1 id="一阶差分的均方差"><a href="#一阶差分的均方差" class="headerlink" title="一阶差分的均方差"></a>一阶差分的均方差</h1><p>roll_data_diff = df[‘Hu_0’].diff(1).rolling(window=7)<br>df[“Hu0_diff_std”] = roll_data_diff.std()<br>df</p><pre><code>![统计特征](https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202204/Characteristic-Engineering-of-Time-Series/统计特征.6ahmg2mw8s00.jpg)
4. **利用tsfresh工具提取特征**
先将原序列转换为n个窗口子序列。原表one_data结构为：
![滚动窗口原表结构](https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202204/Characteristic-Engineering-of-Time-Series/滚动窗口原表结构.119hmuad0jy8.jpg)
其中id,time列是在原表的基础上后加上的，目的是为了方便使用API接口函数。id代表组别，time代表时间顺序。然后使用API转换为窗口子序列。
```python
from tsfresh.utilities.dataframe_functions import roll_time_series
# 滚动窗口
#max_timeshift:最大偏移量，min_timeshift：最小偏移量，rolling_direction：每次移动的大小和方向。column_sort按什么排序，默认已从小到大排好
df_rolled = roll_time_series(one_data, column_id="id", column_sort="time",max_timeshift = 6 ,min_timeshift = 6,rolling_direction=-1)
df_rolled
</code></pre><p><img lazyload="" src="/images/loading.svg" data-src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202204/Characteristic-Engineering-of-Time-Series/tsfresh%E7%AA%97%E5%8F%A3%E5%BA%8F%E5%88%97.4f2dy005fr40.jpg" alt="tsfresh窗口序列"><br>转化后的id是原id与原时间的组合，也为后面特征提取中的组别。（1，1）代表1号组别的第一个时间点组成的子序列，（1，43316）代表1号组别第43316个点组成的子序列。然后再进行特征提取.</p><pre class="language-python"><code class="language-python"><span class="token keyword">from</span> tsfresh <span class="token keyword">import</span> extract_features
<span class="token comment" spellcheck="true"># 特征提取,使用drop先删去多余的列，column_id为组别</span>
df_features <span class="token operator">=</span> extract_features<span class="token punctuation">(</span>df_rolled<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"date"</span><span class="token punctuation">,</span><span class="token string">"time"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> column_id<span class="token operator">=</span><span class="token string">"id"</span><span class="token punctuation">)</span>
df_features
</code></pre><h3 id="2-3-2-特征预处理"><a href="#2-3-2-特征预处理" class="headerlink" title="2.3.2 特征预处理"></a>2.3.2 特征预处理</h3><p>首先处理表中的空值，因为前面窗口大小选为7，所以需要把表df（前面没有划分子窗口的表）的前六行删去，与df_features表的大小保持一致。df_features表中存在大量的空值，需要先将含空值的列删去。然后将df_features的索引设为df的索引，之后会利用concat函数将两表合并。又df表中，因为提取时序规律的特征中，头和尾存在许多空值，需要将其删除，然后取删除后的时间区段，选取df_features表的对应时间段。最后使用concat函数合并两表。</p><pre class="language-python"><code class="language-python"><span class="token comment" spellcheck="true">#删除前6行</span>
df <span class="token operator">=</span> df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
<span class="token comment" spellcheck="true"># 删除有空值的列</span>
df_features <span class="token operator">=</span> df_features<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#设置索引</span>
df_features<span class="token punctuation">.</span>index <span class="token operator">=</span> df<span class="token punctuation">.</span>index
<span class="token comment" spellcheck="true">#删除空值行，此时查看表可以得到时间段</span>
df <span class="token operator">=</span> df<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#合并两表</span>
df_concat <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>df<span class="token punctuation">,</span>df_features<span class="token punctuation">[</span><span class="token string">'2022-01-26 13:12:00'</span><span class="token punctuation">:</span><span class="token string">'2022-02-24 03:13:00'</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token punctuation">,</span> axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
df_concat
</code></pre><p>然后需要对特征无量纲化。使用标准化。</p><pre class="language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler
scaler <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#因为上式返回结果为series，这里将其转换为表格形式。</span>
df_Standar <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>scaler<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>df_concat<span class="token punctuation">)</span><span class="token punctuation">,</span>index<span class="token operator">=</span>df_concat<span class="token punctuation">.</span>index<span class="token punctuation">,</span> columns<span class="token operator">=</span>df_concat<span class="token punctuation">.</span>columns<span class="token punctuation">)</span>
df_Standar
</code></pre><h3 id="2-3-3-特征降维"><a href="#2-3-3-特征降维" class="headerlink" title="2.3.3 特征降维"></a>2.3.3 特征降维</h3><p>使用过滤法，利用方差和相关系数过滤特征。</p><pre class="language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 特征过滤 filter</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_selection <span class="token keyword">import</span> VarianceThreshold  
X_train_columns <span class="token operator">=</span> df_Standar<span class="token punctuation">.</span>columns
<span class="token comment" spellcheck="true">#方差过滤，返回方差大于设定阈值的列</span>
selector <span class="token operator">=</span> VarianceThreshold<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> selector<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>df_Standar<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#因为上式返回结果为series，这里将其转换为表格形式。</span>
<span class="token comment" spellcheck="true">#X_train_columns[selector.get_support(indices=True)]结果为筛选后的列名</span>
df_filter <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>X<span class="token punctuation">,</span>index<span class="token operator">=</span>df_concat<span class="token punctuation">.</span>index<span class="token punctuation">,</span> columns<span class="token operator">=</span>X_train_columns<span class="token punctuation">[</span>selector<span class="token punctuation">.</span>get_support<span class="token punctuation">(</span>indices<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
df_filter
</code></pre><pre class="language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 特征过滤 相关系数corr</span>
<span class="token comment" spellcheck="true"># 剔除相关性系数高于threshold的corr_drop</span>
corr_df <span class="token operator">=</span> df_filter<span class="token punctuation">.</span>corr<span class="token punctuation">(</span><span class="token punctuation">)</span>
threshold <span class="token operator">=</span> <span class="token number">0.9</span>
<span class="token comment" spellcheck="true">#k=1,返回上三角矩阵</span>
upper <span class="token operator">=</span> corr_df<span class="token punctuation">.</span>where<span class="token punctuation">(</span>np<span class="token punctuation">.</span>triu<span class="token punctuation">(</span>np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>corr_df<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>bool<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#返回相关系数大于阈值的列名</span>
corr_drop <span class="token operator">=</span> <span class="token punctuation">[</span>column <span class="token keyword">for</span> column <span class="token keyword">in</span> upper<span class="token punctuation">.</span>columns <span class="token keyword">if</span> any<span class="token punctuation">(</span>upper<span class="token punctuation">[</span>column<span class="token punctuation">]</span><span class="token punctuation">.</span>abs<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> threshold<span class="token punctuation">)</span><span class="token punctuation">]</span>
df_filter <span class="token operator">=</span> df_filter<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>corr_drop<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
df_filter
</code></pre></div><div class="post-copyright-info"><div class="article-copyright-info-container"><ul><li>本文标题：时序数据异常检测流程与项目实战</li><li>本文作者：EasyBoy</li><li>创建时间：2022-03-25 20:23:25</li><li>本文链接：https://easyboy-blog.com/anomaly-detection-process.html</li><li>版权声明：本博客所有文章除特别声明外，均采用 <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div></div><ul class="post-tags-box"><li class="tag-item"><a href="/tags/%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE/">#时序数据</a>&nbsp;</li><li class="tag-item"><a href="/tags/%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/">#异常处理</a>&nbsp;</li><li class="tag-item"><a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">#机器学习</a>&nbsp;</li></ul><div class="article-nav"><div class="article-prev"><a class="prev" rel="prev" href="/centos7-an-zhuang-qt-ji-huan-jing-pei-zhi.html"><span class="left arrow-icon flex-center"><i class="fas fa-chevron-left"></i> </span><span class="title flex-center"><span class="post-nav-title-item">centos7安装QT及环境配置</span> <span class="post-nav-item">上一篇</span></span></a></div><div class="article-next"><a class="next" rel="next" href="/compilation-process.html"><span class="title flex-center"><span class="post-nav-title-item">c/c++编译流程</span> <span class="post-nav-item">下一篇</span> </span><span class="right arrow-icon flex-center"><i class="fas fa-chevron-right"></i></span></a></div></div><div class="comment-container"><div class="comments-container"><div id="comment-anchor"></div><div class="comment-area-title"><i class="fas fa-comments">&nbsp;评论</i></div><div class="valine-container"><script data-pjax src="//cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js"></script><div id="vcomments"></div><script data-pjax>function loadValine(){function e(e){switch(e){case"en":return"Author";case"zh-CN":return"博主";default:return"Master"}}new Valine({el:"#vcomments",appId:"TSl5PlExO22wiwkA3e15kGvM-gzGzoHsz",appKey:"36AERjunsq15rL0xcz3ovKbG",meta:["nick","mail","link"],avatar:"wavatar",enableQQ:!0,placeholder:"😜 尽情吐槽吧~",lang:"zh-CN".toLowerCase()});const a=setInterval(()=>{const n=document.querySelectorAll("#vcomments .vcards .vcard");if(n.length>0){let t="EasyBoy";if(t)for(let a of n){const n=a.querySelector(".vhead .vnick"),l=n.innerHTML;l===t&&(n.innerHTML=`${l} <span class="author">${e(KEEP.hexo_config.language)}</span>`)}clearInterval(a)}else clearInterval(a)},2e3)}{const e=setTimeout(()=>{loadValine(),clearTimeout(e)},1e3)}</script></div></div></div></div></div></div></div><div class="page-main-content-bottom"><footer class="footer"><div class="info-container"><div class="copyright-info info-item">&copy; <span>2020</span> - 2022&nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;<a href="/">EasyBoy</a></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div class="website-count info-item"><span id="busuanzi_container_site_uv">访问人数&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp; </span><span id="busuanzi_container_site_pv">总访问量&nbsp;<span id="busuanzi_value_site_pv"></span></span></div><div class="theme-info info-item">由 <a target="_blank" href="https://hexo.io">Hexo</a> 驱动&nbsp;|&nbsp;主题&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.5</a></div></div></footer></div></div><div class="post-tools"><div class="post-tools-container"><ul class="tools-list"><li class="tools-item page-aside-toggle"><i class="fas fa-outdent"></i></li><li class="go-comment"><i class="fas fa-comment"></i></li></ul></div></div><div class="right-bottom-side-tools"><div class="side-tools-container"><ul class="side-tools-list"><li class="tools-item tool-font-adjust-plus flex-center"><i class="fas fa-search-plus"></i></li><li class="tools-item tool-font-adjust-minus flex-center"><i class="fas fa-search-minus"></i></li><li class="tools-item tool-expand-width flex-center"><i class="fas fa-arrows-alt-h"></i></li><li class="tools-item tool-dark-light-toggle flex-center"><i class="fas fa-moon"></i></li><li class="tools-item rss flex-center"><a class="flex-center" href="/atom.xml" target="_blank"><i class="fas fa-rss"></i></a></li><li class="tools-item tool-scroll-to-top flex-center"><i class="fas fa-arrow-up"></i></li><li class="tools-item tool-scroll-to-bottom flex-center"><i class="fas fa-arrow-down"></i></li></ul><ul class="exposed-tools-list"><li class="tools-item tool-toggle-show flex-center"><i class="fas fa-cog fa-spin"></i></li></ul></div></div><aside class="page-aside"><div class="post-toc-wrap"><div class="post-toc"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-%E6%80%BB%E4%BD%93%E6%B5%81%E7%A8%8B%E4%BB%8B%E7%BB%8D"><span class="nav-text">1.总体流程介绍</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98"><span class="nav-text">2.项目实战</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97"><span class="nav-text">2.1 数据清洗</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-%E6%8E%A2%E7%B4%A2%E6%80%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90EDA"><span class="nav-text">2.2 探索性数据分析EDA</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B"><span class="nav-text">2.3 特征工程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-1-%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="nav-text">2.3.1 特征提取</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#sum-%E5%80%BC%E7%9A%84%E6%80%BB%E5%92%8C"><span class="nav-text">sum() 值的总和</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#mean-%E5%9D%87%E5%80%BC"><span class="nav-text">mean() 均值</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#median-%E5%80%BC%E7%9A%84%E7%AE%97%E6%9C%AF%E4%B8%AD%E5%80%BC"><span class="nav-text">median() 值的算术中值</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#min-%E6%9C%80%E5%B0%8F%E5%80%BC"><span class="nav-text">min() 最小值</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#max-%E6%9C%80%E5%A4%A7"><span class="nav-text">max() 最大</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#std-%E8%B4%9D%E5%A1%9E%E5%B0%94%E4%BF%AE%E6%AD%A3%E6%A0%B7%E6%9C%AC%E6%A0%87%E5%87%86%E5%B7%AE-%E5%9D%87%E6%96%B9%E5%B7%AE"><span class="nav-text">std() 贝塞尔修正样本标准差(均方差)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#var-%E6%97%A0%E5%81%8F%E6%96%B9%E5%B7%AE"><span class="nav-text">var() 无偏方差</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#cov-%E6%97%A0%E5%81%8F%E5%8D%8F%E6%96%B9%E5%B7%AE%EF%BC%88%E4%BA%8C%E5%85%83%EF%BC%89"><span class="nav-text">cov() 无偏协方差（二元）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#corr-%E7%9B%B8%E5%85%B3%EF%BC%88%E4%BA%8C%E8%BF%9B%E5%88%B6%EF%BC%89"><span class="nav-text">corr() 相关（二进制）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#variation-v-x3D-std-v-x2F-mean-v-%E7%A6%BB%E6%95%A3%E7%B3%BB%E6%95%B0"><span class="nav-text">variation_v &#x3D; std_v&#x2F;mean_v 离散系数</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#polyfit-%E7%BA%BF%E6%80%A7%E6%8B%9F%E5%90%88%EF%BC%8C%E6%B1%82%E6%96%9C%E7%8E%87"><span class="nav-text">polyfit 线性拟合，求斜率</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#df-%E2%80%9CHu0-autocorr1%E2%80%9D-x3D-df-%E2%80%9CHu-0%E2%80%9D-autocorr-1"><span class="nav-text">df[“Hu0_autocorr1”] &#x3D; df[“Hu_0”].autocorr(1)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#df-%E2%80%9CHu0-autocorr2%E2%80%9D-x3D-df-%E2%80%9CHu-0%E2%80%9D-autocorr-2"><span class="nav-text">df[“Hu0_autocorr2”] &#x3D; df[“Hu_0”].autocorr(2)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%80%E9%98%B6%E5%B7%AE%E5%88%86%E7%9A%84%E5%9D%87%E6%96%B9%E5%B7%AE"><span class="nav-text">一阶差分的均方差</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-2-%E7%89%B9%E5%BE%81%E9%A2%84%E5%A4%84%E7%90%86"><span class="nav-text">2.3.2 特征预处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-3-%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4"><span class="nav-text">2.3.3 特征降维</span></a></li></ol></li></ol></div></div></aside><div class="image-viewer-container"><img src=""></div><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-input-field-pre"><i class="fas fa-keyboard"></i></span><div class="search-input-container"><input autocomplete="off" autocorrect="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fas fa-times"></i></span></div><div id="search-result"><div id="no-result"><i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></main><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/utils.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/main.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/header-shrink.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/back2top.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/dark-light-toggle.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/local-search.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/code-copy.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/lazyload.js"></script><div class="post-scripts pjax"><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/left-side-toggle.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/libs/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/toc.js"></script></div><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/libs/pjax.min.js"></script><script>window.addEventListener("DOMContentLoaded",()=>{window.pjax=new Pjax({selectors:["head title",".page-container",".pjax"],history:!0,debug:!1,cacheBust:!1,timeout:0,analytics:!1,currentUrlFullReload:!1,scrollRestoration:!1}),document.addEventListener("pjax:send",()=>{KEEP.utils.pjaxProgressBarStart()}),document.addEventListener("pjax:complete",()=>{KEEP.utils.pjaxProgressBarEnd(),window.pjax.executeScripts(document.querySelectorAll("script[data-pjax], .pjax script")),KEEP.refresh()})})</script></body></html>