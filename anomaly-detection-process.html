<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/cell-32x32-next.png"><link rel="icon" href="/img/cell-32x32-next.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="laser"><meta name="keywords" content=""><meta name="description" content="本文主要内容为对时序数据异常检测流程进行简单介绍，然后通过项目实战进行详细解释。全文内容根据个人实际经验所得。 1.总体流程介绍针对项目中传感器数据异常检测，经调研后，个人初步总结工程上实现异常检测的流程。流程框图如下图所示："><meta property="og:type" content="article"><meta property="og:title" content="时序数据异常检测流程与项目实战"><meta property="og:url" content="https://haochendaily.com/anomaly-detection-process.html"><meta property="og:site_name" content="haochenBlog"><meta property="og:description" content="本文主要内容为对时序数据异常检测流程进行简单介绍，然后通过项目实战进行详细解释。全文内容根据个人实际经验所得。 1.总体流程介绍针对项目中传感器数据异常检测，经调研后，个人初步总结工程上实现异常检测的流程。流程框图如下图所示："><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://cdn.staticaly.com/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Anomaly_detection_process.6l6blsl243s0.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet.4mjopka34v80.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_index.78rh4tnfar00.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_plot.4833uxky2zg0.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_resample.tfaifs2cgrk.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_twoday_describe.3qyix6pukji0.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_twoday_boxplot.705wl11k1jo0.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_twoday_boxplot_new.44m969zxzbg0.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/L1_id_data.6dh59h41kq40.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/L1_id_pivot.2ab6wthn3ack.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/L1_id_oneclass.59gip30dtvk0.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/butter.6leaq5g4j7s0.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data2_1T_corr.5gurkritpvs0.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data2_1T_acf.3xqf5jmk4f80.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data2_1T_distplot.462fv8dw1b00.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data2_1T_decompose.7bi8h01gdf40.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data_1T_periodogram.bx0uzqbkjcw.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data_1T_residperiod.4rqdgw1afwu0.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/polyfit.1wq4d6hwhjq8.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/polyfit_detrend.2eofsy7hwrwg.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/ployfit_FFT.4u82p09d7n60.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/twice_detrend.7jhgdh1lahw0.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/twice_detrend_FFT.ekqba34lveo.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/acf_1000.hy1dzybmthk.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202204/Characteristic-Engineering-of-Time-Series/时间特征.407xag8uznw0.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202204/Characteristic-Engineering-of-Time-Series/%E6%97%B6%E5%BA%8F%E8%A7%84%E5%BE%8B%E7%89%B9%E5%BE%81.5n1vvk2y3d40.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202204/Characteristic-Engineering-of-Time-Series/%E7%BB%9F%E8%AE%A1%E7%89%B9%E5%BE%81.6ahmg2mw8s00.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202204/Characteristic-Engineering-of-Time-Series/%E6%BB%9A%E5%8A%A8%E7%AA%97%E5%8F%A3%E5%8E%9F%E8%A1%A8%E7%BB%93%E6%9E%84.119hmuad0jy8.jpg"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202204/Characteristic-Engineering-of-Time-Series/tsfresh%E7%AA%97%E5%8F%A3%E5%BA%8F%E5%88%97.4f2dy005fr40.jpg"><meta property="article:published_time" content="2022-03-25T12:23:25.727Z"><meta property="article:modified_time" content="2022-04-29T16:00:00.000Z"><meta property="article:author" content="laser"><meta property="article:tag" content="时序数据"><meta property="article:tag" content="异常处理"><meta property="article:tag" content="机器学习"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="https://cdn.staticaly.com/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Anomaly_detection_process.6l6blsl243s0.jpg"><meta name="referrer" content="no-referrer-when-downgrade"><title>时序数据异常检测流程与项目实战 - haochenBlog</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"haochendaily.com",root:"/",version:"1.9.2",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"C"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"left",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 6.0.0"><link rel="alternate" href="/atom.xml" title="haochenBlog" type="application/atom+xml">

<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>EASY</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(https://cdn.staticaly.com/gh/fight-ing-go/image_repository@master/wallpaper_img/wallhaven-72ywpv_1920x1080.1t8ds73xt2yo.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="时序数据异常检测流程与项目实战"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2022-03-25 20:23" pubdate>2022年3月25日 晚上</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 20k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 170 分钟 </span><span id="busuanzi_container_page_pv" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="busuanzi_value_page_pv"></span> 次</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="padding-left:2rem;margin-right:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></aside></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">时序数据异常检测流程与项目实战</h1><div class="markdown-body"><p>本文主要内容为对时序数据异常检测流程进行简单介绍，然后通过项目实战进行详细解释。全文内容根据个人实际经验所得。</p><h1 id="1-总体流程介绍"><a href="#1-总体流程介绍" class="headerlink" title="1.总体流程介绍"></a>1.总体流程介绍</h1><p>针对项目中传感器数据异常检测，经调研后，个人初步总结工程上实现异常检测的流程。流程框图如下图所示：<br><span id="more"></span></p><p><img src="https://cdn.staticaly.com/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Anomaly_detection_process.6l6blsl243s0.jpg" srcset="/img/loading.gif" lazyload alt="Anomaly_detection_process"></p><p>总体步骤有五步：</p><ol><li>数据清洗：对数据做初步处理，方便后续的数据分析。包括时间戳的转换（因为是时序数据，需要对时间列做专门处理）、数据重采样（修改时间频率）、缺失值处理、异常值处理、数据平滑处理</li><li>探索性数据分析EDA：通过作图、制表、方程拟合、计算特征量等手段探索数据的结构和规律的一种数据分析方法。主要是利用各种方式自由探索数据分布、数据相关性等。分析后决定检测哪种类型的异常。</li><li>特征提取/相关性分析：对于单维序列，因为缺乏可用特征，需要进行特征提取，以便后续训练模型，时序序列中比较重要的特征是周比环比。对于多维序列，需要先进行相关性分析，剔除相关性强的数据。要根据检测的异常类型，实施特征提取方案。</li><li>训练模型：对数据分析后选择合适的算法进行建模，用提取出的特征或若相关数据进行模型训练。</li><li>异常检测：利用训练好的模型检测实际数据。单维常用算法有LSTM + Vae，通过预测的方式检测异常；多维可利用孤立森林、SVM、kmeans等。</li></ol><h1 id="2-项目实战"><a href="#2-项目实战" class="headerlink" title="2.项目实战"></a>2.项目实战</h1><p>利用工具：jupyter notebook; 语言：python</p><h2 id="2-1-数据清洗"><a href="#2-1-数据清洗" class="headerlink" title="2.1 数据清洗"></a>2.1 数据清洗</h2><p>实现目标：提取csv文件数据，处理缺失值、异常值、数据平滑化，完成数据清洗。<br>首先加载必要库:</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np <br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd <br><span class="hljs-keyword">import</span> random <span class="hljs-keyword">as</span> rd <br><span class="hljs-keyword">import</span> datetime <br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt <br><span class="hljs-keyword">import</span> matplotlib.dates <span class="hljs-keyword">as</span> mdate<br><span class="hljs-keyword">from</span> statsmodels.tsa.seasonal <span class="hljs-keyword">import</span> seasonal_decompose<br><span class="hljs-keyword">from</span> statsmodels.graphics.tsaplots <span class="hljs-keyword">import</span> plot_acf<br><span class="hljs-keyword">from</span> statsmodels.graphics.tsaplots <span class="hljs-keyword">import</span> plot_pacf<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><span class="hljs-keyword">from</span> statsmodels.tsa.stattools <span class="hljs-keyword">import</span> adfuller<br><span class="hljs-keyword">from</span> scipy <span class="hljs-keyword">import</span> signal<br><span class="hljs-keyword">import</span> warnings<br>warnings.filterwarnings(<span class="hljs-string">"ignore"</span>)<br></code></pre></td></tr></tbody></table></figure><p>提取csv文件,利用pd.read_csv()函数可完整提取表中全部内容，函数有很多参数可以选择，实现众多功能</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#读取表格数据</span><br>data1 = pd.read_csv(<span class="hljs-string">'./data/componet.csv'</span>)<br>data2 = pd.read_csv(<span class="hljs-string">'./data/tehu.csv'</span>)<br>data1 <span class="hljs-comment">#展示data1中数据</span><br></code></pre></td></tr></tbody></table></figure><p>表格数据如图所示：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet.4mjopka34v80.jpg" srcset="/img/loading.gif" lazyload width="60%/"></div><p>查询表中是否有缺失值，使用.isnull()查询，返回含有缺失值的行。我的数据没有缺失值，表为空，就不展示了。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 查看缺失值</span><br>pivot_data[pivot_data.isnull().T.<span class="hljs-built_in">any</span>()]<br></code></pre></td></tr></tbody></table></figure><p>将data1中时间列数据设置为索引，方便查询，也方便可视化</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">data1.index = pd.to_datetime(data1.Datetime) <span class="hljs-comment">#设置时间列为索引</span><br>data1<br></code></pre></td></tr></tbody></table></figure><p>设置完后数据：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_index.78rh4tnfar00.jpg" srcset="/img/loading.gif" lazyload width="60%/"></div><p>先对未处理的数据进行可视化，看看数据形态：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#可视化</span><br><span class="hljs-comment">#设置x轴显示格式，设置x轴显示范围，freq代表间隔频率，tmp_data1.index[0]代表起始时间,tmp_data1.index[-1]代表结束时间</span><br><span class="hljs-keyword">for</span> c_disc <span class="hljs-keyword">in</span> [<span class="hljs-string">'Comp0_Te'</span>,<span class="hljs-string">'Comp1_Te'</span>]:<br>    t_disc = tmp_data1[c_disc]<br>    plt.figure(figsize=(<span class="hljs-number">120</span>,<span class="hljs-number">10</span>))<br>    plt.title(c_disc)    <br>    plt.ylabel(c_disc)    <br>    plt.gca().xaxis.set_major_formatter(mdate.DateFormatter(<span class="hljs-string">'%Y-%m-%d'</span>))<br>    plt.xticks(pd.date_range(tmp_data1.index[<span class="hljs-number">0</span>],tmp_data1.index[-<span class="hljs-number">1</span>],freq=<span class="hljs-string">'D'</span>),rotation=<span class="hljs-number">45</span>) <br>    plt.plot(t_disc)<br></code></pre></td></tr></tbody></table></figure><p>其中一个曲线示意图：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_plot.4833uxky2zg0.jpg" srcset="/img/loading.gif" lazyload width="100%/"></div><p>可以看出，数据有明显的异常点，要么很大，要么很小。为了后面的数据分析与模型训练，我们所以需要对这些明显的异常点进行简单处理。处理方式为使用箱型图，筛选出异常点，然后用前值进行替换。 在此之前，我们先对时间索引进行处理。在这里，我的数据采样间隔大致为2s，但并不固定。因此，在尽可能不影响原数据的情况下，将重采样间隔设置为2S，只做规范时间频率使用。使用resample()函数处理。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#重采样 </span><br>tmp_data1 = data1.resample(<span class="hljs-string">'2S'</span>).mean() <span class="hljs-comment">#时间间隔取2S，mean()取平均值,用tmp_data1接收转换后的表，不改变原表内容</span><br>tmp_data1<br></code></pre></td></tr></tbody></table></figure><p>重采样后的数据：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_resample.tfaifs2cgrk.jpg" srcset="/img/loading.gif" lazyload width="100%/"></div><p>可以看出，数据时间间隔已变为2S等距，且值也有所变化，因为非等距时间间隔，不可避免地出现了缺失值。因此下一步对缺失值进行<strong>填补</strong>。填补策略为：对短时间缺失数据填补，长时间缺失数据删除。填补使用缺失点前7个历史数据的均值填补，以是否连续缺失十个点判断是否是长时间缺失数据。这里自己写了个填补函数用于实现上面的功能。（对于几百万的数据量，填补时间很长，有一两小时）</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">nmeans_fill_missing</span>(<span class="hljs-params">fill_col, df , window=<span class="hljs-number">7</span>, time_range = <span class="hljs-number">10</span></span>):<br>        <span class="hljs-string">'''</span><br><span class="hljs-string">        实现功能： 对表格中的某一列的缺失值进行填补，使用邻近历史数据的均值填补，对于大范围缺失点，不进行填补，可对均值窗口、缺失时间范围进行设置</span><br><span class="hljs-string">        fill_col: 选择插值的列，可填名字，也可填index</span><br><span class="hljs-string">        df: DataFrame,输入需要插值的表</span><br><span class="hljs-string">        window: 插值窗口大小</span><br><span class="hljs-string">        time_range: 设置判断长时间间隔的点数</span><br><span class="hljs-string">        '''</span><br>        <span class="hljs-comment"># count记录起始位置，每当遇到长间隔空值点，会将count移动到下一个非空值点</span><br>        count = <span class="hljs-number">0</span><br>        i=<span class="hljs-number">0</span><br>        <span class="hljs-keyword">while</span> i &lt; <span class="hljs-built_in">len</span>(df):<br>            <span class="hljs-comment"># count += 1</span><br>            value = np.isnan(df[fill_col].iloc[i])   <span class="hljs-comment">#判断当前值是否为空</span><br>            <span class="hljs-keyword">if</span> value == <span class="hljs-literal">True</span>:<br>                <span class="hljs-comment"># 判断当前空值点是否是长间隔</span><br>                islonginterval = islong_missing(fill_col, df , range_window=time_range, row_index=i)<br>                <span class="hljs-comment">#当遇到长间隔空值时，将count一直移动到下一个非空点</span><br>                <span class="hljs-keyword">if</span> islonginterval:<br>                    i += time_range<br>                    <span class="hljs-keyword">while</span> value ==<span class="hljs-literal">True</span> <span class="hljs-keyword">and</span> i&lt;<span class="hljs-built_in">len</span>(df):<br>                        value = np.isnan(df[fill_col].iloc[i])<br>                        i +=<span class="hljs-number">1</span><br>                    count = i   <br>                <span class="hljs-keyword">else</span>:  <br>                    <span class="hljs-keyword">if</span> i - count &lt;= window:         <span class="hljs-comment">#判断当前位置是否有足够历史数据进行插值</span><br>                        <span class="hljs-keyword">if</span> i+window&gt;=<span class="hljs-built_in">len</span>(df):       <span class="hljs-comment">#如果已经到了表格末尾，后续数据不够进行填补，直接略过剩下的点。该策略仅针对数据量足够大的情况</span><br>                            <span class="hljs-keyword">break</span><br>                        train_value_list = []   <span class="hljs-comment">#用于当历史数据不够的情况存放窗口内的点，如 [1,2,3,current:NAN,5,6,7]  此时历史数据不够，则取从1开始的7个点，掠过略过空值</span><br>                        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(window):<br>                            train_value = np.isnan(df[fill_col].iloc[j+count]) <br>                            <span class="hljs-keyword">if</span> train_value == <span class="hljs-literal">False</span>:<br>                                train_value_list.append(df[fill_col].iloc[j+count])<br>                        df[fill_col].iloc[i] = np.array(train_value_list).mean()<br>                    <span class="hljs-keyword">else</span>:<br>                        df[fill_col].iloc[i] = df[fill_col][i - window:i].mean()  <span class="hljs-comment">#如果窗口大小满足，取前window内的均值填补</span><br>            i +=<span class="hljs-number">1</span><br><br>        <span class="hljs-keyword">return</span> df<br><br><span class="hljs-comment"># 判断当前空值点是否是长间隔</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">islong_missing</span>(<span class="hljs-params">fill_col, df , range_window=<span class="hljs-number">10</span>, row_index=<span class="hljs-number">0</span></span>):<br>        <span class="hljs-string">'''</span><br><span class="hljs-string">        判断当前空值点是否是长间隔</span><br><span class="hljs-string">        df: DataFrame,输入需要插值的表  </span><br><span class="hljs-string">        window:插值窗口大小</span><br><span class="hljs-string">        range_window: 设置判断长时间间隔的点数</span><br><span class="hljs-string">        fill_col: 选择插值的列,可填名字.也可填index</span><br><span class="hljs-string">        row_index: 开始判断的起始索引</span><br><span class="hljs-string">        '''</span><br><br>        islonginterval = <span class="hljs-literal">True</span>    <span class="hljs-comment">#判断当前空值是否属于长时间范围内的空值，是的话就跳过，不进行插值填补</span><br>        count = <span class="hljs-number">1</span><br>        <span class="hljs-comment"># 判断逻辑：判断后续十个时间点是否为空，当存在一个非空点，即跳出循环，且islonginterval为false</span><br>        <span class="hljs-keyword">while</span> row_index+count&lt;<span class="hljs-built_in">len</span>(df) <span class="hljs-keyword">and</span> islonginterval==<span class="hljs-literal">True</span> <span class="hljs-keyword">and</span> count&lt;=range_window:<br>            islonginterval = np.isnan(df[fill_col].iloc[row_index+count])<br>            count +=<span class="hljs-number">1</span><br><br>        <span class="hljs-keyword">return</span> islonginterval<br><br><span class="hljs-comment">#对两列分别填补</span><br><span class="hljs-keyword">for</span> c_disc <span class="hljs-keyword">in</span> [<span class="hljs-string">'Comp0_Te'</span>,<span class="hljs-string">'Comp1_Te'</span>]:<br>    tmp_data1 = nmeans_fill_missing(c_disc, tmp_data1, window=<span class="hljs-number">7</span>)<br>tmp_data1<br></code></pre></td></tr></tbody></table></figure><p>为了检验填补效果，又写了个子函数，用来获取每次检测到的长间隔时间端的开始时间和结束时间对于的行数。根据返回的结果，查询对应的时间信息，判断是否满足填补策略</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">find_long_missing</span>(<span class="hljs-params">fill_col, df , time_range = <span class="hljs-number">10</span></span>):<br>        <span class="hljs-string">'''</span><br><span class="hljs-string">        实现功能： 获取长间隔断点的点信息，返回dot_list数组，每两个为一对时间段</span><br><span class="hljs-string">        fill_col: 选择插值的列，可填名字，也可填index</span><br><span class="hljs-string">        df: DataFrame,输入需要插值的表</span><br><span class="hljs-string">        time_range: 设置判断长时间间隔的点数</span><br><span class="hljs-string">        '''</span><br>        <span class="hljs-comment"># count记录起始位置，每当遇到长间隔空值点，会将count移动到下一个非空值点</span><br>        i=<span class="hljs-number">0</span><br>        dot_list = []<br>        <span class="hljs-keyword">while</span> i &lt; <span class="hljs-built_in">len</span>(df):<br>            value = np.isnan(df[fill_col].iloc[i])   <span class="hljs-comment">#判断当前值是否为空</span><br>            <span class="hljs-keyword">if</span> value == <span class="hljs-literal">True</span>:<br>                <span class="hljs-comment"># 判断当前空值点是否是长间隔</span><br>                islonginterval = islong_missing(fill_col, df , range_window=time_range, row_index=i)<br>                <span class="hljs-comment">#当遇到长间隔空值时，将count一直移动到下一个非空点</span><br>                <span class="hljs-keyword">if</span> islonginterval:<br>                    dot_list.append(i)<br>                    i += (time_range-<span class="hljs-number">1</span>)<br>                    <span class="hljs-keyword">while</span> value ==<span class="hljs-literal">True</span> <span class="hljs-keyword">and</span> i&lt;<span class="hljs-built_in">len</span>(df):<br>                        i +=<span class="hljs-number">1</span><br>                        value = np.isnan(df[fill_col].iloc[i])<br>                        <br>                    dot_list.append(i)   <br>            i +=<span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> dot_list<br></code></pre></td></tr></tbody></table></figure><p>然后删除缺失值并导出。使用reset_index()是为了让时间索引一起导出来。这里用的导出方法缺点是索引需要自己手动加上去。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#删除缺失值</span><br>tmp_data1 = tmp_data1.dropna(axis = <span class="hljs-number">0</span>, how = <span class="hljs-string">'all'</span>,inplace = <span class="hljs-literal">False</span>)<br><span class="hljs-comment">#避免之后重新填补，导出经插值，删除空值后的表</span><br>path = os.path.abspath(<span class="hljs-string">r'./data/l1_tehu'</span>)  <span class="hljs-comment"># 文件夹路径</span><br>new_file_name = <span class="hljs-string">'tmp_data1_insert.csv'</span><br>tmp_data1.reset_index().to_csv(path + <span class="hljs-string">'/'</span> + new_file_name, mode=<span class="hljs-string">'a'</span>, encoding=<span class="hljs-string">'gbk'</span>, header=<span class="hljs-literal">False</span>, index=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></tbody></table></figure><p>下面对前面的<strong>异常值</strong>进行处理。这里只选取其中一个片段进行示范。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">twoday_data = tmp_data1[<span class="hljs-string">'2021-11-01 18:58:30'</span>: <span class="hljs-string">'2021-11-03 11:35:00'</span>]<br>twoday_data.describe()  <span class="hljs-comment">#描述表的一些信息</span><br></code></pre></td></tr></tbody></table></figure><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_twoday_describe.3qyix6pukji0.jpg" srcset="/img/loading.gif" lazyload width="40%/"></div><p>画出箱线图，可以看出存在的一些异常点：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">plt.subplot(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>)<br>plt.boxplot(twoday_data[<span class="hljs-string">'Comp0_Te'</span>])<br>plt.subplot(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>)<br>plt.boxplot(twoday_data[<span class="hljs-string">'Comp1_Te'</span>])<br>plt.figure(figsize=(<span class="hljs-number">20</span>,<span class="hljs-number">10</span>))<br>plt.show()<br></code></pre></td></tr></tbody></table></figure><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_twoday_boxplot.705wl11k1jo0.jpg" srcset="/img/loading.gif" lazyload width="60%/"></div><p>然后利用四分位，删除异常值并用前值进行填补。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 超过了上四分位2倍四分位距或下四分位2倍距离都算异常值，用上一个值填充</span><br>a = twoday_data[<span class="hljs-string">'Comp0_Te'</span>].quantile(<span class="hljs-number">0.75</span>)<br>b = twoday_data[<span class="hljs-string">'Comp0_Te'</span>].quantile(<span class="hljs-number">0.25</span>)<br>c = twoday_data[<span class="hljs-string">'Comp0_Te'</span>]<br>c[(c&gt;=(a-b)*<span class="hljs-number">2</span>+a)|(c&lt;=b-(a-b)*<span class="hljs-number">2</span>)]=np.nan<br>c.fillna(method=<span class="hljs-string">'pad'</span>,inplace=<span class="hljs-literal">True</span>)<br>twoday_data[<span class="hljs-string">'Comp0_Te'</span>] = c<br><span class="hljs-built_in">print</span>(twoday_data[<span class="hljs-string">'Comp0_Te'</span>].describe())<br></code></pre></td></tr></tbody></table></figure><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_twoday_boxplot_new.44m969zxzbg0.jpg" srcset="/img/loading.gif" lazyload width="60%/"></div><p>异常值处理完后，还有数据平滑处理。平滑处理在第二张表中演示。下面处理第二张表的数据。同样的操作，先将时间列设为索引，展示data2中数据：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">data2.index = pd.to_datetime(data2.Datetime) <span class="hljs-comment">#设置时间列为索引</span><br>data2<br></code></pre></td></tr></tbody></table></figure><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/L1_id_data.6dh59h41kq40.jpg" srcset="/img/loading.gif" lazyload width="40%/"></div><p>表中有个ID列，表示各个传感器的型号，做数据分析时，可以将ID列提取出来，作为列索引，方便观察。因此，先对表格进行<strong>透视</strong>：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#数据透视</span><br><span class="hljs-comment">#tmp_data2用来拷贝data2数据变为二重索引表，原表数据保留 </span><br>tmp_data2=data2   <br>tmp_data2[<span class="hljs-string">'L1_id'</span>] = tmp_data2[<span class="hljs-string">'L1_id'</span>].astype(<span class="hljs-built_in">str</span>)<br>tmp_data2=data2.pivot_table(index=<span class="hljs-string">'Datetime'</span>,columns=<span class="hljs-string">'L1_id'</span>)<br>tmp_data2<br></code></pre></td></tr></tbody></table></figure><p>透视结果如下所示：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/L1_id_pivot.2ab6wthn3ack.jpg" srcset="/img/loading.gif" lazyload width="100%/"></div><p>表格的列变成了二重索引，为了方便后续引用，将其变为一重索引。需要注意的是，这种变换需要数据类型都为string型，如果不是，需要提前转换。当然，还有一种手动方法，变为二重索引后导出表，将原列索引删除，自己再加上索引就好。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#改为一重列索引表，用one_class_data2表示</span><br>one_class_data2 =tmp_data2.copy(deep=<span class="hljs-literal">True</span>)  <span class="hljs-comment">#拷贝表格</span><br>one_class_data2.columns = [<span class="hljs-string">"_"</span>.join(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> one_class_data2.columns.ravel()]  <span class="hljs-comment">#将原来的二重索引的列名进行拼接</span><br><span class="hljs-comment"># one_class_data2.columns = tmp_data2.columns.droplevel(0)  #这个方法是直接将外围第二重索引去掉，只取第一重列索引。</span><br>one_class_data2<br></code></pre></td></tr></tbody></table></figure><p>结果如下：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/L1_id_oneclass.59gip30dtvk0.jpg" srcset="/img/loading.gif" lazyload width="100%/"></div><p>可以看到，列已经变为一重，列名为二重列名拼接而成。后续步骤与第一张表一样，这里不再做解释。最后再对其进行<strong>平滑处理</strong>。平滑方式选用传统的<em>巴特沃斯</em> 低通滤波器。对于参数wn的确定，首先采样频率定为1=采样长度/采样时间（其实采样频率可以自己定，其他的频率以采样频率为基准进行计算即可，结果都一样）。截止频率需要根据实际的来，我的数据中最大的频率差不多以77个点为一个周期，所以稍微扩大下范围后计算截止频率 = 1/60（采样频率为1，那么采样时间即为周期T=1）。根据公式wn = 2*截止频率/采样频率 = 0.033。以两天的数据量为例。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 低通滤波器-巴特沃斯</span><br><span class="hljs-comment"># wn=2*截至频率/采样频率   如果一天采样10个点，采样频率为10，截止频率为想要滤除的频率上限或下限</span><br><span class="hljs-comment"># pivot_data为透视后清理完的表</span><br>twoday_data = pivot_data[<span class="hljs-string">'2022-01-26 00:00:00'</span>:<span class="hljs-string">'2022-01-28 00:00:00'</span>]<br>b, a = signal.butter(<span class="hljs-number">10</span>, <span class="hljs-number">0.033</span>, <span class="hljs-string">'lowpass'</span>) <span class="hljs-comment">#配置滤波器 8 表示滤波器的阶数</span><br>twoday_data[<span class="hljs-string">'Te_0_filter'</span>] = signal.filtfilt(b, a, twoday_data[<span class="hljs-string">'Te_0'</span>])<br></code></pre></td></tr></tbody></table></figure><p>滤波结果如下：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/butter.6leaq5g4j7s0.jpg" srcset="/img/loading.gif" lazyload width="50%/"></div><h2 id="2-2-探索性数据分析EDA"><a href="#2-2-探索性数据分析EDA" class="headerlink" title="2.2 探索性数据分析EDA"></a>2.2 探索性数据分析EDA</h2><p>首先进行相关性分析。这里以表data2为例。分析的数据取较完整地一个月的时间片段，重采样为1min适当减小数据量。（记得导入表后先设置时间索引）</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">Month_data2 = data2[<span class="hljs-string">'2022-01-25 13:12:30'</span>:<span class="hljs-string">'2022-02-24 15:13:00'</span>]<br><span class="hljs-comment"># 重采样一分钟(一个月数据)</span><br>Month_data2_1T = Month_data2.resample(<span class="hljs-string">'T'</span>).mean()<br>Month_data2_1T=Month_data2_1T.<span class="hljs-built_in">round</span>(<span class="hljs-number">2</span>) <span class="hljs-comment">#保留两位小数。</span><br><span class="hljs-comment"># 相关系数</span><br>Month_data2_1T.corr()<br></code></pre></td></tr></tbody></table></figure><p>这里仅展示部分结果图：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data2_1T_corr.5gurkritpvs0.jpg" srcset="/img/loading.gif" lazyload width="50%/"></div><p>可以看到，每个变量间的相关程度都很高，不利用互相作为特征值。<br>对数据的自相关性和偏相关性进行分析。自相关：描述的是一组时间序列和它前面间隔n个时刻的一组时间序列之前的相关性。偏自相关：描述的是一组时间序列和它前面间隔n个时刻的一组时间序列之前的偏相关性。这里的偏相关性可以从本质上理解为去除了样本之间的干涉，也就是更早时刻的相关性影响。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 自相关，偏自相关，列出每一列的相关图</span><br>col = Month_data2_1T.columns<br><span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> col:  <br>    fig = plt.figure(figsize=(<span class="hljs-number">12</span>,<span class="hljs-number">4</span>))<br>    ax1 = fig.add_subplot(<span class="hljs-number">121</span>)<br>    ax1.set_xlabel(c)<br>    ax2 = fig.add_subplot(<span class="hljs-number">122</span>)<br>    ax2.set_xlabel(c)<br>    plot_acf(Month_data2_1T[c],lags=<span class="hljs-number">50</span>,ax = ax1)<br>    plot_pacf(Month_data2_1T[c],lags=<span class="hljs-number">50</span>,ax = ax2)<br>    plt.tight_layout()<br></code></pre></td></tr></tbody></table></figure><p>同样的，展示部分结果图。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data2_1T_acf.3xqf5jmk4f80.jpg" srcset="/img/loading.gif" lazyload width="60%/"></div><p>研究自相关、偏相关可用于判断是否适合使用时间预测方法,也可用于查看周期（下面会有演示）。该图可应用于LSTM算法，作为参数选择的依据。具体使用方法有待明确。<br>查看温湿度的统计分布。这里仅仅是查看下数据分布，目前没有对于其分析的一些想法。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 管道温湿度统计分布图</span><br><span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> col: <br>    plt.figure(figsize=(<span class="hljs-number">15</span>, <span class="hljs-number">3</span>))<br>    sns.distplot(Month_data2_1T[c], bins=<span class="hljs-built_in">int</span>(np.sqrt(<span class="hljs-built_in">len</span>(Month_data2_1T[c]))))<br></code></pre></td></tr></tbody></table></figure><p>展示部分结果图。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data2_1T_distplot.462fv8dw1b00.jpg" srcset="/img/loading.gif" lazyload width="60%/"></div><p>数据平稳性判断，使用单位根检验法。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">check_stationarity</span>(<span class="hljs-params">y, lags_plots=<span class="hljs-number">48</span>, figsize=(<span class="hljs-params"><span class="hljs-number">22</span>,<span class="hljs-number">8</span></span>)</span>):<br>    <span class="hljs-string">"Use Series as parameter"</span><br>    <span class="hljs-comment"># Creating plots of the DF</span><br>    y = pd.Series(y)<br>    fig = plt.figure()<br><br>    ax1 = plt.subplot2grid((<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>), colspan=<span class="hljs-number">2</span>)<br>    ax2 = plt.subplot2grid((<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), (<span class="hljs-number">1</span>, <span class="hljs-number">0</span>))<br>    ax3 = plt.subplot2grid((<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    ax4 = plt.subplot2grid((<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), (<span class="hljs-number">2</span>, <span class="hljs-number">0</span>), colspan=<span class="hljs-number">2</span>)<br><br>    y.plot(ax=ax1, figsize=figsize)<br>    ax1.set_title(<span class="hljs-string">'Nums Variation'</span>)<br>    plot_acf(y, lags=lags_plots, zero=<span class="hljs-literal">False</span>, ax=ax2);<br>    plot_pacf(y, lags=lags_plots, zero=<span class="hljs-literal">False</span>, ax=ax3);<br>    sns.distplot(y, bins=<span class="hljs-built_in">int</span>(np.sqrt(<span class="hljs-built_in">len</span>(y))), ax=ax4)<br>    ax4.set_title(<span class="hljs-string">'Distribution Chart'</span>)<br><br>    plt.tight_layout()<br>    <span class="hljs-comment"># plt.show()</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">'Results of Dickey-Fuller Test:'</span>)<br>    <span class="hljs-comment">#  regression：{c”，“ct”，“ctt”，“n”}要包含在回归中的常数和趋势顺序。</span><br>    <span class="hljs-comment"># “c”：仅限常量（默认值）。</span><br>    <span class="hljs-comment"># “ct”：恒定和趋势。</span><br>    <span class="hljs-comment"># “ctt”：常数、线性和二次趋势。</span><br>    <span class="hljs-comment"># n：没有常数，没有趋势。</span><br><br>    <span class="hljs-comment"># ADF的结果主要看以下两个方面：</span><br>    <span class="hljs-comment"># Test Statistic的值如果比Critical Value (5%)小则满足稳定性需求.</span><br>    <span class="hljs-comment"># p-value越低（理论上需要低于0.05）证明序列越稳定。</span><br>    adfinput = adfuller(y,regression = <span class="hljs-string">'c'</span>)  <span class="hljs-comment">#单位根检验</span><br>    adftest = pd.Series(adfinput[<span class="hljs-number">0</span>:<span class="hljs-number">4</span>], index=[<span class="hljs-string">'Test Statistic'</span>,<span class="hljs-string">'p-value'</span>,<span class="hljs-string">'Lags Used'</span>,<span class="hljs-string">'Number of Observations Used'</span>])<br>    adftest = <span class="hljs-built_in">round</span>(adftest,<span class="hljs-number">4</span>)<br>    <span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> adfinput[<span class="hljs-number">4</span>].items():<br>        adftest[<span class="hljs-string">"Critical Value (%s)"</span>%key] = value.<span class="hljs-built_in">round</span>(<span class="hljs-number">4</span>)<br>        <br>    <span class="hljs-built_in">print</span>(adftest)<br>    <br>    <span class="hljs-keyword">if</span> adftest[<span class="hljs-number">0</span>].<span class="hljs-built_in">round</span>(<span class="hljs-number">2</span>) &lt; adftest[<span class="hljs-number">5</span>].<span class="hljs-built_in">round</span>(<span class="hljs-number">2</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">'\nThe Test Statistics is lower than the Critical Value of 5%.\nThe serie seems to be stationary'</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">"\nThe Test Statistics is higher than the Critical Value of 5%.\nThe serie isn't stationary"</span>)<br><br><span class="hljs-comment"># 检验平稳性</span><br>check_stationarity(Month_data2_1T[<span class="hljs-string">'Te_0'</span>])<br></code></pre></td></tr></tbody></table></figure><blockquote><p>输出结果为：<br>Results of Dickey-Fuller Test:<br>Test Statistic -1.4583<br>p-value 0.5540<br>Lags Used 55.0000<br>Number of Observations Used 43266.0000<br>Critical Value (1%) -3.4305<br>Critical Value (5%) -2.8616<br>Critical Value (10%) -2.5668<br>dtype: float64<br>The Test Statistics is higher than the Critical Value of 5%.<br>The serie isn’t stationary</p></blockquote><p>判断平稳性两个标准：Test Statistic小于Critical Value (5%)　或是p-value小于0.05。平稳性是多数统计学模型的必要条件之一。可见原数据并不是平稳序列。<br>对于非平稳序列，可使用一阶差分使其平稳化。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#序列平稳化，一阶差分</span><br>Month_data2_1T[<span class="hljs-string">'Te_0_diff'</span>] = Month_data2_1T[<span class="hljs-string">'Te_0'</span>].diff(<span class="hljs-number">1</span>)<br></code></pre></td></tr></tbody></table></figure><p>其稳定性结果为：</p><blockquote><p>Results of Dickey-Fuller Test:<br>Test Statistic -51.9122<br>p-value 0.0000<br>Lags Used 54.0000<br>Number of Observations Used 43267.0000<br>Critical Value (1%) -3.4305<br>Critical Value (5%) -2.8616<br>Critical Value (10%) -2.5668<br>dtype: float64<br>The Test Statistics is lower than the Critical Value of 5%.<br>The serie seems to be stationary</p></blockquote><p>可见一阶差分可以有效是原序列平稳。后期可利用差分序列进行异常检测训练。<br>时间序列分解：所谓分解就是将时序数据分离成不同的成分，分解为：长期趋势Trend、季节性Seasonality和随机残差Residuals。分解序列后可针对每个子序列分别建模处理，如建模趋势后，在原数据中减去趋势的干扰。又或者当作特征值。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 管道温湿度时序序列分解：趋势+季节性+残差</span><br>col = Month_data2_1T.columns<br><span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> col:  <br>    <span class="hljs-comment">#用加性模型，周期1440为1440min，分解数据时间频率为1min，一天为1440min。这里将一天设为周期，那么分解出的季节性数据以1天为周期</span><br>    decompose_result = seasonal_decompose(Month_data2_1T[c], model=<span class="hljs-string">"additive"</span>, period=<span class="hljs-number">1440</span>)<br>    fig = plt.figure(figsize=(<span class="hljs-number">20</span>,<span class="hljs-number">18</span>))<br>    ax1 = fig.add_subplot(<span class="hljs-number">411</span>)<br>    ax2 = fig.add_subplot(<span class="hljs-number">412</span>)<br>    ax3 = fig.add_subplot(<span class="hljs-number">413</span>)<br>    ax4 = fig.add_subplot(<span class="hljs-number">414</span>)<br>    ax1.set_xlabel(c)<br>    ax1.set_ylabel(<span class="hljs-string">'init'</span>)<br>    ax2.set_xlabel(c)<br>    ax2.set_ylabel(<span class="hljs-string">'trend'</span>)<br>    ax3.set_xlabel(c)<br>    ax3.set_ylabel(<span class="hljs-string">'seasonal'</span>)<br>    ax4.set_xlabel(c)<br>    ax4.set_ylabel(<span class="hljs-string">'resid'</span>)<br>    ax1.plot(Month_data2_1T[c])<br>    ax2.plot(decompose_result.trend)<br>    ax3.plot(decompose_result.seasonal)<br>    ax4.plot(decompose_result.resid)<br>    plt.tight_layout()<br></code></pre></td></tr></tbody></table></figure><p>部分结果如下：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data2_1T_decompose.7bi8h01gdf40.jpg" srcset="/img/loading.gif" lazyload width="80%/"></div><p>接下来进行周期性检验。首先使用FFT查看频谱图：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">define_fft</span>(<span class="hljs-params">data, fs = <span class="hljs-number">1</span>, show_pic=<span class="hljs-literal">False</span></span>): <br>    <span class="hljs-string">""" </span><br><span class="hljs-string">    # Parameters  </span><br><span class="hljs-string"></span><br><span class="hljs-string">    data: 检测数据，dataframe类型 </span><br><span class="hljs-string">    show_pic: 是否展示图片 </span><br><span class="hljs-string">    fs: 采样频率，采样时长除以采样点数 = 采样频率</span><br><span class="hljs-string">    """</span> <br>    n = data.shape[<span class="hljs-number">0</span>]<br>    x = data.values<br>    yy = fft(x)<br>    fre = fftfreq(n, <span class="hljs-number">1</span>/fs)			<span class="hljs-comment">#求频率横坐标</span><br>    indices = np.where(fre &gt; <span class="hljs-number">0</span>)		<span class="hljs-comment">#筛选大于零的频率</span><br>    w_pos = <span class="hljs-number">2</span>*<span class="hljs-built_in">abs</span>(yy[indices])/n	<span class="hljs-comment">#计算幅度值</span><br>    F_pos = fre[indices]			<br><br>    result_fft = pd.DataFrame(columns=[<span class="hljs-string">'freq'</span>, <span class="hljs-string">'spec'</span>, <span class="hljs-string">'T'</span>]) <br>    result_fft[<span class="hljs-string">'freq'</span>] = F_pos <br>    result_fft[<span class="hljs-string">'spec'</span>] = w_pos <br>    result_fft[<span class="hljs-string">'T'</span>] = <span class="hljs-number">1</span>/F_pos/<span class="hljs-number">1440</span><br>    <span class="hljs-comment"># 按照频率强弱程度降序排列 </span><br>    result_fft = result_fft.sort_values(by=<span class="hljs-string">'spec'</span>, ascending=<span class="hljs-literal">False</span>) <br>    <span class="hljs-built_in">print</span>(result_fft.head(<span class="hljs-number">10</span>))<br>    <span class="hljs-keyword">if</span> show_pic :<br>        <span class="hljs-comment"># 频率转换为周期 </span><br>        plt.plot(<span class="hljs-number">1</span>/F_pos/<span class="hljs-number">1440</span>, w_pos)<br>        plt.show()<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br><br>define_fft(Month_data2_1T[<span class="hljs-string">'Te_0'</span>],fs=<span class="hljs-number">1</span>,show_pic=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></tbody></table></figure><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data_1T_periodogram.bx0uzqbkjcw.jpg" srcset="/img/loading.gif" lazyload width="40%/"> <img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data_1T_residperiod.4rqdgw1afwu0.jpg" srcset="/img/loading.gif" lazyload width="30%/"></div><p>查看左侧频谱图，可以发现图是有问题的。在周期最大的三个点，也即频率最小的三个点处出现了很大的峰值，低频成分上翘，这明显不对。考虑原因可能有二。</p><ol><li>原数据存在直流偏移的影响。<br>解决办法：减去直流量，试减去平均值</li><li>原数据中趋势的存在干扰了频谱分析。当信号中有明显的趋势项而未消除时，进行相关性分析和功率谱密度分析时会出现畸变，造成低频成分上翘甚至淹没主频成分。<br>解决办法：去趋势。</li></ol><p>对原数据减去平均值后进行FFT分析，发现频谱图的形状并没有变化，改试方案2。去趋势的方法在网上有许多，这里使用了两种办法：多项式拟合去趋势和时序序列分解。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 多项式拟合去趋势,使用滤波后的数据</span><br>n = Month_data2_1T[<span class="hljs-string">'Te_0_filter'</span>].shape[<span class="hljs-number">0</span>]<br>x=np.linspace(<span class="hljs-number">1</span>, n, n)<br>y = Month_data_1T[<span class="hljs-string">'Te_0_filter'</span>].values<br>z1 = np.polyfit(x, y, <span class="hljs-number">10</span>)              <span class="hljs-comment"># 曲线拟合，返回值为多项式的各项系数，10为阶数，具体数据选取看曲线拟合程度，可进行可视化查看</span><br>p1 = np.poly1d(z1)                    <span class="hljs-comment"># 返回值为多项式的表达式，也就是函数式子</span><br><span class="hljs-comment"># print(p1)</span><br>y_pred = p1(x)                        <span class="hljs-comment"># 根据函数的多项式表达式，求解 y,即趋势</span><br>Month_data_1T[<span class="hljs-string">'x'</span>]=Month_data_1T[<span class="hljs-string">'Te_0_filter'</span>]-y_pred<br>define_fft(Month_data_1T[<span class="hljs-string">'x'</span>],fs=<span class="hljs-number">1</span>,show_pic=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></tbody></table></figure><p>下图为原数据曲线图、趋势图、原数据去趋势图和FFT图。可以看出，用拟合法去趋势后，FFT图尾端翘起现象几乎没有了，但仍有小尾巴残留。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/polyfit.1wq4d6hwhjq8.jpg" srcset="/img/loading.gif" lazyload width="80%/"> <img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/polyfit_detrend.2eofsy7hwrwg.jpg" srcset="/img/loading.gif" lazyload width="80%/"> <img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/ployfit_FFT.4u82p09d7n60.jpg" srcset="/img/loading.gif" lazyload width="50%/"></div><p>接下来是由时序序列分解法。该方法上面讲过了，操作步骤一致，只是在分解趋势适合，分解了两次，使用77周期分解以此，发现还有周期现象，又使用1440周期对分解出的趋势分解了一次，对用原数据减去二次趋势，再求FFT，结果如图。第一张为去趋势后的图，第二张为FFT结果图。可以看出，该方法去趋势效果更好。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/twice_detrend.7jhgdh1lahw0.jpg" srcset="/img/loading.gif" lazyload width="80%/"> <img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/twice_detrend_FFT.ekqba34lveo.jpg" srcset="/img/loading.gif" lazyload width="40%/"></div><p>根据频谱图结果，列出最大的三个能量谱的点依次为1天，0.5天，77min。可能的周期也是这三个点。再根据这三个点看自相关图，分别列出滞后点为1000和10000的相关图。如图所示。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/acf_1000.hy1dzybmthk.jpg" srcset="/img/loading.gif" lazyload width="80%/"></div>对于自相关图，当序列存在周期时，会在周期出出现一个高峰。从图中可以看出，曲线分别以约77和1440为周期处出现高峰。再结合实际，77min大致为系统运行一个周期，1440min为系统运行一天。由此可见，数据约以77min和1440min为周期。<h2 id="2-3-特征工程"><a href="#2-3-特征工程" class="headerlink" title="2.3 特征工程"></a>2.3 特征工程</h2><h3 id="2-3-1-特征提取"><a href="#2-3-1-特征提取" class="headerlink" title="2.3.1 特征提取"></a>2.3.1 特征提取</h3><ol><li><strong>从时间中提取特征</strong><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#仅取第一列Hu_0数据</span><br>df = Month_data_1T.iloc[:,<span class="hljs-number">0</span>:<span class="hljs-number">1</span>]<br>df[<span class="hljs-string">'时间'</span>] = df.index<br><span class="hljs-comment"># 年份</span><br>df[<span class="hljs-string">'年'</span>]=df[<span class="hljs-string">'时间'</span>].apply(<span class="hljs-keyword">lambda</span> x: x.year)<br><span class="hljs-comment"># 月份</span><br>df[<span class="hljs-string">'月'</span>]=df[<span class="hljs-string">'时间'</span>].apply(<span class="hljs-keyword">lambda</span> x: x.month)<br><span class="hljs-comment"># 日</span><br>df[<span class="hljs-string">'日'</span>]=df[<span class="hljs-string">'时间'</span>].apply(<span class="hljs-keyword">lambda</span> x: x.day)<br><span class="hljs-comment"># 小时</span><br>df[<span class="hljs-string">'时'</span>]=df[<span class="hljs-string">'时间'</span>].apply(<span class="hljs-keyword">lambda</span> x: x.hour)<br><span class="hljs-comment"># 分钟</span><br>df[<span class="hljs-string">'分'</span>]=df[<span class="hljs-string">'时间'</span>].apply(<span class="hljs-keyword">lambda</span> x: x.minute)<br><span class="hljs-comment"># 一天中的第几分钟</span><br>df[<span class="hljs-string">'一天中的第几分钟'</span>]=df[<span class="hljs-string">'时间'</span>].apply(<span class="hljs-keyword">lambda</span> x: x.minute + x.hour*<span class="hljs-number">60</span>)<br><span class="hljs-comment"># 星期几；</span><br>df[<span class="hljs-string">'星期几'</span>]=df[<span class="hljs-string">'时间'</span>].apply(<span class="hljs-keyword">lambda</span> x: x.dayofweek)<br><span class="hljs-comment"># 一年中的第几天</span><br>df[<span class="hljs-string">'一年中的第几天'</span>]=df[<span class="hljs-string">'时间'</span>].apply(<span class="hljs-keyword">lambda</span> x: x.dayofyear)<br><span class="hljs-comment"># # 一年中的第几周</span><br><span class="hljs-comment"># df['一年中的第几周']=df['时间'].apply(lambda x: x.week)</span><br><span class="hljs-comment"># 一天中哪个时间段：凌晨、早晨、上午、中午、下午、傍晚、晚上、深夜；</span><br>period_dict ={<br>    <span class="hljs-number">23</span>: <span class="hljs-number">0x00</span>, <span class="hljs-number">0</span>: <span class="hljs-number">0x00</span>, <span class="hljs-number">1</span>: <span class="hljs-number">0x00</span>,<br>    <span class="hljs-number">2</span>: <span class="hljs-number">0x01</span>, <span class="hljs-number">3</span>: <span class="hljs-number">0x01</span>, <span class="hljs-number">4</span>: <span class="hljs-number">0x01</span>,<br>    <span class="hljs-number">5</span>: <span class="hljs-number">0x02</span>, <span class="hljs-number">6</span>: <span class="hljs-number">0x02</span>, <span class="hljs-number">7</span>: <span class="hljs-number">0x02</span>,<br>    <span class="hljs-number">8</span>: <span class="hljs-number">0x03</span>, <span class="hljs-number">9</span>: <span class="hljs-number">0x03</span>, <span class="hljs-number">10</span>: <span class="hljs-number">0x03</span>, <span class="hljs-number">11</span>: <span class="hljs-number">0x03</span>,<br>    <span class="hljs-number">12</span>: <span class="hljs-number">0x04</span>, <span class="hljs-number">13</span>: <span class="hljs-number">0x04</span>,<span class="hljs-number">14</span>: <span class="hljs-number">0x04</span>, <br>    <span class="hljs-number">15</span>: <span class="hljs-number">0x05</span>, <span class="hljs-number">16</span>: <span class="hljs-number">0x05</span>, <span class="hljs-number">17</span>: <span class="hljs-number">0x05</span>,<span class="hljs-number">18</span>: <span class="hljs-number">0x05</span>,<br>    <span class="hljs-number">19</span>: <span class="hljs-number">0x07</span>, <span class="hljs-number">20</span>: <span class="hljs-number">0x07</span>, <span class="hljs-number">21</span>: <span class="hljs-number">0x07</span>, <span class="hljs-number">22</span>: <span class="hljs-number">0x07</span>,<br><span class="hljs-comment">#     23: '深夜', 0: '深夜', 1: '深夜',</span><br><span class="hljs-comment">#     2: '凌晨', 3: '凌晨', 4: '凌晨',</span><br><span class="hljs-comment">#     5: '早晨', 6: '早晨', 7: '早晨',</span><br><span class="hljs-comment">#     8: '上午', 9: '上午', 10: '上午', 11: '上午',</span><br><span class="hljs-comment">#     12: '中午', 13: '中午',14: '中午',</span><br><span class="hljs-comment">#     15: '下午', 16: '下午', 17: '下午',18: '下午',</span><br><span class="hljs-comment">#     19: '晚上', 20: '晚上', 21: '晚上', 22: '晚上',</span><br>}<br>df[<span class="hljs-string">'时间段'</span>]=df[<span class="hljs-string">'时'</span>].<span class="hljs-built_in">map</span>(period_dict)<br><span class="hljs-comment"># # 一年中的哪个季度</span><br><span class="hljs-comment"># season_dict = {</span><br><span class="hljs-comment">#     1: '春季', 2: '春季', 3: '春季',</span><br><span class="hljs-comment">#     4: '夏季', 5: '夏季', 6: '夏季',</span><br><span class="hljs-comment">#     7: '秋季', 8: '秋季', 9: '秋季',</span><br><span class="hljs-comment">#     10: '冬季', 11: '冬季', 12: '冬季',</span><br><span class="hljs-comment"># }</span><br><span class="hljs-comment"># df['季节']=df['月'].map(season_dict)</span><br><span class="hljs-comment"># # 是否闰年</span><br><span class="hljs-comment"># df['是否闰年'] = df['时间'].apply(lambda x: x.is_leap_year)</span><br><span class="hljs-comment"># 是否月初</span><br>df[<span class="hljs-string">'是否月初'</span>] = df[<span class="hljs-string">'时间'</span>].apply(<span class="hljs-keyword">lambda</span> x: x.is_month_start)<br><span class="hljs-comment"># 是否月末</span><br>df[<span class="hljs-string">'是否月末'</span>] = df[<span class="hljs-string">'时间'</span>].apply(<span class="hljs-keyword">lambda</span> x: x.is_month_end)<br><span class="hljs-comment"># 是否季节初</span><br><span class="hljs-comment"># df['是否季节初'] = df['时间'].apply(lambda x: x.is_quarter_start)</span><br><span class="hljs-comment"># 是否季节末</span><br><span class="hljs-comment"># df['是否季节末'] = df['时间'].apply(lambda x: x.is_quarter_end)</span><br><span class="hljs-comment"># 是否年初</span><br><span class="hljs-comment"># df['是否年初'] = df['时间'].apply(lambda x: x.is_year_start)</span><br><span class="hljs-comment"># 是否年尾</span><br><span class="hljs-comment"># df['是否年尾'] = df['时间'].apply(lambda x: x.is_year_end)</span><br><span class="hljs-comment"># 是否周末</span><br>df[<span class="hljs-string">'是否周末'</span>] = df[<span class="hljs-string">'时间'</span>].apply(<span class="hljs-keyword">lambda</span> x: <span class="hljs-literal">True</span> <span class="hljs-keyword">if</span> x.dayofweek <span class="hljs-keyword">in</span> [<span class="hljs-number">5</span>, <span class="hljs-number">6</span>] <span class="hljs-keyword">else</span> <span class="hljs-literal">False</span>)<br>df<br></code></pre></td></tr></tbody></table></figure>结果如下图所示：<div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202204/Characteristic-Engineering-of-Time-Series/时间特征.407xag8uznw0.jpg" srcset="/img/loading.gif" lazyload></div></li><li><strong>从时序规律中提取特征</strong><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> statsmodels.tsa.seasonal <span class="hljs-keyword">import</span> seasonal_decompose<br><span class="hljs-comment"># 数据含有两个周期77和1440</span><br><span class="hljs-comment"># 偏移6min差分</span><br>df[<span class="hljs-string">"Hu0_-5S"</span>] = df[<span class="hljs-string">'Hu_0'</span>].shift(<span class="hljs-number">6</span>)<br><span class="hljs-comment"># 偏移77min差分，一小周期</span><br>df[<span class="hljs-string">"Hu0_-1period"</span>] = df[<span class="hljs-string">'Hu_0'</span>].shift(<span class="hljs-number">1</span>*<span class="hljs-number">77</span>)<br><span class="hljs-comment"># 偏移两小周期</span><br>df[<span class="hljs-string">"Hu0_-2period"</span>] = df[<span class="hljs-string">'Hu_0'</span>].shift(<span class="hljs-number">2</span>*<span class="hljs-number">77</span>)<br><span class="hljs-comment"># 偏移1天，一大周期</span><br>df[<span class="hljs-string">"Hu0_-1day"</span>] = df[<span class="hljs-string">'Hu_0'</span>].shift(<span class="hljs-number">1</span>*<span class="hljs-number">1440</span>)<br>decompose_result = seasonal_decompose(df[<span class="hljs-string">'Hu_0'</span>], model=<span class="hljs-string">"additive"</span>, period=<span class="hljs-number">77</span>)<br><span class="hljs-comment"># 分离77周期分离</span><br>df[<span class="hljs-string">"Hu0_77seasonal"</span>] = decompose_result.seasonal<br>decompose_result = seasonal_decompose(decompose_result.seasonal, model=<span class="hljs-string">"additive"</span>, period=<span class="hljs-number">1440</span>)<br><span class="hljs-comment"># 分离1440周期分量</span><br>df[<span class="hljs-string">"Hu0_1440seasonal"</span>] = decompose_result.seasonal<br><span class="hljs-comment"># 趋势分量</span><br>df[<span class="hljs-string">"Hu0_trend"</span>] = decompose_result.trend<br><span class="hljs-comment"># 残差分量</span><br>df[<span class="hljs-string">"Hu0_resid"</span>] = decompose_result.resid<br>df<br></code></pre></td></tr></tbody></table></figure><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202204/Characteristic-Engineering-of-Time-Series/%E6%97%B6%E5%BA%8F%E8%A7%84%E5%BE%8B%E7%89%B9%E5%BE%81.5n1vvk2y3d40.jpg" srcset="/img/loading.gif" lazyload alt="时序规律特征"></li><li><strong>从统计窗口提取特征</strong><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#sum() 值的总和</span><br><span class="hljs-comment">#mean() 均值</span><br><span class="hljs-comment">#median() 值的算术中值</span><br><span class="hljs-comment">#min() 最小值</span><br><span class="hljs-comment">#max() 最大</span><br><span class="hljs-comment">#std() 贝塞尔修正样本标准差(均方差)</span><br><span class="hljs-comment">#var() 无偏方差</span><br><span class="hljs-comment">#cov() 无偏协方差（二元）</span><br><span class="hljs-comment">#corr() 相关（二进制）</span><br><span class="hljs-comment">#variation_v = std_v/mean_v 离散系数</span><br><span class="hljs-comment">#polyfit 线性拟合，求斜率</span><br><br><span class="hljs-comment">#使用rolling滚动窗口，窗口大小为7</span><br>roll_data = df[<span class="hljs-string">'Hu_0'</span>].rolling(window=<span class="hljs-number">7</span>)<br>df[<span class="hljs-string">"Hu0_mean"</span>] = roll_data.mean()<br>df[<span class="hljs-string">"Hu0_median"</span>] = roll_data.median()<br>df[<span class="hljs-string">"Hu0_min"</span>] = roll_data.<span class="hljs-built_in">min</span>()<br>df[<span class="hljs-string">"Hu0_max"</span>] = roll_data.<span class="hljs-built_in">max</span>()<br>df[<span class="hljs-string">"Hu0_std"</span>] = roll_data.std()<br>df[<span class="hljs-string">"Hu0_var"</span>] = roll_data.var()<br>df[<span class="hljs-string">"Hu0_cov"</span>] = roll_data.cov()<br>df[<span class="hljs-string">"Hu0_corr"</span>] = roll_data.corr()<br>df[<span class="hljs-string">"Hu0_variation"</span>] = df[<span class="hljs-string">"Hu0_std"</span>]/df[<span class="hljs-string">"Hu0_mean"</span>]<br>df[<span class="hljs-string">"Hu0_sum"</span>] = roll_data.<span class="hljs-built_in">sum</span>()<br>df[<span class="hljs-string">"Hu0_sum_diff2"</span>] = df[<span class="hljs-string">"Hu0_sum"</span>].shift(<span class="hljs-number">1</span>)-df[<span class="hljs-string">"Hu0_sum"</span>].shift(<span class="hljs-number">2</span>)<br><span class="hljs-comment">#df["Hu0_autocorr1"] = df["Hu_0"].autocorr(1)</span><br><span class="hljs-comment">#df["Hu0_autocorr2"] = df["Hu_0"].autocorr(2)</span><br>x = <span class="hljs-built_in">range</span>(<span class="hljs-number">7</span>)<br>z = <span class="hljs-keyword">lambda</span> y : np.polyfit(x, y, <span class="hljs-number">1</span>)[<span class="hljs-number">0</span>]<br>df[<span class="hljs-string">"Hu0_polyfit"</span>] = roll_data.apply(z)<br><span class="hljs-comment">#一阶差分的均方差</span><br>roll_data_diff = df[<span class="hljs-string">'Hu_0'</span>].diff(<span class="hljs-number">1</span>).rolling(window=<span class="hljs-number">7</span>)<br>df[<span class="hljs-string">"Hu0_diff_std"</span>] = roll_data_diff.std()<br>df<br></code></pre></td></tr></tbody></table></figure><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202204/Characteristic-Engineering-of-Time-Series/%E7%BB%9F%E8%AE%A1%E7%89%B9%E5%BE%81.6ahmg2mw8s00.jpg" srcset="/img/loading.gif" lazyload alt="统计特征"></li><li><strong>利用tsfresh工具提取特征</strong><br>先将原序列转换为n个窗口子序列。原表one_data结构为：<br><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202204/Characteristic-Engineering-of-Time-Series/%E6%BB%9A%E5%8A%A8%E7%AA%97%E5%8F%A3%E5%8E%9F%E8%A1%A8%E7%BB%93%E6%9E%84.119hmuad0jy8.jpg" srcset="/img/loading.gif" lazyload alt="滚动窗口原表结构"><br>其中id,time列是在原表的基础上后加上的，目的是为了方便使用API接口函数。id代表组别，time代表时间顺序。然后使用API转换为窗口子序列。<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> tsfresh.utilities.dataframe_functions <span class="hljs-keyword">import</span> roll_time_series<br><span class="hljs-comment"># 滚动窗口</span><br><span class="hljs-comment">#max_timeshift:最大偏移量，min_timeshift：最小偏移量，rolling_direction：每次移动的大小和方向。column_sort按什么排序，默认已从小到大排好</span><br>df_rolled = roll_time_series(one_data, column_id=<span class="hljs-string">"id"</span>, column_sort=<span class="hljs-string">"time"</span>,max_timeshift = <span class="hljs-number">6</span> ,min_timeshift = <span class="hljs-number">6</span>,rolling_direction=-<span class="hljs-number">1</span>)<br>df_rolled<br></code></pre></td></tr></tbody></table></figure><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/202204/Characteristic-Engineering-of-Time-Series/tsfresh%E7%AA%97%E5%8F%A3%E5%BA%8F%E5%88%97.4f2dy005fr40.jpg" srcset="/img/loading.gif" lazyload alt="tsfresh窗口序列"><br>转化后的id是原id与原时间的组合，也为后面特征提取中的组别。（1，1）代表1号组别的第一个时间点组成的子序列，（1，43316）代表1号组别第43316个点组成的子序列。然后再进行特征提取.</li></ol><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> tsfresh <span class="hljs-keyword">import</span> extract_features<br><span class="hljs-comment"># 特征提取,使用drop先删去多余的列，column_id为组别</span><br>df_features = extract_features(df_rolled.drop([<span class="hljs-string">"date"</span>,<span class="hljs-string">"time"</span>],axis = <span class="hljs-number">1</span>), column_id=<span class="hljs-string">"id"</span>)<br>df_features<br></code></pre></td></tr></tbody></table></figure><h3 id="2-3-2-特征预处理"><a href="#2-3-2-特征预处理" class="headerlink" title="2.3.2 特征预处理"></a>2.3.2 特征预处理</h3><p>首先处理表中的空值，因为前面窗口大小选为7，所以需要把表df（前面没有划分子窗口的表）的前六行删去，与df_features表的大小保持一致。df_features表中存在大量的空值，需要先将含空值的列删去。然后将df_features的索引设为df的索引，之后会利用concat函数将两表合并。又df表中，因为提取时序规律的特征中，头和尾存在许多空值，需要将其删除，然后取删除后的时间区段，选取df_features表的对应时间段。最后使用concat函数合并两表。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#删除前6行</span><br>df = df.iloc[<span class="hljs-number">6</span>:,:]<br><span class="hljs-comment"># 删除有空值的列</span><br>df_features = df_features.dropna(axis=<span class="hljs-number">1</span>)<br><span class="hljs-comment">#设置索引</span><br>df_features.index = df.index<br><span class="hljs-comment">#删除空值行，此时查看表可以得到时间段</span><br>df = df.dropna(axis=<span class="hljs-number">0</span>)<br><span class="hljs-comment">#合并两表</span><br>df_concat = pd.concat([df,df_features[<span class="hljs-string">'2022-01-26 13:12:00'</span>:<span class="hljs-string">'2022-02-24 03:13:00'</span>]] , axis = <span class="hljs-number">1</span>)<br>df_concat<br></code></pre></td></tr></tbody></table></figure><p>然后需要对特征无量纲化。使用标准化。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<br>scaler = StandardScaler()<br><span class="hljs-comment">#因为上式返回结果为series，这里将其转换为表格形式。</span><br>df_Standar = pd.DataFrame(scaler.fit_transform(df_concat),index=df_concat.index, columns=df_concat.columns)<br>df_Standar<br></code></pre></td></tr></tbody></table></figure><h3 id="2-3-3-特征降维"><a href="#2-3-3-特征降维" class="headerlink" title="2.3.3 特征降维"></a>2.3.3 特征降维</h3><p>使用过滤法，利用方差和相关系数过滤特征。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 特征过滤 filter</span><br><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> VarianceThreshold  <br>X_train_columns = df_Standar.columns<br><span class="hljs-comment">#方差过滤，返回方差大于设定阈值的列</span><br>selector = VarianceThreshold(<span class="hljs-number">0.5</span>)<br>X = selector.fit_transform(df_Standar)<br><span class="hljs-comment">#因为上式返回结果为series，这里将其转换为表格形式。</span><br><span class="hljs-comment">#X_train_columns[selector.get_support(indices=True)]结果为筛选后的列名</span><br>df_filter = pd.DataFrame(X,index=df_concat.index, columns=X_train_columns[selector.get_support(indices=<span class="hljs-literal">True</span>)])<br>df_filter<br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 特征过滤 相关系数corr</span><br><span class="hljs-comment"># 剔除相关性系数高于threshold的corr_drop</span><br>corr_df = df_filter.corr()<br>threshold = <span class="hljs-number">0.9</span><br><span class="hljs-comment">#k=1,返回上三角矩阵</span><br>upper = corr_df.where(np.triu(np.ones(corr_df.shape), k=<span class="hljs-number">1</span>).astype(np.<span class="hljs-built_in">bool</span>))<br><span class="hljs-comment">#返回相关系数大于阈值的列名</span><br>corr_drop = [column <span class="hljs-keyword">for</span> column <span class="hljs-keyword">in</span> upper.columns <span class="hljs-keyword">if</span> <span class="hljs-built_in">any</span>(upper[column].<span class="hljs-built_in">abs</span>() &gt; threshold)]<br>df_filter = df_filter.drop(corr_drop,axis=<span class="hljs-number">1</span>)<br>df_filter<br></code></pre></td></tr></tbody></table></figure></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="category-chain-item">机器学习</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE/">#时序数据</a> <a href="/tags/%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/">#异常处理</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">#机器学习</a></div></div><div class="license-box my-3"><div class="license-title"><div>时序数据异常检测流程与项目实战</div><div>https://haochendaily.com/anomaly-detection-process.html</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>laser</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2022年3月25日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/centos7-an-zhuang-qt-ji-huan-jing-pei-zhi.html" title="centos7安装QT及环境配置"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">centos7安装QT及环境配置</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/compilation-process.html" title="c/c++编译流程"><span class="hidden-mobile">c/c++编译流程</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article id="comments" lazyload><div id="valine"></div><script type="text/javascript">Fluid.utils.loadComments("#valine",(function(){Fluid.utils.createScript("https://lib.baomitu.com/valine/1.4.17/Valine.min.js",(function(){var i=Object.assign({appId:"TSl5PlExO22wiwkA3e15kGvM-gzGzoHsz",appKey:"36AERjunsq15rL0xcz3ovKbG",path:"window.location.pathname",placeholder:"尽情吐槽吧~",avatar:"retro",meta:["nick","mail","link"],requiredFields:[],pageSize:10,lang:"zh-CN",highlight:!1,recordIP:!1,serverURLs:"",emojiCDN:null,emojiMaps:null,enableQQ:!1},{el:"#valine",path:window.location.pathname});new Valine(i),Fluid.utils.waitElementVisible("#valine .vcontent",()=>{var i="#valine .vcontent img:not(.vemoji)";Fluid.plugins.imageCaption(i),Fluid.plugins.fancyBox(i)})}))}))</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var o=jQuery("#board-ctn").offset().top;window.tocbot.init({tocSelector:"#toc-body",contentSelector:".markdown-body",headingSelector:CONFIG.toc.headingSelector||"h1,h2,h3,h4,h5,h6",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",collapseDepth:CONFIG.toc.collapseDepth||0,scrollSmooth:!0,headingsOffset:-o}),t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var o=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),n=[];for(var i of o)n.push(".markdown-body > "+i.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(n.join(", "))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script src="/js/local-search.js"></script><script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript></body></html>