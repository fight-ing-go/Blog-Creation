<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>home-laser</title>
  
  
  <link href="https://easyboy-blog.com/atom.xml" rel="self"/>
  
  <link href="https://easyboy-blog.com/"/>
  <updated>2022-04-14T16:00:00.000Z</updated>
  <id>https://easyboy-blog.com/</id>
  
  <author>
    <name>laser</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>时序数据异常检测流程与项目实战</title>
    <link href="https://easyboy-blog.com/anomaly-detection-process.html"/>
    <id>https://easyboy-blog.com/anomaly-detection-process.html</id>
    <published>2022-03-25T12:23:25.727Z</published>
    <updated>2022-04-14T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要内容为对时序数据异常检测流程进行简单介绍，然后通过项目实战进行详细解释。全文内容根据个人实际经验所得。</p><h1 id="1-总体流程介绍"><a href="#1-总体流程介绍" class="headerlink" title="1.总体流程介绍"></a>1.总体流程介绍</h1><p>针对项目中传感器数据异常检测，经调研后，个人初步总结工程上实现异常检测的流程。流程框图如下图所示：<br> <span id="more"></span>  </p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Anomaly_detection_process.6l6blsl243s0.jpg" width="60%/"></div>  <p>总体步骤有五步：  </p><ol><li>数据清洗：对数据做初步处理，方便后续的数据分析。包括时间戳的转换（因为是时序数据，需要对时间列做专门处理）、数据重采样（修改时间频率）、缺失值处理、异常值处理、数据平滑处理</li><li>探索性数据分析EDA：通过作图、制表、方程拟合、计算特征量等手段探索数据的结构和规律的一种数据分析方法。主要是利用各种方式自由探索数据分布、数据相关性等。</li><li>特征提取/相关性分析：对于单维序列，因为缺乏可用特征，需要进行特征提取，以便后续训练模型，时序序列中比较重要的特征是周比环比。对于多维序列，需要先进行相关性分析，剔除相关性强的数据。</li><li>训练模型：对数据分析后选择合适的算法进行建模，用提取出的特征或若相关数据进行模型训练。</li><li>异常检测：利用训练好的模型检测实际数据。单维常用算法有LSTM + Vae，通过预测的方式检测异常；多维可利用孤立森林、SVM、kmeans等。</li></ol><h1 id="2-项目实战"><a href="#2-项目实战" class="headerlink" title="2.项目实战"></a>2.项目实战</h1><p>利用工具：jupyter notebook; 语言：python</p><h2 id="2-1-数据清洗"><a href="#2-1-数据清洗" class="headerlink" title="2.1 数据清洗"></a>2.1 数据清洗</h2><p>实现目标：提取csv文件数据，处理缺失值、异常值、数据平滑化，完成数据清洗。<br>首先加载必要库:</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np <span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd <span class="token keyword">import</span> random <span class="token keyword">as</span> rd <span class="token keyword">import</span> datetime <span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt <span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>dates <span class="token keyword">as</span> mdate<span class="token keyword">from</span> statsmodels<span class="token punctuation">.</span>tsa<span class="token punctuation">.</span>seasonal <span class="token keyword">import</span> seasonal_decompose<span class="token keyword">from</span> statsmodels<span class="token punctuation">.</span>graphics<span class="token punctuation">.</span>tsaplots <span class="token keyword">import</span> plot_acf<span class="token keyword">from</span> statsmodels<span class="token punctuation">.</span>graphics<span class="token punctuation">.</span>tsaplots <span class="token keyword">import</span> plot_pacf<span class="token keyword">import</span> seaborn <span class="token keyword">as</span> sns<span class="token keyword">from</span> statsmodels<span class="token punctuation">.</span>tsa<span class="token punctuation">.</span>stattools <span class="token keyword">import</span> adfuller<span class="token keyword">from</span> scipy <span class="token keyword">import</span> signal<span class="token keyword">import</span> warningswarnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">"ignore"</span><span class="token punctuation">)</span></code></pre><p>提取csv文件,利用pd.read_csv()函数可完整提取表中全部内容，函数有很多参数可以选择，实现众多功能</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#读取表格数据</span>data1 <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./data/componet.csv'</span><span class="token punctuation">)</span>data2 <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./data/tehu.csv'</span><span class="token punctuation">)</span>data1 <span class="token comment" spellcheck="true">#展示data1中数据</span></code></pre><p>表格数据如图所示：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet.4mjopka34v80.jpg" width="60%/"></div>  <p>查询表中是否有缺失值，使用.isnull()查询，返回含有缺失值的行。我的数据没有缺失值，表为空，就不展示了。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 查看缺失值</span>pivot_data<span class="token punctuation">[</span>pivot_data<span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T<span class="token punctuation">.</span>any<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span></code></pre><p>将data1中时间列数据设置为索引，方便查询，也方便可视化</p><pre class=" language-python"><code class="language-python">data1<span class="token punctuation">.</span>index <span class="token operator">=</span> pd<span class="token punctuation">.</span>to_datetime<span class="token punctuation">(</span>data1<span class="token punctuation">.</span>Datetime<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#设置时间列为索引</span>data1</code></pre><p>设置完后数据：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_index.78rh4tnfar00.jpg" width="60%/"></div>  <p>先对未处理的数据进行可视化，看看数据形态：</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#可视化</span><span class="token keyword">for</span> c_disc <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'Comp0_Te'</span><span class="token punctuation">,</span><span class="token string">'Comp1_Te'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    t_disc <span class="token operator">=</span> tmp_data1<span class="token punctuation">[</span>c_disc<span class="token punctuation">]</span>    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>c_disc<span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span>c_disc<span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>gca<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>xaxis<span class="token punctuation">.</span>set_major_formatter<span class="token punctuation">(</span>mdate<span class="token punctuation">.</span>DateFormatter<span class="token punctuation">(</span><span class="token string">'%Y-%m-%d'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#设置x轴显示格式</span>    <span class="token comment" spellcheck="true">#设置x轴显示范围，freq代表间隔频率，tmp_data1.index[0]代表起始时间,tmp_data1.index[-1]代表结束时间</span>    plt<span class="token punctuation">.</span>xticks<span class="token punctuation">(</span>pd<span class="token punctuation">.</span>date_range<span class="token punctuation">(</span>tmp_data1<span class="token punctuation">.</span>index<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>tmp_data1<span class="token punctuation">.</span>index<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>freq<span class="token operator">=</span><span class="token string">'D'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>rotation<span class="token operator">=</span><span class="token number">45</span><span class="token punctuation">)</span>     plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>t_disc<span class="token punctuation">)</span></code></pre><p>其中一个曲线示意图：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_plot.4833uxky2zg0.jpg" width="100%/"></div> <p>可以看出，数据有明显的异常点，要么很大，要么很小。为了后面的数据分析与模型训练，我们所以需要对这些明显的异常点进行简单处理。处理方式为使用箱型图，筛选出异常点，然后用前值进行替换。 在此之前，我们先对时间索引进行处理。在这里，我的数据采样间隔大致为2s，但并不固定。因此，在尽可能不影响原数据的情况下，将重采样间隔设置为2S，只做规范时间频率使用。使用resample()函数处理。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#重采样 </span>tmp_data1 <span class="token operator">=</span> data1<span class="token punctuation">.</span>resample<span class="token punctuation">(</span><span class="token string">'2S'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#时间间隔取2S，mean()取平均值,用tmp_data1接收转换后的表，不改变原表内容</span>tmp_data1</code></pre><p>重采样后的数据：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_resample.tfaifs2cgrk.jpg" width="100%/"></div>  <p>可以看出，数据时间间隔已变为2S等距，且值也有所变化，因为非等距时间间隔，不可避免地出现了缺失值。因此下一步对缺失值进行<strong>填补</strong>。填补策略为：对短时间缺失数据填补，长时间缺失数据删除。填补使用缺失点前7个历史数据的均值填补，以是否连续缺失十个点判断是否是长时间缺失数据。这里自己写了个填补函数用于实现上面的功能。（对于几百万的数据量，填补时间很长，有一两小时）</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">nmeans_fill_missing</span><span class="token punctuation">(</span>fill_col<span class="token punctuation">,</span> df <span class="token punctuation">,</span> window<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> time_range <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">'''        实现功能： 对表格中的某一列的缺失值进行填补，使用邻近历史数据的均值填补，对于大范围缺失点，不进行填补，可对均值窗口、缺失时间范围进行设置        fill_col: 选择插值的列，可填名字，也可填index        df: DataFrame,输入需要插值的表        window: 插值窗口大小        time_range: 设置判断长时间间隔的点数        '''</span>        <span class="token comment" spellcheck="true"># count记录起始位置，每当遇到长间隔空值点，会将count移动到下一个非空值点</span>        count <span class="token operator">=</span> <span class="token number">0</span>        i<span class="token operator">=</span><span class="token number">0</span>        <span class="token keyword">while</span> i <span class="token operator">&lt;</span> len<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># count += 1</span>            value <span class="token operator">=</span> np<span class="token punctuation">.</span>isnan<span class="token punctuation">(</span>df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">#判断当前值是否为空</span>            <span class="token keyword">if</span> value <span class="token operator">==</span> <span class="token boolean">True</span><span class="token punctuation">:</span>                <span class="token comment" spellcheck="true"># 判断当前空值点是否是长间隔</span>                islonginterval <span class="token operator">=</span> islong_missing<span class="token punctuation">(</span>fill_col<span class="token punctuation">,</span> df <span class="token punctuation">,</span> range_window<span class="token operator">=</span>time_range<span class="token punctuation">,</span> row_index<span class="token operator">=</span>i<span class="token punctuation">)</span>                <span class="token comment" spellcheck="true">#当遇到长间隔空值时，将count一直移动到下一个非空点</span>                <span class="token keyword">if</span> islonginterval<span class="token punctuation">:</span>                    i <span class="token operator">+=</span> time_range                    <span class="token keyword">while</span> value <span class="token operator">==</span><span class="token boolean">True</span> <span class="token operator">and</span> i<span class="token operator">&lt;</span>len<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">:</span>                        value <span class="token operator">=</span> np<span class="token punctuation">.</span>isnan<span class="token punctuation">(</span>df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>                        i <span class="token operator">+=</span><span class="token number">1</span>                    count <span class="token operator">=</span> i                   <span class="token keyword">else</span><span class="token punctuation">:</span>                      <span class="token keyword">if</span> i <span class="token operator">-</span> count <span class="token operator">&lt;=</span> window<span class="token punctuation">:</span>         <span class="token comment" spellcheck="true">#判断当前位置是否有足够历史数据进行插值</span>                        <span class="token keyword">if</span> i<span class="token operator">+</span>window<span class="token operator">>=</span>len<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token comment" spellcheck="true">#如果已经到了表格末尾，后续数据不够进行填补，直接略过剩下的点。该策略仅针对数据量足够大的情况</span>                            <span class="token keyword">break</span>                        train_value_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>   <span class="token comment" spellcheck="true">#用于当历史数据不够的情况存放窗口内的点，如 [1,2,3,current:NAN,5,6,7]  此时历史数据不够，则取从1开始的7个点，掠过略过空值</span>                        <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>window<span class="token punctuation">)</span><span class="token punctuation">:</span>                            train_value <span class="token operator">=</span> np<span class="token punctuation">.</span>isnan<span class="token punctuation">(</span>df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>j<span class="token operator">+</span>count<span class="token punctuation">]</span><span class="token punctuation">)</span>                             <span class="token keyword">if</span> train_value <span class="token operator">==</span> <span class="token boolean">False</span><span class="token punctuation">:</span>                                train_value_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>j<span class="token operator">+</span>count<span class="token punctuation">]</span><span class="token punctuation">)</span>                        df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>train_value_list<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>                    <span class="token keyword">else</span><span class="token punctuation">:</span>                        df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">[</span>i <span class="token operator">-</span> window<span class="token punctuation">:</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#如果窗口大小满足，取前window内的均值填补</span>            i <span class="token operator">+=</span><span class="token number">1</span>        <span class="token keyword">return</span> df<span class="token comment" spellcheck="true"># 判断当前空值点是否是长间隔</span><span class="token keyword">def</span> <span class="token function">islong_missing</span><span class="token punctuation">(</span>fill_col<span class="token punctuation">,</span> df <span class="token punctuation">,</span> range_window<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> row_index<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">'''        判断当前空值点是否是长间隔        df: DataFrame,输入需要插值的表          window:插值窗口大小        range_window: 设置判断长时间间隔的点数        fill_col: 选择插值的列,可填名字.也可填index        row_index: 开始判断的起始索引        '''</span>        islonginterval <span class="token operator">=</span> <span class="token boolean">True</span>    <span class="token comment" spellcheck="true">#判断当前空值是否属于长时间范围内的空值，是的话就跳过，不进行插值填补</span>        count <span class="token operator">=</span> <span class="token number">1</span>        <span class="token comment" spellcheck="true"># 判断逻辑：判断后续十个时间点是否为空，当存在一个非空点，即跳出循环，且islonginterval为false</span>        <span class="token keyword">while</span> row_index<span class="token operator">+</span>count<span class="token operator">&lt;</span>len<span class="token punctuation">(</span>df<span class="token punctuation">)</span> <span class="token operator">and</span> islonginterval<span class="token operator">==</span><span class="token boolean">True</span> <span class="token operator">and</span> count<span class="token operator">&lt;=</span>range_window<span class="token punctuation">:</span>            islonginterval <span class="token operator">=</span> np<span class="token punctuation">.</span>isnan<span class="token punctuation">(</span>df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>row_index<span class="token operator">+</span>count<span class="token punctuation">]</span><span class="token punctuation">)</span>            count <span class="token operator">+=</span><span class="token number">1</span>        <span class="token keyword">return</span> islonginterval<span class="token comment" spellcheck="true">#对两列分别填补</span><span class="token keyword">for</span> c_disc <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'Comp0_Te'</span><span class="token punctuation">,</span><span class="token string">'Comp1_Te'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    tmp_data1 <span class="token operator">=</span> nmeans_fill_missing<span class="token punctuation">(</span>c_disc<span class="token punctuation">,</span> tmp_data1<span class="token punctuation">,</span> window<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">)</span>tmp_data1</code></pre><p>为了检验填补效果，又写了个子函数，用来获取每次检测到的长间隔时间端的开始时间和结束时间对于的行数。根据返回的结果，查询对应的时间信息，判断是否满足填补策略</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">find_long_missing</span><span class="token punctuation">(</span>fill_col<span class="token punctuation">,</span> df <span class="token punctuation">,</span> time_range <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">'''        实现功能： 获取长间隔断点的点信息，返回dot_list数组，每两个为一对时间段        fill_col: 选择插值的列，可填名字，也可填index        df: DataFrame,输入需要插值的表        time_range: 设置判断长时间间隔的点数        '''</span>        <span class="token comment" spellcheck="true"># count记录起始位置，每当遇到长间隔空值点，会将count移动到下一个非空值点</span>        i<span class="token operator">=</span><span class="token number">0</span>        dot_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">while</span> i <span class="token operator">&lt;</span> len<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">:</span>            value <span class="token operator">=</span> np<span class="token punctuation">.</span>isnan<span class="token punctuation">(</span>df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">#判断当前值是否为空</span>            <span class="token keyword">if</span> value <span class="token operator">==</span> <span class="token boolean">True</span><span class="token punctuation">:</span>                <span class="token comment" spellcheck="true"># 判断当前空值点是否是长间隔</span>                islonginterval <span class="token operator">=</span> islong_missing<span class="token punctuation">(</span>fill_col<span class="token punctuation">,</span> df <span class="token punctuation">,</span> range_window<span class="token operator">=</span>time_range<span class="token punctuation">,</span> row_index<span class="token operator">=</span>i<span class="token punctuation">)</span>                <span class="token comment" spellcheck="true">#当遇到长间隔空值时，将count一直移动到下一个非空点</span>                <span class="token keyword">if</span> islonginterval<span class="token punctuation">:</span>                    dot_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>                    i <span class="token operator">+=</span> <span class="token punctuation">(</span>time_range<span class="token number">-1</span><span class="token punctuation">)</span>                    <span class="token keyword">while</span> value <span class="token operator">==</span><span class="token boolean">True</span> <span class="token operator">and</span> i<span class="token operator">&lt;</span>len<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">:</span>                        i <span class="token operator">+=</span><span class="token number">1</span>                        value <span class="token operator">=</span> np<span class="token punctuation">.</span>isnan<span class="token punctuation">(</span>df<span class="token punctuation">[</span>fill_col<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>                                            dot_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>               i <span class="token operator">+=</span><span class="token number">1</span>        <span class="token keyword">return</span> dot_list</code></pre><p>然后删除缺失值并导出。使用reset_index()是为了让时间索引一起导出来。这里用的导出方法缺点是索引需要自己手动加上去。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#删除缺失值</span>tmp_data1 <span class="token operator">=</span> tmp_data1<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> how <span class="token operator">=</span> <span class="token string">'all'</span><span class="token punctuation">,</span>inplace <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#避免之后重新填补，导出经插值，删除空值后的表</span>path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>abspath<span class="token punctuation">(</span>r<span class="token string">'./data/l1_tehu'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 文件夹路径</span>new_file_name <span class="token operator">=</span> <span class="token string">'tmp_data1_insert.csv'</span>tmp_data1<span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span>path <span class="token operator">+</span> <span class="token string">'/'</span> <span class="token operator">+</span> new_file_name<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'a'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'gbk'</span><span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></code></pre><p>下面对前面的<strong>异常值</strong>进行处理。这里只选取其中一个片段进行示范。</p><pre class=" language-python"><code class="language-python">twoday_data <span class="token operator">=</span> tmp_data1<span class="token punctuation">[</span><span class="token string">'2021-11-01 18:58:30'</span><span class="token punctuation">:</span> <span class="token string">'2021-11-03 11:35:00'</span><span class="token punctuation">]</span>twoday_data<span class="token punctuation">.</span>describe<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#描述表的一些信息</span></code></pre><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_twoday_describe.3qyix6pukji0.jpg" width="40%/"></div>  <p>画出箱线图，可以看出存在的一些异常点：</p><pre class=" language-python"><code class="language-python">plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>boxplot<span class="token punctuation">(</span>twoday_data<span class="token punctuation">[</span><span class="token string">'Comp0_Te'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>boxplot<span class="token punctuation">(</span>twoday_data<span class="token punctuation">[</span><span class="token string">'Comp1_Te'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_twoday_boxplot.705wl11k1jo0.jpg" width="60%/"></div>  <p>然后利用四分位，删除异常值并用前值进行填补。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 超过了上四分位2倍四分位距或下四分位2倍距离都算异常值，用上一个值填充</span>a <span class="token operator">=</span> twoday_data<span class="token punctuation">[</span><span class="token string">'Comp0_Te'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>quantile<span class="token punctuation">(</span><span class="token number">0.75</span><span class="token punctuation">)</span>b <span class="token operator">=</span> twoday_data<span class="token punctuation">[</span><span class="token string">'Comp0_Te'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>quantile<span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">)</span>c <span class="token operator">=</span> twoday_data<span class="token punctuation">[</span><span class="token string">'Comp0_Te'</span><span class="token punctuation">]</span>c<span class="token punctuation">[</span><span class="token punctuation">(</span>c<span class="token operator">>=</span><span class="token punctuation">(</span>a<span class="token operator">-</span>b<span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">2</span><span class="token operator">+</span>a<span class="token punctuation">)</span><span class="token operator">|</span><span class="token punctuation">(</span>c<span class="token operator">&lt;=</span>b<span class="token operator">-</span><span class="token punctuation">(</span>a<span class="token operator">-</span>b<span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token operator">=</span>np<span class="token punctuation">.</span>nanc<span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>method<span class="token operator">=</span><span class="token string">'pad'</span><span class="token punctuation">,</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>twoday_data<span class="token punctuation">[</span><span class="token string">'Comp0_Te'</span><span class="token punctuation">]</span> <span class="token operator">=</span> c<span class="token keyword">print</span><span class="token punctuation">(</span>twoday_data<span class="token punctuation">[</span><span class="token string">'Comp0_Te'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>describe<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/componet_twoday_boxplot_new.44m969zxzbg0.jpg" width="60%/"></div>  <p>异常值处理完后，还有数据平滑处理。平滑处理在第二张表中演示。下面处理第二张表的数据。同样的操作，先将时间列设为索引，展示data2中数据：</p><pre class=" language-python"><code class="language-python">data2<span class="token punctuation">.</span>index <span class="token operator">=</span> pd<span class="token punctuation">.</span>to_datetime<span class="token punctuation">(</span>data2<span class="token punctuation">.</span>Datetime<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#设置时间列为索引</span>data2</code></pre><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/L1_id_data.6dh59h41kq40.jpg" width="40%/"></div>   <p>表中有个ID列，表示各个传感器的型号，做数据分析时，可以将ID列提取出来，作为列索引，方便观察。因此，先对表格进行<strong>透视</strong>：</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#数据透视</span><span class="token comment" spellcheck="true">#tmp_data2用来拷贝data2数据变为二重索引表，原表数据保留 </span>tmp_data2<span class="token operator">=</span>data2   tmp_data2<span class="token punctuation">[</span><span class="token string">'L1_id'</span><span class="token punctuation">]</span> <span class="token operator">=</span> tmp_data2<span class="token punctuation">[</span><span class="token string">'L1_id'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>str<span class="token punctuation">)</span>tmp_data2<span class="token operator">=</span>data2<span class="token punctuation">.</span>pivot_table<span class="token punctuation">(</span>index<span class="token operator">=</span><span class="token string">'Datetime'</span><span class="token punctuation">,</span>columns<span class="token operator">=</span><span class="token string">'L1_id'</span><span class="token punctuation">)</span>tmp_data2</code></pre><p>透视结果如下所示：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/L1_id_pivot.2ab6wthn3ack.jpg" width="100%/"></div>  <p>表格的列变成了二重索引，为了方便后续引用，将其变为一重索引。需要注意的是，这种变换需要数据类型都为string型，如果不是，需要提前转换。当然，还有一种手动方法，变为二重索引后导出表，将原列索引删除，自己再加上索引就好。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#改为一重列索引表，用one_class_data2表示</span>one_class_data2 <span class="token operator">=</span>tmp_data2<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>deep<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#拷贝表格</span>one_class_data2<span class="token punctuation">.</span>columns <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"_"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> one_class_data2<span class="token punctuation">.</span>columns<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true">#将原来的二重索引的列名进行拼接</span><span class="token comment" spellcheck="true"># one_class_data2.columns = tmp_data2.columns.droplevel(0)  #这个方法是直接将外围第二重索引去掉，只取第一重列索引。</span>one_class_data2</code></pre><p>结果如下：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/L1_id_oneclass.59gip30dtvk0.jpg" width="100%/"></div>  <p>可以看到，列已经变为一重，列名为二重列名拼接而成。后续步骤与第一张表一样，这里不再做解释。最后再对其进行<strong>平滑处理</strong>。平滑方式选用传统的<em>巴特沃斯</em> 低通滤波器。对于参数wn的确定，首先采样频率定为1=采样长度/采样时间（其实采样频率可以自己定，其他的频率以采样频率为基准进行计算即可，结果都一样）。截止频率需要根据实际的来，我的数据中最大的频率差不多以77个点为一个周期，所以稍微扩大下范围后计算截止频率 = 1/60（采样频率为1，那么采样时间即为周期T=1）。根据公式wn = 2*截止频率/采样频率 = 0.033。以两天的数据量为例。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 低通滤波器-巴特沃斯</span><span class="token comment" spellcheck="true"># wn=2*截至频率/采样频率   如果一天采样10个点，采样频率为10，截止频率为想要滤除的频率上限或下限</span><span class="token comment" spellcheck="true"># pivot_data为透视后清理完的表</span>twoday_data <span class="token operator">=</span> pivot_data<span class="token punctuation">[</span><span class="token string">'2022-01-26 00:00:00'</span><span class="token punctuation">:</span><span class="token string">'2022-01-28 00:00:00'</span><span class="token punctuation">]</span>b<span class="token punctuation">,</span> a <span class="token operator">=</span> signal<span class="token punctuation">.</span>butter<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">0.033</span><span class="token punctuation">,</span> <span class="token string">'lowpass'</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#配置滤波器 8 表示滤波器的阶数</span>twoday_data<span class="token punctuation">[</span><span class="token string">'Te_0_filter'</span><span class="token punctuation">]</span> <span class="token operator">=</span> signal<span class="token punctuation">.</span>filtfilt<span class="token punctuation">(</span>b<span class="token punctuation">,</span> a<span class="token punctuation">,</span> twoday_data<span class="token punctuation">[</span><span class="token string">'Te_0'</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><p>滤波结果如下：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/butter.6leaq5g4j7s0.jpg" width="50%/"></div>  <h2 id="2-2-探索性数据分析EDA"><a href="#2-2-探索性数据分析EDA" class="headerlink" title="2.2 探索性数据分析EDA"></a>2.2 探索性数据分析EDA</h2><p>首先进行相关性分析。这里以表data2为例。分析的数据取较完整地一个月的时间片段，重采样为1min适当减小数据量。（记得导入表后先设置时间索引）</p><pre class=" language-python"><code class="language-python">Month_data2 <span class="token operator">=</span> data2<span class="token punctuation">[</span><span class="token string">'2022-01-25 13:12:30'</span><span class="token punctuation">:</span><span class="token string">'2022-02-24 15:13:00'</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true"># 重采样一分钟(一个月数据)</span>Month_data2_1T <span class="token operator">=</span> Month_data2<span class="token punctuation">.</span>resample<span class="token punctuation">(</span><span class="token string">'T'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>Month_data2_1T<span class="token operator">=</span>Month_data2_1T<span class="token punctuation">.</span>round<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#保留两位小数。</span><span class="token comment" spellcheck="true"># 相关系数</span>Month_data2_1T<span class="token punctuation">.</span>corr<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>这里仅展示部分结果图：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data2_1T_corr.5gurkritpvs0.jpg" width="50%/"></div>  <p>可以看到，每个变量间的相关程度都很高，不利用互相作为特征值。<br>对数据的自相关性和偏相关性进行分析。自相关：描述的是一组时间序列和它前面间隔n个时刻的一组时间序列之前的相关性。偏自相关：描述的是一组时间序列和它前面间隔n个时刻的一组时间序列之前的偏相关性。这里的偏相关性可以从本质上理解为去除了样本之间的干涉，也就是更早时刻的相关性影响。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 自相关，偏自相关，列出每一列的相关图</span>col <span class="token operator">=</span> Month_data2_1T<span class="token punctuation">.</span>columns<span class="token keyword">for</span> c <span class="token keyword">in</span> col<span class="token punctuation">:</span>      fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    ax1 <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">121</span><span class="token punctuation">)</span>    ax1<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span>c<span class="token punctuation">)</span>    ax2 <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">122</span><span class="token punctuation">)</span>    ax2<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span>c<span class="token punctuation">)</span>    plot_acf<span class="token punctuation">(</span>Month_data2_1T<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span>lags<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span>ax <span class="token operator">=</span> ax1<span class="token punctuation">)</span>    plot_pacf<span class="token punctuation">(</span>Month_data2_1T<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span>lags<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span>ax <span class="token operator">=</span> ax2<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>同样的，展示部分结果图。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data2_1T_acf.3xqf5jmk4f80.jpg" width="60%/"></div>  <p>研究自相关、偏相关可用于判断是否适合使用时间预测方法,也可用于查看周期（下面会有演示）。该图可应用于LSTM算法，作为参数选择的依据。具体使用方法有待明确。<br>查看温湿度的统计分布。这里仅仅是查看下数据分布，目前没有对于其分析的一些想法。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 管道温湿度统计分布图</span><span class="token keyword">for</span> c <span class="token keyword">in</span> col<span class="token punctuation">:</span>     plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    sns<span class="token punctuation">.</span>distplot<span class="token punctuation">(</span>Month_data2_1T<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span> bins<span class="token operator">=</span>int<span class="token punctuation">(</span>np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>len<span class="token punctuation">(</span>Month_data2_1T<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>展示部分结果图。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data2_1T_distplot.462fv8dw1b00.jpg" width="60%/"></div>  <p>数据平稳性判断，使用单位根检验法。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">check_stationarity</span><span class="token punctuation">(</span>y<span class="token punctuation">,</span> lags_plots<span class="token operator">=</span><span class="token number">48</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">22</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token string">"Use Series as parameter"</span>    <span class="token comment" spellcheck="true"># Creating plots of the DF</span>    y <span class="token operator">=</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span>y<span class="token punctuation">)</span>    fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>    ax1 <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplot2grid<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> colspan<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>    ax2 <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplot2grid<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    ax3 <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplot2grid<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    ax4 <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplot2grid<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> colspan<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>    y<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>ax<span class="token operator">=</span>ax1<span class="token punctuation">,</span> figsize<span class="token operator">=</span>figsize<span class="token punctuation">)</span>    ax1<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'Nums Variation'</span><span class="token punctuation">)</span>    plot_acf<span class="token punctuation">(</span>y<span class="token punctuation">,</span> lags<span class="token operator">=</span>lags_plots<span class="token punctuation">,</span> zero<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> ax<span class="token operator">=</span>ax2<span class="token punctuation">)</span><span class="token punctuation">;</span>    plot_pacf<span class="token punctuation">(</span>y<span class="token punctuation">,</span> lags<span class="token operator">=</span>lags_plots<span class="token punctuation">,</span> zero<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> ax<span class="token operator">=</span>ax3<span class="token punctuation">)</span><span class="token punctuation">;</span>    sns<span class="token punctuation">.</span>distplot<span class="token punctuation">(</span>y<span class="token punctuation">,</span> bins<span class="token operator">=</span>int<span class="token punctuation">(</span>np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>len<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ax<span class="token operator">=</span>ax4<span class="token punctuation">)</span>    ax4<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'Distribution Chart'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># plt.show()</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Results of Dickey-Fuller Test:'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#  regression：{c”，“ct”，“ctt”，“n”}要包含在回归中的常数和趋势顺序。</span>    <span class="token comment" spellcheck="true"># “c”：仅限常量（默认值）。</span>    <span class="token comment" spellcheck="true"># “ct”：恒定和趋势。</span>    <span class="token comment" spellcheck="true"># “ctt”：常数、线性和二次趋势。</span>    <span class="token comment" spellcheck="true"># n：没有常数，没有趋势。</span>    <span class="token comment" spellcheck="true"># ADF的结果主要看以下两个方面：</span>    <span class="token comment" spellcheck="true"># Test Statistic的值如果比Critical Value (5%)小则满足稳定性需求.</span>    <span class="token comment" spellcheck="true"># p-value越低（理论上需要低于0.05）证明序列越稳定。</span>    adfinput <span class="token operator">=</span> adfuller<span class="token punctuation">(</span>y<span class="token punctuation">,</span>regression <span class="token operator">=</span> <span class="token string">'c'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#单位根检验</span>    adftest <span class="token operator">=</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span>adfinput<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Test Statistic'</span><span class="token punctuation">,</span><span class="token string">'p-value'</span><span class="token punctuation">,</span><span class="token string">'Lags Used'</span><span class="token punctuation">,</span><span class="token string">'Number of Observations Used'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    adftest <span class="token operator">=</span> round<span class="token punctuation">(</span>adftest<span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> key<span class="token punctuation">,</span> value <span class="token keyword">in</span> adfinput<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        adftest<span class="token punctuation">[</span><span class="token string">"Critical Value (%s)"</span><span class="token operator">%</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> value<span class="token punctuation">.</span>round<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>adftest<span class="token punctuation">)</span>        <span class="token keyword">if</span> adftest<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>round<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> adftest<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">.</span>round<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\nThe Test Statistics is lower than the Critical Value of 5%.\nThe serie seems to be stationary'</span><span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\nThe Test Statistics is higher than the Critical Value of 5%.\nThe serie isn't stationary"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 检验平稳性</span>check_stationarity<span class="token punctuation">(</span>Month_data2_1T<span class="token punctuation">[</span><span class="token string">'Te_0'</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><blockquote><p>输出结果为：<br><br>Results of Dickey-Fuller Test:<br><br>Test Statistic                    -1.4583<br><br>p-value                            0.5540<br><br>Lags Used                         55.0000<br><br>Number of Observations Used    43266.0000<br><br>Critical Value (1%)               -3.4305<br><br>Critical Value (5%)               -2.8616<br><br>Critical Value (10%)              -2.5668<br><br>dtype: float64<br><br><br><br>The Test Statistics is higher than the Critical Value of 5%.<br><br>The serie isn’t stationary  </p></blockquote><p>判断平稳性两个标准：Test Statistic小于Critical Value (5%)　或是p-value小于0.05。平稳性是多数统计学模型的必要条件之一。可见原数据并不是平稳序列。<br>对于非平稳序列，可使用一阶差分使其平稳化。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#序列平稳化，一阶差分</span>Month_data2_1T<span class="token punctuation">[</span><span class="token string">'Te_0_diff'</span><span class="token punctuation">]</span> <span class="token operator">=</span> Month_data2_1T<span class="token punctuation">[</span><span class="token string">'Te_0'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>diff<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span></code></pre><p>其稳定性结果为：</p><blockquote><p>Results of Dickey-Fuller Test:<br><br>Test Statistic                   -51.9122<br><br>p-value                            0.0000<br><br>Lags Used                         54.0000<br><br>Number of Observations Used    43267.0000<br><br>Critical Value (1%)               -3.4305<br><br>Critical Value (5%)               -2.8616<br><br>Critical Value (10%)              -2.5668<br><br>dtype: float64<br><br><br><br>The Test Statistics is lower than the Critical Value of 5%.<br><br>The serie seems to be stationary</p></blockquote><p>可见一阶差分可以有效是原序列平稳。后期可利用差分序列进行异常检测训练。<br>时间序列分解：所谓分解就是将时序数据分离成不同的成分，分解为：长期趋势Trend、季节性Seasonality和随机残差Residuals。分解序列后可针对每个子序列分别建模处理，如建模趋势后，在原数据中减去趋势的干扰。又或者当作特征值。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 管道温湿度时序序列分解：趋势+季节性+残差</span>col <span class="token operator">=</span> Month_data2_1T<span class="token punctuation">.</span>columns<span class="token keyword">for</span> c <span class="token keyword">in</span> col<span class="token punctuation">:</span>      <span class="token comment" spellcheck="true">#用加性模型，周期1440为1440min，分解数据时间频率为1min，一天为1440min。这里将一天设为周期，那么分解出的季节性数据以1天为周期</span>    decompose_result <span class="token operator">=</span> seasonal_decompose<span class="token punctuation">(</span>Month_data2_1T<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"additive"</span><span class="token punctuation">,</span> period<span class="token operator">=</span><span class="token number">1440</span><span class="token punctuation">)</span>    fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">18</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    ax1 <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">411</span><span class="token punctuation">)</span>    ax2 <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">412</span><span class="token punctuation">)</span>    ax3 <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">413</span><span class="token punctuation">)</span>    ax4 <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">414</span><span class="token punctuation">)</span>    ax1<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span>c<span class="token punctuation">)</span>    ax1<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'init'</span><span class="token punctuation">)</span>    ax2<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span>c<span class="token punctuation">)</span>    ax2<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'trend'</span><span class="token punctuation">)</span>    ax3<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span>c<span class="token punctuation">)</span>    ax3<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'seasonal'</span><span class="token punctuation">)</span>    ax4<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span>c<span class="token punctuation">)</span>    ax4<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'resid'</span><span class="token punctuation">)</span>    ax1<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>Month_data2_1T<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">)</span>    ax2<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>decompose_result<span class="token punctuation">.</span>trend<span class="token punctuation">)</span>    ax3<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>decompose_result<span class="token punctuation">.</span>seasonal<span class="token punctuation">)</span>    ax4<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>decompose_result<span class="token punctuation">.</span>resid<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>部分结果如下：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data2_1T_decompose.7bi8h01gdf40.jpg" width="80%/"></div><p>接下来进行周期性检验。首先使用FFT查看频谱图：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">define_fft</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> fs <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> show_pic<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token triple-quoted-string string">"""     # Parameters      data: 检测数据，dataframe类型     show_pic: 是否展示图片     fs: 采样频率，采样时长除以采样点数 = 采样频率    """</span>     n <span class="token operator">=</span> data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    x <span class="token operator">=</span> data<span class="token punctuation">.</span>values    yy <span class="token operator">=</span> fft<span class="token punctuation">(</span>x<span class="token punctuation">)</span>    fre <span class="token operator">=</span> fftfreq<span class="token punctuation">(</span>n<span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">/</span>fs<span class="token punctuation">)</span>            <span class="token comment" spellcheck="true">#求频率横坐标</span>    indices <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>fre <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#筛选大于零的频率</span>    w_pos <span class="token operator">=</span> <span class="token number">2</span><span class="token operator">*</span>abs<span class="token punctuation">(</span>yy<span class="token punctuation">[</span>indices<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">/</span>n    <span class="token comment" spellcheck="true">#计算幅度值</span>    F_pos <span class="token operator">=</span> fre<span class="token punctuation">[</span>indices<span class="token punctuation">]</span>                result_fft <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'freq'</span><span class="token punctuation">,</span> <span class="token string">'spec'</span><span class="token punctuation">,</span> <span class="token string">'T'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>     result_fft<span class="token punctuation">[</span><span class="token string">'freq'</span><span class="token punctuation">]</span> <span class="token operator">=</span> F_pos     result_fft<span class="token punctuation">[</span><span class="token string">'spec'</span><span class="token punctuation">]</span> <span class="token operator">=</span> w_pos     result_fft<span class="token punctuation">[</span><span class="token string">'T'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token operator">/</span>F_pos<span class="token operator">/</span><span class="token number">1440</span>    <span class="token comment" spellcheck="true"># 按照频率强弱程度降序排列 </span>    result_fft <span class="token operator">=</span> result_fft<span class="token punctuation">.</span>sort_values<span class="token punctuation">(</span>by<span class="token operator">=</span><span class="token string">'spec'</span><span class="token punctuation">,</span> ascending<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>     <span class="token keyword">print</span><span class="token punctuation">(</span>result_fft<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> show_pic <span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 频率转换为周期 </span>        plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">/</span>F_pos<span class="token operator">/</span><span class="token number">1440</span><span class="token punctuation">,</span> w_pos<span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token number">0</span>define_fft<span class="token punctuation">(</span>Month_data2_1T<span class="token punctuation">[</span><span class="token string">'Te_0'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>fs<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>show_pic<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></code></pre><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data_1T_periodogram.bx0uzqbkjcw.jpg" width="40%/"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/Month_data_1T_residperiod.4rqdgw1afwu0.jpg" width="30%/"></div>  <p>查看左侧频谱图，可以发现图是有问题的。在周期最大的三个点，也即频率最小的三个点处出现了很大的峰值，低频成分上翘，这明显不对。考虑原因可能有二。  </p><ol><li>原数据存在直流偏移的影响。<br>  解决办法：减去直流量，试减去平均值  </li><li>原数据中趋势的存在干扰了频谱分析。当信号中有明显的趋势项而未消除时，进行相关性分析和功率谱密度分析时会出现畸变，造成低频成分上翘甚至淹没主频成分。<br>  解决办法：去趋势。</li></ol><p>对原数据减去平均值后进行FFT分析，发现频谱图的形状并没有变化，改试方案2。去趋势的方法在网上有许多，这里使用了两种办法：多项式拟合去趋势和时序序列分解。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 多项式拟合去趋势,使用滤波后的数据</span>n <span class="token operator">=</span> Month_data2_1T<span class="token punctuation">[</span><span class="token string">'Te_0_filter'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>x<span class="token operator">=</span>np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> n<span class="token punctuation">,</span> n<span class="token punctuation">)</span>y <span class="token operator">=</span> Month_data_1T<span class="token punctuation">[</span><span class="token string">'Te_0_filter'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>valuesz1 <span class="token operator">=</span> np<span class="token punctuation">.</span>polyfit<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>              <span class="token comment" spellcheck="true"># 曲线拟合，返回值为多项式的各项系数，10为阶数，具体数据选取看曲线拟合程度，可进行可视化查看</span>p1 <span class="token operator">=</span> np<span class="token punctuation">.</span>poly1d<span class="token punctuation">(</span>z1<span class="token punctuation">)</span>                    <span class="token comment" spellcheck="true"># 返回值为多项式的表达式，也就是函数式子</span><span class="token comment" spellcheck="true"># print(p1)</span>y_pred <span class="token operator">=</span> p1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                        <span class="token comment" spellcheck="true"># 根据函数的多项式表达式，求解 y,即趋势</span>Month_data_1T<span class="token punctuation">[</span><span class="token string">'x'</span><span class="token punctuation">]</span><span class="token operator">=</span>Month_data_1T<span class="token punctuation">[</span><span class="token string">'Te_0_filter'</span><span class="token punctuation">]</span><span class="token operator">-</span>y_preddefine_fft<span class="token punctuation">(</span>Month_data_1T<span class="token punctuation">[</span><span class="token string">'x'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>fs<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>show_pic<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></code></pre><p>下图为原数据曲线图、趋势图、原数据去趋势图和FFT图。可以看出，用拟合法去趋势后，FFT图尾端翘起现象几乎没有了，但仍有小尾巴残留。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/polyfit.1wq4d6hwhjq8.jpg" width="80%/"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/polyfit_detrend.2eofsy7hwrwg.jpg" width="80%/"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/ployfit_FFT.4u82p09d7n60.jpg" width="50%/">    </div>  <p>接下来是由时序序列分解法。该方法上面讲过了，操作步骤一致，只是在分解趋势适合，分解了两次，使用77周期分解以此，发现还有周期现象，又使用1440周期对分解出的趋势分解了一次，对用原数据减去二次趋势，再求FFT，结果如图。第一张为去趋势后的图，第二张为FFT结果图。可以看出，该方法去趋势效果更好。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/twice_detrend.7jhgdh1lahw0.jpg" width="80%/"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/twice_detrend_FFT.ekqba34lveo.jpg" width="40%/">    </div>  <p>根据频谱图结果，列出最大的三个能量谱的点依次为1天，0.5天，77min。可能的周期也是这三个点。再根据这三个点看自相关图，分别列出滞后点为1000和10000的相关图。如图所示。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Anomaly_detection_process_img/acf_1000.hy1dzybmthk.jpg" width="80%/"></div>  <p>对于自相关图，当序列存在周期时，会在周期出出现一个高峰。从图中可以看出，曲线分别以约77和1440为周期处出现高峰。再结合实际，77min大致为系统运行一个周期，1440min为系统运行一天。由此可见，数据约以77min和1440min为周期。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;本文主要内容为对时序数据异常检测流程进行简单介绍，然后通过项目实战进行详细解释。全文内容根据个人实际经验所得。&lt;/p&gt;
&lt;h1 id=&quot;1-总体流程介绍&quot;&gt;&lt;a href=&quot;#1-总体流程介绍&quot; class=&quot;headerlink&quot; title=&quot;1.总体流程介绍&quot;&gt;&lt;/a&gt;1.总体流程介绍&lt;/h1&gt;&lt;p&gt;针对项目中传感器数据异常检测，经调研后，个人初步总结工程上实现异常检测的流程。流程框图如下图所示：&lt;br&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="https://easyboy-blog.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习" scheme="https://easyboy-blog.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="时序数据" scheme="https://easyboy-blog.com/tags/%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE/"/>
    
    <category term="异常处理" scheme="https://easyboy-blog.com/tags/%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>c/c++编译流程</title>
    <link href="https://easyboy-blog.com/compilation-process.html"/>
    <id>https://easyboy-blog.com/compilation-process.html</id>
    <published>2022-03-20T08:26:46.597Z</published>
    <updated>2022-04-16T13:22:50.148Z</updated>
    
    <content type="html"><![CDATA[<p>c/c++程序从源代码到二进制程序的编译一般依靠编译工具GCC(GNU Compiler Collection)实现，具体流程分为4步：</p><ol><li>预处理(Preprocessing)</li><li>编译(Compilation)</li><li>汇编(Assemble)</li><li>链接(Linking)   <span id="more"></span></li></ol><h1 id="1-预处理"><a href="#1-预处理" class="headerlink" title="1.预处理"></a>1.预处理</h1><p>对.c或.h或.cpp文件进行预处理，使用预处理器将头文件内容复制到源代码中、删除注释、对宏进行替换等。处理后的文件后缀为.i，实际为完整的源代码，此时文件大小会大许多。gcc命令为:<br><code>gcc -E test.c -o test.i</code><br>-o是指定输出文件名。  </p><h1 id="2-编译"><a href="#2-编译" class="headerlink" title="2.编译"></a>2.编译</h1><p>将预处理文件转换为汇编语言的形式即汇编代码，处理后的文件后缀为.s。编译完后文件已经变得很小了。gcc命令为：<br><code>gcc -S test.i -o test.s</code></p><h1 id="3-汇编"><a href="#3-汇编" class="headerlink" title="3.汇编"></a>3.汇编</h1><p>对汇编代码进一步翻译为机器码，形成目标代码，处理后文件后缀为.o。gcc命令为：<br><code>gcc -c test.s -o test.o</code></p><h1 id="4-链接"><a href="#4-链接" class="headerlink" title="4.链接"></a>4.链接</h1><p>使用链接器将目标代码与其他目标代码、库代码、启动代码等链接起来生成可执行程序，处理后文件后缀为.out(windows下为.exe)。gcc命令为：<br><code>gcc test.o -o test</code><br>gcc工作流程示意图： </p><div align="center"><img src="https://cdn.jsdelivr.net/gh/fight-ing-go/image_repository@master/Compilation_process_img/gcc-compilation-process.33xk22nfohu0.webp" width="60%/"></div><p>注：直接编译为可执行程序的命令为：<code> gcc &lt;文件名&gt; -o &lt;生成的文件名&gt;</code><br>　　gcc命令对于c代码，g++命令对应c++代码。  </p><p>存在误区：</p><ul><li>并不是gcc只能编c，g++只能编c++，两者都可以。后缀为.c的gcc会认作c程序，g++会认作c++；而后缀为.cpp的，两者都会认为是c++程序。g++在编译阶段能调用gcc，而gcc不能自动和c++程序使用的库联结，所以需要g++完成链接，为了统一编译/链接都用了g++。  </li><li>gcc和g++都会定义_cplusplus宏，这个宏只标志编译器将代码按c还是c++语法解释。</li><li>编译能使用gcc/g++，因为在编译阶段g++能自动调用gcc，两者等价；但gcc不能进行库连接，所以链接用g++或gcc -lstdc++。</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;c/c++程序从源代码到二进制程序的编译一般依靠编译工具GCC(GNU Compiler Collection)实现，具体流程分为4步：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;预处理(Preprocessing)&lt;/li&gt;
&lt;li&gt;编译(Compilation)&lt;/li&gt;
&lt;li&gt;汇编(Assemble)&lt;/li&gt;
&lt;li&gt;链接(Linking)&lt;/li&gt;&lt;/ol&gt;</summary>
    
    
    
    <category term="c++" scheme="https://easyboy-blog.com/categories/c/"/>
    
    
    <category term="c++" scheme="https://easyboy-blog.com/tags/c/"/>
    
  </entry>
  
  <entry>
    <title>机器学习笔记</title>
    <link href="https://easyboy-blog.com/machine-learning-notes.html"/>
    <id>https://easyboy-blog.com/machine-learning-notes.html</id>
    <published>2022-03-14T07:16:30.553Z</published>
    <updated>2022-03-20T13:41:38.487Z</updated>
    
    <content type="html"><![CDATA[<pre><code>机器学习三要素：数据、算法、模型简单来说，机器学习就是利用已有的数据通过选择的算法训练模型，用以预测分析。</code></pre> <span id="more"></span><h1 id="1-机器学习算法分类"><a href="#1-机器学习算法分类" class="headerlink" title="1 机器学习算法分类"></a>1 机器学习算法分类</h1><ul><li><strong>监督学习</strong>：输入的数据有标签。<br>  对于离散数据，标签用于分类，可以归结为分类问题。<br>  对于连续数据标签，归结为回归问题。</li><li><strong>无监督学习</strong>：输入数据无标签。</li></ul><h1 id="2-开发流程"><a href="#2-开发流程" class="headerlink" title="2 开发流程"></a>2 开发流程</h1><ol><li>收集数据。要考虑到后续分析所需要的数据，选取重要特征、足够多的数据等。</li><li>准备数据。实际中，收集到的数据可能存在很多问题，需要进行数据清洗。然后再将其划分为训练集(占比较大)和测试集。</li><li>选择模型。根据实际情况，选择合适的模型。监督学习模型和无监督学习模型。</li><li>训练。使用训练集数据对选择的模型进行训练，需要反复测试。</li><li>评估。对训练出的模型，用测试集进行测试，检验其性能好坏。评估指标主要有：准确率、召回率、F值。</li><li>参数调整。主要是调整参数对模型进行改进。</li><li>预测。将模型应用于实际，对相关问题进行预测。</li></ol><h1 id="3-学习工具"><a href="#3-学习工具" class="headerlink" title="3 学习工具"></a>3 学习工具</h1><ol><li>机器学习库：sklearn。Python的机器学习工具，包含许多机器学习算法的实现。</li><li>数据集：scikit-learn、kaggle、UCI</li><li>开发工具：pycharm、vscode、Jupyter notebook(网页版可视化)</li></ol><h1 id="4-特征工程"><a href="#4-特征工程" class="headerlink" title="4 特征工程"></a>4 特征工程</h1><p>  在使用模型进行训练前，需要对原始数据展开特征工程，目的是为了更高效的利用算法，能影响机器学习的效果。<br>  包含三个步骤：特征提取、特征预处理、特征降维。</p><h2 id="4-1-特征提取"><a href="#4-1-特征提取" class="headerlink" title="4.1 特征提取"></a>4.1 特征提取</h2><pre><code>从原本的数据集中提取出适合机器学习的数据。  主要是为了解决三个问题:  </code></pre><ul><li>原始数据特征中的强相关性造成的冗余信息。  </li><li>原始数据十分稀疏.</li><li>原始数据维度较大。<blockquote><p>API: sklearn.feature_extraction</p></blockquote></li></ul><h2 id="4-2-特征预处理"><a href="#4-2-特征预处理" class="headerlink" title="4.2 特征预处理"></a>4.2 特征预处理</h2><p>  对特征无量纲化，目的是让特征处于同等地位。常见方法有：归一化和标准化。</p><h3 id="4-2-1-归一化"><a href="#4-2-1-归一化" class="headerlink" title="4.2.1 归一化"></a>4.2.1 归一化</h3><p>  将原始数据映射到[0，1]之间。公式为：<br>  $x’=\frac {x-min}{max-min}$　　　$x’’=x’*(mx-mi)+mi$<br>  其中，ｘ’’为最终结果，max为一列中的最大值，min为一列中的最小值。mx,mi为指定映射的区间，通常mx=1,mi=0<br>  缺点：当数据存在较多异常点是，会影响归一化结果。该方法鲁棒性差，只适合精确小数据场景。  </p><blockquote><p>API: sklearn.preprocessing.MinMaxScaler(feature_range=(0,1)…)</p></blockquote><h3 id="4-2-2-标准化"><a href="#4-2-2-标准化" class="headerlink" title="4.2.2 标准化"></a>4.2.2 标准化</h3><p>  将数据变换为均值为0，标准差为1的范围内。公式为:<br>  $x’=\frac{x-\overline x}{\sigma}$<br>  作用于每一列，$\overline x$ 为平均值，$\sigma$ 为标准差<br>  平均值和标准差受异常值影响较小，标准化方法能一定程度上克服异常点带来的干扰。适用于样本数量大的情况。</p><blockquote><p>API: sklearn.preprocessing.StandardScaler()  </p></blockquote><h2 id="4-3-特征降维"><a href="#4-3-特征降维" class="headerlink" title="4.3 特征降维"></a>4.3 特征降维</h2><p>  减少相关性较强的特征，得到一组不相关的主变量。常见方法有：特征选择和主成分分析。  </p><h3 id="4-3-1-特征选择"><a href="#4-3-1-特征选择" class="headerlink" title="4.3.1 特征选择"></a>4.3.1 特征选择</h3><p>  在原有的冗余特征中找出主要特征。</p><ul><li>Filter(过滤式): <ul><li>方差选择法：过滤低方差特征<blockquote><p>API: sklearn.feature_selection.VarianceThreshold(threshold = 0.0)  </p></blockquote></li><li>相关系数： 过滤相关程度高的特征,常用有皮尔逊相关系数。对于相关性程度高的特征：<ol><li>选取其中一个</li><li>加权求和</li><li>主成分分析<blockquote><p>API: scipy.stats.pearsonr</p></blockquote></li></ol></li></ul></li><li>Embedded(嵌入式)：<ul><li>决策树</li><li>正则化 <h3 id="4-3-2-主成分分析-PCA"><a href="#4-3-2-主成分分析-PCA" class="headerlink" title="4.3.2 主成分分析(PCA)"></a>4.3.2 主成分分析(PCA)</h3>将n维特征映射到k维上，实现特征降维，减少复杂度。一般用于回归分析或聚类。<blockquote><p>API: sklearn.decomposition.PCA(n_components=None)  </p></blockquote><h1 id="5-模型选择与调优"><a href="#5-模型选择与调优" class="headerlink" title="5. 模型选择与调优"></a>5. 模型选择与调优</h1><p>一般来说，模型调优有3个方向：选择更好的算法，调优模型参数，改进数据。这里简单说下模型参数调优。<br>模型参数调优有两步：交叉验证(cross validation)和超参数搜索-网格搜索(Grid Search)。</p></li></ul></li><li>交叉验证：对于训练集数据，再次将其划分为训练集和验证集，用以评估模型预测准确性，让模型更加准确可信。限制模型过拟合、欠拟合等问题。</li><li>超参数搜索-网格搜索:对于算法中需要自定义的参数，叫超参数。对模型预设几种超参数组合，同时训练，选出最优参数组合。<blockquote><p>API: sklearn.model_selection.GridSearchCV  (同时进行交叉验证和网格搜索)</p></blockquote></li></ul><h1 id="6-总结"><a href="#6-总结" class="headerlink" title="6.总结"></a>6.总结</h1><p>机器学习实战流程：</p><ol><li>导入数据</li><li>划分数据集</li><li>特征工程</li><li>模型训练与调优</li><li>模型评估</li></ol>]]></content>
    
    
    <summary type="html">&lt;pre&gt;&lt;code&gt;机器学习三要素：数据、算法、模型
简单来说，机器学习就是利用已有的数据通过选择的算法训练模型，用以预测分析。
&lt;/code&gt;&lt;/pre&gt;</summary>
    
    
    
    <category term="机器学习" scheme="https://easyboy-blog.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习" scheme="https://easyboy-blog.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
</feed>
